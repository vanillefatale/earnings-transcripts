# generator/summary_qna_gpt.py

import os
import argparse
from pathlib import Path
from dotenv import load_dotenv
from openai import OpenAI

from telegram_notifier import send_telegram_message

load_dotenv()

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    raise RuntimeError("OPENAI_API_KEY ê°€ .env ì— ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")

client = OpenAI(api_key=OPENAI_API_KEY)

BASE_DIR = Path(__file__).resolve().parent
READY_DIR = BASE_DIR / "0-ready"       # 0-ready/<output_name>_qna.txt
SUMMARY_DIR = BASE_DIR / "2-summary"   # 2-summary/<output_name>_qna_summary_gpt.txt
SUMMARY_DIR.mkdir(exist_ok=True)


def read_file(path: Path) -> str:
    with open(path, "r", encoding="utf-8") as f:
        return f.read()

QNA_PROMPT = """
You are a corporate earnings call analyst focused on Q&A segments.

When the user provides an earnings call transcript, automatically extract and summarize ALL Q&A pairs in a single response without asking for confirmation or pausing.

Critical Instructions:
- NEVER ask how many Q&A pairs exist
- NEVER ask if user wants to continue
- NEVER provide partial results
- ALWAYS complete full analysis of ALL Q&A pairs in one response
- NO formatting marks (asterisks, hashtags, dashes, bullets, bold, italic, etc.)
- Plain text only for Telegram compatibility

Workflow:
1. Read entire transcript and locate the Q&A section
2. Count total Q&A pairs
3. Extract and summarize ALL Q&A pairs immediately in a single response

Output Format:
For each Q&A pair, provide:

Q. [í•µì‹¬ ì§ˆë¬¸ ë‚´ìš©]
[ë‹µë³€ì„ 2-3ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ìš”ì•½í•˜ë˜, ~ì„, ~í•¨, ~ì¤‘ì„ ë“±ì˜ ëª…ì‚¬í˜• ì¢…ê²°ì–´ë¯¸ ì‚¬ìš©]

Example:

Q. ë¸Œëœë“œë³„ ê°€ê²© ì¸ìƒ ì¶”ì„¸?
ì—¬ëŸ¬ ë¸Œëœë“œë“¤ì´ ê°€ê²© ì¸ìƒì„ ë°œí‘œí–ˆìœ¼ë‚˜ ì´ë²ˆ ë¶„ê¸°ëŠ” íŠ¹ë³„íˆ í¬ì§€ ì•Šì•˜ìŒ. ê´€ì„¸ì™€ ì›ê°€ ìƒìŠ¹ì„ ê°ì•ˆí•´ ë¸Œëœë“œë“¤ê³¼ í˜‘ì˜ ì¤‘ì´ë‚˜, ì†Œë¹„ì ë¶€ë‹´ì„ ê³ ë ¤í•´ ê°€ì¹˜ë¥¼ ìœ ì§€í•˜ë ¤ê³  í•¨.

Q. ì˜¨ë¼ì¸ ì„±ì¥ ê´€ë ¨?
ì—¬ì „íˆ 80% ë§¤ì¶œì€ ì˜¤í”„ë¼ì¸ ë§¤ì¥ì´ë©°, ìŠ¤í† ì–´ì™€ ì´ì»¤ë¨¸ìŠ¤ ëª¨ë‘ ì„±ì¥ ì¤‘ì„.

Q. 2026ë…„ ë¸Œëœë“œ íŒŒì´í”„ë¼ì¸?
êµ¬ì²´ì ì¸ ì´ë¦„ê³¼ ê·œëª¨ëŠ” 3ì›”ì— ê³µìœ  ì˜ˆì •ì´ë‚˜, í˜„ì¬ ë³´ì´ëŠ” 2026 íŒŒì´í”„ë¼ì¸ì— ëŒ€í•´ ë§¤ìš° ê¸ì •ì ìœ¼ë¡œ í‰ê°€í•˜ê³  ìˆìŒ.

Q. í™€ë¦¬ë°ì´ ì‹œì¦Œ ëª¨ë©˜í…€?
Black Fridayì™€ Cyber Monday ì‹¤ì ì— ë§Œì¡±í•˜ê³  ìˆìœ¼ë©°, ë¶„ê¸° ë‚´ë‚´ ì»´í”„ ì„±ì¥ì´ ê³ ë¥´ê²Œ ë‚˜íƒ€ë‚¬ìŒ.

Requirements:
- Keep each answer to 2-3 sentences maximum
- Use Korean business language with ~ì„, ~í•¨, ~ì¤‘ì„ ë“± ëª…ì‚¬í˜• ì¢…ê²°ì–´ë¯¸ë¥¼ ì¼ê´€ë˜ê²Œ ì‚¬ìš©í•  ê²ƒ
- Focus on key points only and exclude unnecessary ì„¸ë¶€ì‚¬í•­, ì—í”¼ì†Œë“œ, ë°˜ë³µ ì„¤ëª…
- No special characters or formatting marks in the output (no asterisks, hashtags, dashes, bullets, bold, italic, êµ¬ë¶„ì„  ë“±)
- Plain text only
- Process entire Q&A section in a single response
- Maintain a professional yet concise tone
- Include ALL Q&A pairs without stopping or truncating

ì¤‘ìš” ì¶œë ¥ í˜•ì‹ ê·œì¹™ (ë°˜ë“œì‹œ ì§€í‚¬ ê²ƒ):
- ê° Q&AëŠ” ì •í™•íˆ ë‘ ë¸”ë¡ìœ¼ë¡œ êµ¬ì„±í•¨
  ì²« ì¤„: Q. ë¡œ ì‹œì‘í•˜ëŠ” ì§ˆë¬¸ ìš”ì•½ í•œ ì¤„
  ë‘˜ì§¸ ì¤„: ë‹µë³€ ìš”ì•½ í•œ ë‹¨ë½ (2-3ë¬¸ì¥, ëª¨ë‘ ~ì„ / ~í•¨ / ~ì¤‘ì„ìœ¼ë¡œ ëë‚˜ë„ë¡ ì‘ì„±í•¨)
- Q. ì™€ ë‹µë³€ ì‚¬ì´ì—ëŠ” ë¹ˆ ì¤„ì„ ë„£ì§€ ì•ŠìŒ
- ì„œë¡œ ë‹¤ë¥¸ Q&A ìŒ ì‚¬ì´ì—ëŠ” ë¹ˆ ì¤„ í•˜ë‚˜ë§Œ ë„£ìŒ
- ë§¨ ìœ„/ë§¨ ì•„ë˜ì— êµ¬ë¶„ì„ , ìš”ì•½ ì„¤ëª… ë¬¸êµ¬, ì¶”ê°€ ì¥ì‹ í…ìŠ¤íŠ¸ë¥¼ ì¶”ê°€í•˜ì§€ ì•ŠìŒ
"""


def generate_qna_summary(text: str) -> str:
    """
    ì–´ë‹ì½œ Q&A ì›ë¬¸(text)ì„ ë°›ì•„ì„œ,
    QNA_PROMPT í˜•ì‹ì— ë§ëŠ” Q&A ìš”ì•½ í…ìŠ¤íŠ¸ë¥¼ ë°˜í™˜.
    (í…”ë ˆê·¸ë¨ì— ê·¸ëŒ€ë¡œ ì „ì†¡ ê°€ëŠ¥í•œ ìˆœìˆ˜ í…ìŠ¤íŠ¸)
    """
    full_prompt = (
        QNA_PROMPT
        + "\n\n"
        + "ì•„ë˜ëŠ” ë¶„ì„í•  ì–´ë‹ì½œ ì „ì²´ ì›ë¬¸ì´ë‹¤. ì´ ì¤‘ Q&A ì„¹ì…˜ì„ ìŠ¤ìŠ¤ë¡œ ì°¾ì•„ì„œ ìœ„ ì§€ì‹œë¥¼ ëª¨ë‘ ë§Œì¡±í•˜ëŠ” ì¶œë ¥ë§Œ ìƒì„±í•˜ë¼.\n"
        + "ì›ë¬¸ ì‹œì‘\n"
        + "================================================================================\n"
        + text
        + "\n================================================================================\n"
        + "ì›ë¬¸ ë\n"
    )

    response = client.responses.create(
        model=os.getenv("OPENAI_MODEL_SUMMARY", "gpt-4.1-mini"),
        input=full_prompt,
        max_output_tokens=4000,  # Q&A í˜ì–´ê°€ ë§ì„ ìˆ˜ ìˆìœ¼ë‹ˆ ë„‰ë„‰í•˜ê²Œ
        temperature=0.2,
    )

    return response.output_text.strip()

# summary_qna_gpt.py ë§¨ ì•„ë˜ìª½ì— ì¶”ê°€

from telegram_notifier import send_telegram_message  # ìƒë‹¨ì— ì´ë¯¸ ìˆìœ¼ë©´ ìƒëµ

def run_qna_summary(output_name: str):
    """
    earningscall_generator ì—ì„œ ë¶ˆëŸ¬ ì“°ê¸° ìœ„í•œ í—¬í¼.
    0-ready/<output_name>_qna.txt ë¥¼ ì½ì–´ì„œ
    GPT Q&A ìš”ì•½ íŒŒì¼ ìƒì„± + í…”ë ˆê·¸ë¨ ì „ì†¡ê¹Œì§€ ìˆ˜í–‰í•¨.
    """
    input_path = READY_DIR / f"{output_name}_qna.txt"
    if not input_path.exists():
        raise FileNotFoundError(f"ì…ë ¥ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {input_path}")

    print(f"[ğŸ§ ] GPT Q&A Summary ìƒì„± ì¤‘... ({input_path})")
    raw_text = read_file(input_path)
    summary_text = generate_qna_summary(raw_text)

    # 1) íŒŒì¼ ì €ì¥
    output_path = SUMMARY_DIR / f"{output_name}_qna_summary_gpt.txt"
    with open(output_path, "w", encoding="utf-8") as f:
        f.write(summary_text)

    print(f"[âœ”] Q&A ìš”ì•½ ì €ì¥ ì™„ë£Œ: {output_path}")

    # 2) í…”ë ˆê·¸ë¨ ë°œì†¡
    header = f"[{output_name}] Q&A Summary\n\n"
    full_msg = header + summary_text

    print("[ğŸ“¨] í…”ë ˆê·¸ë¨ìœ¼ë¡œ Q&A ìš”ì•½ ì „ì†¡ ì¤‘...")

    chunk_size = 3800  # í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ ì œí•œ ê³ ë ¤
    for i in range(0, len(full_msg), chunk_size):
        chunk = full_msg[i : i + chunk_size]
        send_telegram_message(chunk, use_markdown=False)

    return summary_text, str(output_path)


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "output_name",
        help="íŒŒì¼ ë² ì´ìŠ¤ ì´ë¦„ (ì˜ˆ: VSCO_3Q25 â†’ 0-ready/VSCO_3Q25_qna.txt ë¥¼ ì½ìŒ)",
    )
    args = parser.parse_args()

    input_path = READY_DIR / f"{args.output_name}_qna.txt"
    if not input_path.exists():
        raise FileNotFoundError(f"ì…ë ¥ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {input_path}")

    print(f"[ğŸ“¥] Q&A ì›ë¬¸ ì½ëŠ” ì¤‘: {input_path}")
    raw_text = read_file(input_path)

    print("[ğŸ§ ] GPT Q&A Summary ìƒì„± ì¤‘...")
    summary_text = generate_qna_summary(raw_text)

    # 1) íŒŒì¼ ì €ì¥
    output_path = SUMMARY_DIR / f"{args.output_name}_qna_summary_gpt.txt"
    with open(output_path, "w", encoding="utf-8") as f:
        f.write(summary_text)

    print(f"[âœ”] Q&A ìš”ì•½ ì €ì¥ ì™„ë£Œ: {output_path}")

    # 2) í…”ë ˆê·¸ë¨ ì „ì†¡ (í—¤ë”ë„ ìµœëŒ€í•œ ì‹¬í”Œí•œ í”Œë ˆì¸ í…ìŠ¤íŠ¸)
    header = f"[{args.output_name}] Q&A Summary\n\n"
    full_msg = header + summary_text

    print("[ğŸ“¨] í…”ë ˆê·¸ë¨ìœ¼ë¡œ Q&A ìš”ì•½ ì „ì†¡ ì¤‘...")

    # í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ ê¸¸ì´ ì œí•œ ê³ ë ¤ (ì—¬ìœ  ìˆê²Œ 3,800ìë¡œ ë‚˜ëˆ”)
    chunk_size = 3800
    for i in range(0, len(full_msg), chunk_size):
        chunk = full_msg[i : i + chunk_size]
        send_telegram_message(chunk, use_markdown=False)

    print("\n===== PREVIEW (ìƒìœ„ 40ì¤„) =====\n")
    preview_lines = summary_text.splitlines()[:40]
    print("\n".join(preview_lines))


if __name__ == "__main__":
    main()
