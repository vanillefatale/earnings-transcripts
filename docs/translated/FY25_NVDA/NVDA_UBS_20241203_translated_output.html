<!DOCTYPE html>
<html><head><meta charset="UTF-8">
<title>Earnings Call 번역</title>
<style>
    body { font-family: Arial; margin: 40px; background-color: #fdfdfd; }
    h1 { text-align: center; }
    h2 { margin-top: 50px; color: #003366; }
    h3 { color: #333; }
    table { border: 1px solid #ddd; width: 100%; border-collapse: collapse; }
    th { background: #f0f0f0; padding: 10px; border-bottom: 2px solid #ccc; }
    td { padding: 10px; border-bottom: 1px dotted #ccc; vertical-align: top; }
    p { line-height: 1.6; }
    hr { margin: 50px 0; border: none; border-top: 1px solid #ccc; }
    .back-button {
        display: inline-block;
        background-color: #5f5f5f;
        color: white;
        padding: 10px 16px;
        border-radius: 6px;
        text-decoration: none;
        font-weight: 500;
        box-shadow: 0 2px 6px rgba(0,0,0,0.1);
        margin-bottom: 30px;
    }
</style>
</head><body>
<a href="../../index.html" class="back-button">←</a>
<h1>📄 Earnings Call Transcript 번역 결과</h1>

    <h2>📊 Presentation</h2>
    <table style="width:100%; border-collapse:collapse; margin-bottom: 40px;">
        <tr>
            <th style="width:50%; border-bottom: 2px solid #333;">Original</th>
            <th style="width:50%; border-bottom: 2px solid #333;">Translation</th>
        </tr>
        <tr><td>Call Start: 9:35 January 1, 0000 10:05 AM ET<br><br>NVIDIA Corporation (NASDAQ:NVDA)<br>UBS Global Technology Conference Call<br>December 3, 2024 9:35 AM ET<br><br>Company Participants<br><br>Colette Kress - Executive Vice President and Chief Financial Officer<br><br>Conference Call Participants<br><br>Tim Arcuri - UBS<br><br>Tim Arcuri<br><br>Good morning. Thank you. I am Tim Arcuri. I am very pleased to have NVIDIA. Pleased to have Colette with us. Thank you Colette for the time. And we're just going to kick it off. And Colette, it's been an incredible past couple of years. You're still growing very fast. I'm wondering if you can talk about some of the use cases, how they've evolved? We're having enterprises adopt AI widely.</td><td>**통화 시작: 9:35 January 1, 0000 10:05 AM ET**<br><br>**엔비디아 코퍼레이션 (NASDAQ:NVDA)**<br>**UBS 글로벌 테크놀로지 컨퍼런스 콜**<br>**2024년 12월 3일 오전 9:35 ET**<br><br>**회사 참석자**<br><br>콜레트 크레스 - 부사장 겸 최고재무책임자<br><br>**컨퍼런스 콜 참석자**<br><br>팀 아르쿠리 - UBS<br><br>**팀 아르쿠리**<br><br>안녕하세요. 감사합니다. 저는 팀 아르쿠리입니다. 엔비디아를 모시게 되어 매우 기쁩니다. 콜레트와 함께할 수 있어서 기쁩니다. 시간을 내주셔서 감사합니다, 콜레트. 바로 시작하겠습니다. 콜레트, 지난 몇 년간 정말 놀라운 성과를 보여주셨습니다. 여전히 매우 빠르게 성장하고 계십니다. 사용 사례들이 어떻게 발전해왔는지, 그리고 기업들이 AI를 광범위하게 도입하고 있는 상황에 대해 말씀해 주실 수 있나요?</td></tr>
<tr><td>How has the demand picture sort of evolved in terms of Cloud, Consumer, Internet and Enterprise and maybe if you can talk about some of the use cases that you see that are very exciting, as well? Colette Kress<br><br>Okay. Let me first start with a statement that I must read. As a reminder, this presentation contains forward-looking statements and investors are advised to read our reports filed with the SEC for information related to risk, uncertainties in facing our business. Okay, really great to see everybody here and thank you so much for hosting us. Let me kind of talk about what we have seen is certainly just been a fast journey even over the last several quarters.</td><td>클라우드, 소비자, 인터넷, 그리고 엔터프라이즈 측면에서 수요 상황이 어떻게 변화했는지, 그리고 매우 흥미로운 사용 사례들에 대해서도 말씀해 주실 수 있나요?<br><br>콜레트 크레스<br><br>좋습니다. 먼저 제가 반드시 읽어야 하는 성명서부터 시작하겠습니다. 참고로, 이 프레젠테이션에는 미래예측진술이 포함되어 있으며, 투자자분들께서는 저희 사업이 직면한 위험과 불확실성에 관한 정보를 위해 SEC에 제출한 저희 보고서를 읽어보시기 바랍니다. <br><br>좋습니다, 여러분을 뵙게 되어 정말 기쁘고 저희를 초대해 주셔서 대단히 감사합니다. 지난 몇 분기 동안에도 정말 빠른 여정이었다고 저희가 목격한 것에 대해 말씀드리겠습니다.</td></tr>
<tr><td>But keep in mind, we are 30 years in terms of the business that we're doing, but we certainly are in a very important phase. When we think about the phase that we are in and what we are seeing, we do believe that the computing platform that many of us have been using and seeing for more than 20 to 30 years is here to transform for the next decades going forward. So what that means is we are seeing those concentrating on their existing computing platform, which may include general purpose computing and a shift to accelerated computing. But a new piece was also added outside of just focusing on accelerated computing and that was the focus on AI and the focus on Generative AI.</td><td>하지만 명심하셔야 할 점은, 저희가 하고 있는 사업 측면에서는 30년의 역사를 가지고 있지만, 현재 매우 중요한 국면에 있다는 것입니다. 저희가 처해 있는 이 국면과 저희가 목격하고 있는 상황을 생각해보면, 저희 중 많은 사람들이 20년에서 30년 이상 사용하고 지켜봐 온 컴퓨팅 플랫폼이 앞으로 수십 년간 변화를 맞이할 것이라고 확신합니다. 이것이 의미하는 바는, 범용 컴퓨팅을 포함할 수 있는 기존 컴퓨팅 플랫폼에 집중하던 것에서 가속 컴퓨팅으로의 전환에 집중하는 모습을 보고 있다는 것입니다. 하지만 가속 컴퓨팅에만 집중하는 것 외에 새로운 요소가 추가되었는데, 그것은 바로 AI에 대한 집중, 그리고 생성형 AI에 대한 집중입니다.</td></tr>
<tr><td>The new use cases that we have seen of course over the last several quarters is the size of models. If you recall, before the very onset of Generative AI, we talked about large language models. And the importance that they were there for much of the work in terms of the consumer Internet companies, the recommender engines and model sizes continue to get larger. Right now the work in terms of foundational models are very key in terms of the work that you see happening. But you also see the scaling of those models as they focus on many different types of foundational models and multi-modal types of models being built.</td><td>지난 몇 분기 동안 저희가 목격한 새로운 사용 사례는 물론 모델의 규모입니다. 기억하시겠지만, 생성형 AI가 본격적으로 시작되기 전에 저희는 대규모 언어 모델에 대해 이야기했습니다. 그리고 이러한 모델들이 소비자 인터넷 기업들의 업무, 추천 엔진 측면에서 매우 중요했으며, 모델 크기는 계속해서 커지고 있습니다. 현재 파운데이션 모델 관련 작업은 여러분이 보고 계신 업무 측면에서 매우 핵심적입니다. 하지만 또한 다양한 유형의 파운데이션 모델과 멀티모달 유형의 모델 구축에 집중하면서 이러한 모델들의 확장도 보고 계실 것입니다.</td></tr>
<tr><td>The next phase of this transition is also focusing on that inferencing phase. And you'll see more and more work in terms of the types of systems that we are bringing do support that inferencing model after we have developed the large language models, all of our different types of customers are unique. We are working from everything from the start-ups to the research, the CSPs are some of the most important that are standing up compute so fast for the end enterprises that need to use that. We are working with consumer Internet companies, but more importantly, we are working globally in terms of supporting this initiative.</td><td>이 전환의 다음 단계는 추론(inferencing) 단계에 집중하는 것이기도 합니다. 대규모 언어 모델을 개발한 후 추론 모델을 지원하기 위해 우리가 도입하고 있는 시스템 유형 측면에서 더욱 많은 작업을 보시게 될 것입니다. 우리의 다양한 고객 유형은 모두 고유합니다. 우리는 스타트업부터 연구기관까지 모든 분야에서 작업하고 있으며, CSP(클라우드 서비스 제공업체)들은 최종 기업들이 사용할 수 있도록 컴퓨팅을 매우 빠르게 구축하고 있어 가장 중요한 고객 중 일부입니다. 우리는 소비자 인터넷 기업들과도 협력하고 있지만, 더 중요한 것은 이러한 이니셔티브를 지원하기 위해 전 세계적으로 작업하고 있다는 점입니다.</td></tr>
<tr><td>Nothing that we've seen before in terms of the speed and the understanding of what's going to be in front of us. So, those are some of the things that we're seeing today. Tim Arcuri<br><br>And I think, we all worry that eventually we're going to build too much capacity. And I think your view is that we're nowhere close to that. So, maybe can you just speak to sort of how much visibility you have and maybe just the demand picture relative to what you're able to supply?</td><td>이전에 본 적이 없는 속도와 앞으로 무엇이 펼쳐질지에 대한 이해 수준입니다. 이것들이 오늘 우리가 보고 있는 몇 가지 상황들입니다.<br><br>Tim Arcuri<br><br>그리고 저희 모두는 결국 너무 많은 생산능력을 구축하게 될 것을 우려하고 있다고 생각합니다. 그런데 귀하의 견해로는 우리가 그런 상황과는 거리가 멀다고 보시는 것 같습니다. 그렇다면 귀하가 얼마나 많은 가시성을 확보하고 계신지, 그리고 공급 가능한 물량 대비 수요 상황에 대해 말씀해 주실 수 있을까요?</td></tr>
<tr><td>Colette Kress<br><br>Yeah, when we look at the quarters in the past and our scaling, our number one goal in terms of scaling is working with both all of our partners, downstreams with our customers, but also in terms of bringing in supply. No, we are not near any point in time, now where we are seeing any type of a slowdown. What we are seeing right now is demand continues to be fueled a lot due to the size of models, the complexity of inferencing and we are still getting ready for our next architecture, Blackwell.</td><td>콜레트 크레스<br><br>네, 과거 분기들과 저희의 확장을 살펴볼 때, 확장 측면에서 저희의 최우선 목표는 모든 파트너들, 고객들과의 다운스트림 협력뿐만 아니라 공급 확보 측면에서도 함께 작업하는 것입니다. 아니요, 저희는 현재 어떤 종류의 둔화를 보고 있는 시점에 전혀 가까이 있지 않습니다. 지금 저희가 보고 있는 것은 모델의 규모, 추론의 복잡성으로 인해 수요가 계속해서 크게 증가하고 있다는 것이며, 저희는 여전히 차세대 아키텍처인 블랙웰을 준비하고 있습니다.</td></tr>
<tr><td>And right now what we see in terms of our Blackwell, which will be here this quarter is also probably a supply constraint that is going to take us well into our next fiscal year for several quarters from now. So, no, we don't see a slowdown. We continue to see tremendous demand and interest, particularly for our new architecture that's coming out. Tim Arcuri<br><br>Well, just on that point, so you’ve put up a great quarter. You’re shipping Blackwell in January and you are actually shipping more Blackwell than you thought you would three months ago. And at the same time, we do hear a lot of chop in the supply chain. You hear a lot of articles written and things like that.</td><td>그리고 현재 이번 분기에 출시될 예정인 저희 Blackwell의 경우에도 아마 공급 제약이 있을 것으로 보이며, 이는 지금으로부터 몇 분기 후인 다음 회계연도까지 지속될 것으로 예상됩니다. 따라서 아니요, 저희는 둔화를 보지 않습니다. 특히 저희가 출시하는 새로운 아키텍처에 대한 엄청난 수요와 관심을 지속적으로 보고 있습니다.<br><br>Tim Arcuri<br><br>바로 그 점에 대해서 말씀드리면, 훌륭한 분기 실적을 기록하셨고, 1월에 Blackwell을 출하하실 예정이며 실제로 3개월 전에 예상했던 것보다 더 많은 Blackwell을 출하하고 계십니다. 동시에 공급망에서 많은 혼란이 있다는 소식을 듣고 있습니다. 관련 기사들도 많이 나오고 있고요.</td></tr>
<tr><td>Can you just speak to how Blackwell is different than prior product cycles? Colette Kress<br><br>Yes, our Blackwell architecture is unique. What we are doing here is building at a datacenter scale. Don't get us wrong, we have been working in terms of platforms for many years, not just at the chip level and something that is end-to-end to scale. But when you look at our Hopper architecture, our Hopper architecture is for that rack scale and the work that we have done. Essentially what you're seeing with our Blackwell architecture, some of them we will completely build inside of our supply chain get it ready, get it stood up, take it down, dip it and they will stand it up together.</td><td>블랙웰이 이전 제품 사이클과 어떻게 다른지 말씀해 주실 수 있나요?<br><br>콜레트 크레스:<br><br>네, 저희 블랙웰 아키텍처는 독특합니다. 저희가 여기서 하고 있는 것은 데이터센터 규모로 구축하는 것입니다. 오해하지 마시기 바랍니다. 저희는 수년간 플랫폼 측면에서 작업해왔습니다. 단순히 칩 수준이 아니라 확장 가능한 엔드투엔드 솔루션으로 말입니다. 하지만 저희 호퍼 아키텍처를 보시면, 호퍼 아키텍처는 랙 규모와 저희가 수행한 작업을 위한 것입니다. 본질적으로 블랙웰 아키텍처에서 보시는 것은, 일부는 저희가 공급망 내에서 완전히 구축하여 준비하고, 설치하고, 해체하고, 테스트한 후 함께 다시 설치할 것입니다.</td></tr>
<tr><td>And what we are doing is a greater portion of choices for the customers depending on where they are in their lifecycle. And what we mean by that is datacenters are complex and the types of things that they do to make them the most efficient, each of them are at different stages. So you have the opportunity to choose between a lot of different options of what we're doing. That means we can do liquid cool. We can do continued in terms of air-cooled. You can incorporate an ARM CPU, but also x86 if you want. There's many different networking options that we have, whether that's InfiniBand and Ethernet and many different other switch choices in there.</td><td>그리고 저희가 하고 있는 것은 고객들이 그들의 라이프사이클에서 어느 단계에 있는지에 따라 더 많은 선택권을 제공하는 것입니다. 이것이 의미하는 바는 데이터센터는 복잡하고, 데이터센터를 가장 효율적으로 만들기 위해 하는 작업들의 유형이 각각 다른 단계에 있다는 것입니다. 따라서 저희가 제공하는 다양한 옵션들 중에서 선택할 수 있는 기회가 있습니다. 이는 액체 냉각을 할 수도 있고, 공기 냉각을 계속 사용할 수도 있다는 의미입니다. ARM CPU를 통합할 수도 있지만, 원한다면 x86도 사용할 수 있습니다. 저희가 보유한 네트워킹 옵션도 매우 다양합니다. InfiniBand와 이더넷을 비롯해 그 안에서 선택할 수 있는 다양한 스위치 옵션들이 있습니다.</td></tr>
<tr><td>That decision is with the customer and many different configurations. When we think about where we are right now in Blackwell for this quarter, all is done in terms of the chip. The chip is fine. The chip and the work that we have done has moved quite well. Right now, we are standing up configurations for so many of our different customers. You will all see pictures on the Internet. Pictures with happy faces as they get excited for standing up the first one and getting ready to put the whole datacenter and all of the different racks together in terms of that. That's where we stand today. Tim Arcuri<br><br>Great.</td><td>해당 결정은 고객과 다양한 구성에 달려 있습니다. 이번 분기 Blackwell의 현재 상황을 생각해보면, 칩 측면에서는 모든 것이 완료되었습니다. 칩은 문제없고, 저희가 수행한 작업도 상당히 순조롭게 진행되었습니다. 현재 저희는 다양한 고객들을 위한 구성 설정을 진행하고 있습니다. 여러분들도 인터넷에서 사진들을 보실 수 있을 것입니다. 첫 번째 시스템을 구축하며 기뻐하고, 전체 데이터센터와 모든 다양한 랙들을 함께 구성할 준비를 하는 행복한 표정의 사진들을 말입니다. 이것이 오늘 현재 저희가 서 있는 위치입니다.<br><br>Tim Arcuri: 좋습니다.</td></tr>
<tr><td>And there's just a lot going on with the product cadence and you have B100, you have B200, you have the racks with [TB], then you have Blackwell Ultra coming about six months later. So, is there a risk that customers wait, because you have products coming so quickly? Colette Kress<br><br>No, when you think about what is necessary in designing the datacenter, it does takes planning. And what we have seen in, at least, the last five to ten years is more work with all of our different customers as they plan every six months they're planning. What is here? What am I going to build? And they need to be ready for compute at that time that they are working in terms of in projects.</td><td>그리고 제품 출시 일정에 많은 일들이 있습니다. B100도 있고, B200도 있고, [TB]가 포함된 랙도 있고, 그 다음에는 약 6개월 후에 Blackwell Ultra가 출시될 예정입니다. 그렇다면 제품들이 너무 빠르게 출시되기 때문에 고객들이 기다릴 위험이 있을까요?<br><br>콜레트 크레스<br><br>아니요, 데이터센터를 설계하는 데 필요한 것들을 생각해보면, 계획이 필요합니다. 그리고 적어도 지난 5년에서 10년 동안 우리가 본 것은 모든 다양한 고객들과 더 많은 협업을 하고 있다는 것입니다. 그들이 6개월마다 계획을 세울 때 말이죠. 지금 무엇이 있는가? 내가 무엇을 구축할 것인가? 그리고 그들이 프로젝트에서 작업하는 그 시점에 컴퓨팅을 위한 준비가 되어 있어야 합니다.</td></tr>
<tr><td>So given that there are things that are still short in supply, we are still serving with an amazing configuration Hopper 200 for our customers. That is an opportunity for them to begin some of the work that they are doing with an HGX system and they haven’t yet even touched a GPU yet, just because the demand for that has been so strong over. The folks have worked with us helping understand how they build out the datacenters. The datacenters often have already been procured. They just know they need to fit what will be inside of those. That's why you see us with two architectures.</td><td>따라서 여전히 공급이 부족한 제품들이 있는 상황에서, 저희는 고객들에게 놀라운 구성의 Hopper 200을 제공하고 있습니다. 이는 고객들이 HGX 시스템으로 작업을 시작할 수 있는 기회가 되며, 수요가 매우 강했기 때문에 아직 GPU조차 건드리지 못한 상황입니다. 저희와 함께 작업하는 분들은 데이터센터 구축 방법을 이해하는 데 도움을 주고 있습니다. 데이터센터는 이미 조달된 경우가 많으며, 그들은 단지 그 안에 무엇을 넣을지만 알면 되는 상황입니다. 이것이 저희가 두 가지 아키텍처를 보유하고 있는 이유입니다.</td></tr>
<tr><td>Additionally, as you know, we will do Vera Rubin going forward that again will be a discussion that we will have with customers that says here is a potential offerings. How can we help you think through what you may need going forward? Tim Arcuri<br><br>But I guess maybe it's a bit similar to the H100 and H200 where customers didn’t wait and that went all great. So I guess there is evidence out there where customers did not wait when you had a product come out quickly after those Vera products? Colette Kress<br><br>The customers are eager. Wait is a strong word, I would say, they call every day asking in terms of when they can see the compute and we are working feverishly for that new supply.</td><td>추가적으로, 아시다시피 앞으로 Vera Rubin을 출시할 예정인데, 이 역시 고객들과 논의할 사안이 될 것입니다. 잠재적인 제품 제공에 대해 설명하고, 향후 필요할 수 있는 것들에 대해 어떻게 생각해볼 수 있도록 도울 수 있는지에 대한 논의 말입니다.<br><br>**Tim Arcuri**<br><br>하지만 H100과 H200의 경우와 다소 비슷할 것 같은데, 당시 고객들은 기다리지 않았고 모든 것이 순조롭게 진행되었습니다. 따라서 Vera 제품들 이후 빠르게 출시되는 제품에 대해 고객들이 기다리지 않았던 사례가 있다고 볼 수 있지 않을까요?<br><br>**Colette Kress**<br><br>고객들은 매우 열망하고 있습니다. '기다린다'는 표현은 강한 표현이라고 생각하는데, 고객들은 언제 컴퓨팅 제품을 볼 수 있는지 매일 전화를 걸어 문의하고 있으며, 저희는 새로운 공급을 위해 열심히 작업하고 있습니다.</td></tr>
<tr><td>But what the importance is, is remember, this is a journey that's probably going to take place for two decades. Everybody will get onboard. Our architectures allows an end-to-end scaling approach for them to do whatever they need to in the world of accelerated computing and Ai. And we're a very strong candidate to help them, not only with that infrastructure, but also with the software. Tim Arcuri<br><br>Thank you. So I wanted to ask you the cash question. We actually talked about this last night. You've generated about $56 billion in the cash flow over the past four quarters. I heard you are generating about $120 billion in calendar ’25.</td><td>하지만 중요한 것은, 이것이 아마도 20년간 지속될 여정이라는 점을 기억해야 한다는 것입니다. 모든 기업들이 참여하게 될 것입니다. 우리의 아키텍처는 그들이 가속 컴퓨팅과 AI 분야에서 필요로 하는 모든 것을 수행할 수 있도록 엔드투엔드 확장 접근법을 제공합니다. 그리고 우리는 인프라뿐만 아니라 소프트웨어 측면에서도 그들을 도울 수 있는 매우 강력한 후보입니다.<br><br>팀 아르쿠리(Tim Arcuri)<br><br>감사합니다. 현금에 대한 질문을 드리고 싶습니다. 실제로 어젯밤에 이에 대해 이야기를 나눴는데요. 지난 4분기 동안 약 560억 달러의 현금흐름을 창출하셨습니다. 2025년 역년 기준으로는 약 1,200억 달러를 창출할 것으로 들었습니다.</td></tr>
<tr><td>And even if I assume that you buy back about $50 billion per year, you're going to end up with a $100 billion in cash at the end of next year and potentially $200 billion in cash at the end of 2026. These are obviously massive, massive numbers even Apple, which got to $100 billion in cash ended up working that down. How do you think about what you're going to do with the cash? Colette Kress<br><br>Our work in terms of our cash and our use of cash is some of the most important things that any company has to look at. We do spend with a great group of people, helping things through our strategy and our needs.</td><td>그리고 연간 약 500억 달러의 자사주 매입을 가정하더라도, 내년 말에는 1,000억 달러의 현금을, 그리고 2026년 말에는 잠재적으로 2,000억 달러의 현금을 보유하게 될 것입니다. 이는 분명히 엄청난, 엄청난 규모의 수치입니다. 심지어 1,000억 달러의 현금을 보유했던 애플조차도 결국 그 규모를 줄여나갔습니다. 이러한 현금을 어떻게 활용할 계획인지에 대해 어떻게 생각하고 계신가요?<br><br>콜레트 크레스:<br><br>현금과 현금 활용에 대한 우리의 업무는 어떤 회사든 살펴봐야 할 가장 중요한 사안 중 하나입니다. 우리는 우리의 전략과 필요사항을 통해 도움을 주는 훌륭한 인재들과 함께 지출하고 있습니다.</td></tr>
<tr><td>Your first thing that you're going to consider is what is that cash that we need for innovation and all sorts of support just our work in the scaling that we are doing. That's going to be the first pieces. But we are continuing and know that innovation and everything that we are doing in R&D is going to be an important part of that. Now we can do that from both learnings from companies. We can also think about that in terms of our work of bringing on great teams in some M&A form that they come onboard. That's a great opportunity for us to do and we will continue to work also in that area.</td><td>먼저 고려해야 할 것은 혁신과 현재 진행 중인 확장 작업을 지원하는 데 필요한 현금이 얼마인지입니다. 이것이 첫 번째 요소가 될 것입니다. 하지만 저희는 계속해서 혁신과 R&D에서 수행하고 있는 모든 활동이 그 중요한 부분이 될 것임을 알고 있습니다. 이제 저희는 기업들로부터의 학습을 통해 이를 수행할 수 있습니다. 또한 M&A 형태로 우수한 팀들을 영입하여 합류시키는 저희의 작업 측면에서도 생각해볼 수 있습니다. 이는 저희에게 훌륭한 기회이며, 해당 영역에서도 계속 작업해 나갈 것입니다.</td></tr>
<tr><td>Then it leads to thinking about new types of business models that we may want to add and focus on in new areas of AI. And the support that we can do not only for, let's just say, building out software, but building out full systems for others and we'll be investing in that. After we determine those types of investments, our work is, in terms of returning to shareholders, it always will be and our focus on that is a combination of share repurchases and dividends and you'll continue to see this, watch this very carefully. We're not a fan of excess cash. So we are going to watch this carefully and you'll continue for the next quarters. Tim Arcuri<br><br>Great. Thank you.</td><td>그러면 우리가 AI의 새로운 영역에서 추가하고 집중하고자 하는 새로운 유형의 비즈니스 모델에 대해 생각하게 됩니다. 그리고 소프트웨어 구축뿐만 아니라 다른 기업들을 위한 완전한 시스템 구축을 지원할 수 있는 부분에 투자할 예정입니다. 이러한 유형의 투자를 결정한 후, 주주 환원 측면에서 우리의 업무는 항상 그래왔듯이 자사주 매입과 배당의 조합에 중점을 두고 있으며, 여러분께서는 이를 계속해서 매우 주의 깊게 지켜보실 것입니다. 우리는 과도한 현금을 선호하지 않습니다. 따라서 이를 신중히 모니터링할 것이며, 향후 분기에도 계속 지켜봐 주시기 바랍니다.<br><br>Tim Arcuri<br><br>감사합니다.</td></tr>
<tr><td>As we talk about gross margin for a minute, you did say that gross margin comes down in the fiscal Q1 of next year as Blackwell ramps, you said it comes on to low 70s, which you then clarified as 71 through 72.5 on the call. But it comes back up after that and it comes back up to the mid-70s as you get to the end of the year. Can you talk about sort of how confident you are in that? And with Rubin coming after that, there are some people that think, “Well, gross margin will be under pressure once again, once Rubin begins to ramp.” So, can you talk about how confident you are that you can maintain mid-70s over time? Colette Kress<br><br>Okay.</td><td>잠시 매출총이익률에 대해 이야기해보겠습니다. 말씀하신 바로는 Blackwell이 증산되면서 내년 회계연도 1분기에 매출총이익률이 하락하여 70% 초반대로 떨어진다고 하셨는데, 통화에서 이를 71%에서 72.5% 사이로 구체화해 주셨습니다. 하지만 그 이후 다시 상승하여 연말까지 70% 중반대로 회복된다고 하셨습니다. 이에 대한 확신 정도는 어떤지 말씀해 주실 수 있나요? 그리고 그 이후 Rubin이 출시되면, 일부에서는 "Rubin이 증산을 시작하면 매출총이익률이 다시 압박을 받을 것"이라고 생각하고 있습니다. 따라서 장기적으로 70% 중반대를 유지할 수 있다는 확신이 어느 정도인지 말씀해 주실 수 있나요?<br><br>콜레트 크레스: 네.</td></tr>
<tr><td>So Blackwell is unique as we've discussed in terms of its different configurations and we're standing up quite many different ones that you are going to see go to market, even in this quarter. We're not just shipping one version. There's going to be several. So therefore the volume at this time is quite small. As we continue to scale this throughout the year, we will be able to improve the gross margins once we get into the scaling of all of our different system configurations that we have. When we think about going forward though and the Vera Rubin, little far out there to go through, we still have to run through an analysis in terms of the TCO and things that we would do.</td><td>따라서 블랙웰은 앞서 논의한 바와 같이 다양한 구성에서 독특한 특징을 가지고 있으며, 이번 분기에도 시장에 출시될 여러 가지 다른 구성들을 준비하고 있습니다. 저희는 단일 버전만 출하하는 것이 아닙니다. 여러 버전이 있을 예정입니다. 따라서 현재로서는 물량이 상당히 적습니다. 올해 내내 이를 지속적으로 확대해 나가면서, 저희가 보유한 모든 다양한 시스템 구성의 규모 확대에 진입하게 되면 총 마진을 개선할 수 있을 것입니다. 하지만 앞으로 베라 루빈을 고려할 때는 아직 검토하기에는 다소 먼 이야기이며, 여전히 TCO(총소유비용) 측면에서 분석을 진행해야 하고 저희가 해야 할 일들이 있습니다.</td></tr>
<tr><td>So we'll put that off in terms of a little later in terms of what we see. But I'd say, we're in a unique position right now just with Blackwell and what we're seeing. Tim Arcuri<br><br>And how have you been able to move gross margin up so much? Because when Hopper launched, I remember during the early phases of Hopper gross margin was in the mid-60s, and now you're going to end up in the mid-70s. So, how have you moved gross margin up so much? Colette Kress<br><br>Okay. There are many different things when we are determining the value that we have provided to customers. It's not just about performance. It's not just about performance of the chips.</td><td>따라서 저희가 보고 있는 상황에 대해서는 조금 나중에 말씀드리겠습니다. 하지만 현재 Blackwell과 저희가 보고 있는 상황을 고려할 때, 저희는 독특한 위치에 있다고 말씀드릴 수 있습니다.<br><br>**Tim Arcuri**<br><br>그리고 어떻게 매출총이익률을 그렇게 많이 끌어올릴 수 있었나요? Hopper가 출시되었을 때, Hopper 초기 단계에서 매출총이익률이 60% 중반대였던 것으로 기억하는데, 이제는 70% 중반대로 끝날 것 같습니다. 그렇다면 어떻게 매출총이익률을 그렇게 많이 향상시킬 수 있었나요?<br><br>**Colette Kress**<br><br>네. 저희가 고객에게 제공한 가치를 결정할 때 고려하는 다양한 요소들이 있습니다. 단순히 성능만의 문제가 아닙니다. 칩의 성능만의 문제가 아닙니다.</td></tr>
<tr><td>It is about the end-to-end solution and what the customer is able to do to find the lowest TCO for them to determine. That helps determine how we go to market and use a certain price of that piece. That TCO value is essentially looking at the full end-to-end. How would you complete the software? How would you complete your full data-center architecture? Would you need other teams? It's more than just looking at the different components. And it is not a situation where it’s the components and the cost plus model.</td><td>이는 엔드투엔드 솔루션과 고객이 자신들에게 가장 낮은 TCO를 찾기 위해 할 수 있는 것에 관한 내용입니다. 이것이 우리가 시장에 진출하는 방식과 해당 부분의 특정 가격을 사용하는 방법을 결정하는 데 도움이 됩니다. 그 TCO 가치는 본질적으로 완전한 엔드투엔드를 살펴보는 것입니다. 소프트웨어를 어떻게 완성할 것인가? 전체 데이터센터 아키텍처를 어떻게 완성할 것인가? 다른 팀들이 필요한가? 이는 단순히 서로 다른 구성요소들을 살펴보는 것 이상입니다. 그리고 이는 구성요소들과 비용 플러스 모델의 상황이 아닙니다.</td></tr>
<tr><td>So, because of that and because of the strong performance, the strong efficiency, and the best TCO that enables us a full TCO incorporating all of the software that we provide both inside of the systems and support them throughout their lifetime. Tim Arcuri<br><br>Got it. Can we talk about your Networking business? I get a lot of questions, it was down last quarter, it was expected to be up. And some people think that “Well, as you transition from InfiniBand to Ethernet that your position in networking is a little less strong.” So can you just talk about the Networking business and should we expect it to grow alongside of the compute business?</td><td>그래서 그런 이유로, 그리고 강력한 성능, 뛰어난 효율성, 그리고 시스템 내부에 제공하는 모든 소프트웨어와 전체 수명 기간 동안의 지원을 포함한 완전한 TCO를 가능하게 하는 최고의 TCO 때문입니다.<br><br>Tim Arcuri<br><br>알겠습니다. 네트워킹 사업에 대해 이야기해볼 수 있을까요? 많은 질문을 받고 있는데, 지난 분기에 감소했고 증가할 것으로 예상되었습니다. 그리고 일부 사람들은 "InfiniBand에서 Ethernet으로 전환하면서 네트워킹에서의 귀하의 포지션이 다소 약해진 것 아니냐"고 생각합니다. 그래서 네트워킹 사업에 대해 말씀해 주시고, 컴퓨트 사업과 함께 성장할 것으로 예상해야 하는지 알려주실 수 있나요?</td></tr>
<tr><td>Colette Kress<br><br>Our Networking business is one of the most important additions that we added when we went to a datacenter scale. The ability to think through, not just the time where the data, the work is being done at a data processing or the use of the compute and/or the GPU is essential to think through the Networking’s position inside of that datacenter. So we have two different offerings. We have InfiniBand and InfiniBand had tremendous success with many of the largest supercomputers in the world for decades. And that has been very important in terms of the size of data, the size of speed of data going through.</td><td>콜렛 크레스<br><br>우리의 네트워킹 사업은 데이터센터 규모로 확장할 때 추가한 가장 중요한 사업 중 하나입니다. 데이터 처리나 컴퓨트 및/또는 GPU 사용이 이루어지는 시점뿐만 아니라, 데이터센터 내에서 네트워킹의 위치를 종합적으로 고려하는 능력이 필수적입니다. 저희는 두 가지 다른 제품을 제공하고 있습니다. 인피니밴드(InfiniBand)가 있으며, 인피니밴드는 수십 년간 세계 최대 슈퍼컴퓨터들과 함께 엄청난 성공을 거두었습니다. 그리고 이는 데이터의 규모, 데이터 전송 속도 측면에서 매우 중요한 역할을 해왔습니다.</td></tr>
<tr><td>It had different views in terms of how to deal with the traffic that will be there. Ethernet, a great configuration that is the standard for many of the enterprises. But Ethernet was not built for AI. Ethernet was just built for the networking inside of datacenters. So we are taking some of the best of the breeds of what you see in terms of inter InfiniBand and creating Ethernet for AI. That allows customers now, both the choice between those. We can be full end-to-end systems with InfiniBand and now you have your choice in terms of what we do with Ethernet. Both of these things are a growth option for us. In terms of this last quarter, we had some timing issues.</td><td>트래픽 처리 방식에 대해서는 서로 다른 관점들이 있었습니다. 이더넷은 많은 기업들의 표준인 훌륭한 구성이지만, 이더넷은 AI를 위해 구축된 것이 아닙니다. 이더넷은 단지 데이터센터 내부의 네트워킹을 위해 구축된 것입니다. 그래서 저희는 인피니밴드에서 볼 수 있는 최고의 기술들을 일부 활용하여 AI용 이더넷을 만들고 있습니다. 이를 통해 고객들은 이제 두 가지 선택권을 갖게 됩니다. 저희는 인피니밴드로 완전한 엔드투엔드 시스템을 제공할 수 있고, 이제 이더넷으로도 선택의 여지를 드릴 수 있습니다. 이 두 가지 모두 저희에게는 성장 옵션입니다. 지난 분기의 경우, 저희는 일부 타이밍 이슈가 있었습니다.</td></tr>
<tr><td>But now, what you will see in terms of the continuation of our Networking will definitely grow. With our designs in terms of Networking with our compute, we have some of the strongest clusters that are being built and also using our Networking. That connection that we have done has been a very important part of the work that we've done since the acquisition of Mellanox. Folks do represent and understand our use of networking and how that can help their overall system as a whole. Tim Arcuri<br><br>Great. Can we talk about scaling of these large language models? There's been some articles written that Google and OpenAI are having a hard time to get better results out of these larger models.</td><td>하지만 이제 네트워킹 사업의 지속적인 성장을 확실히 보실 수 있을 것입니다. 컴퓨팅과 네트워킹 설계 측면에서, 저희는 네트워킹을 활용하여 구축되고 있는 가장 강력한 클러스터들 중 일부를 보유하고 있습니다. 저희가 구축한 이러한 연결성은 멜라녹스 인수 이후 진행해온 작업의 매우 중요한 부분이었습니다. 고객들은 저희의 네트워킹 활용법과 이것이 전체 시스템에 어떻게 도움이 될 수 있는지를 이해하고 인정하고 있습니다.<br><br>**팀 아쿠리(Tim Arcuri)**<br><br>좋습니다. 이러한 대규모 언어 모델의 스케일링에 대해 이야기해볼 수 있을까요? 구글과 OpenAI가 이러한 대형 모델에서 더 나은 결과를 얻는 데 어려움을 겪고 있다는 기사들이 나오고 있는데요.</td></tr>
<tr><td>But on the other hand, you had Meta on their earnings call and you had others like Anthropic saying that the scaling is of live and well. So can you just speak to that? I know that there's some nuances in post-training and of course, there's the test time difference with the – some of these new models from OpenAI. Is the scaling question something that investors should be thinking about? Colette Kress<br><br>When we look at what we are seeing in the size of clusters that are being built and the work that many of our customers are looking to do, the scaling laws that we see particularly in terms of training, they're still here.</td><td>하지만 한편으로는 Meta가 실적발표에서, 그리고 Anthropic과 같은 다른 회사들이 스케일링이 여전히 살아있고 잘 작동하고 있다고 말했습니다. 이에 대해 말씀해 주실 수 있나요? 포스트 트레이닝에서 일부 뉘앙스가 있고, 물론 OpenAI의 일부 새로운 모델들과 관련된 테스트 타임 차이도 있다는 것을 알고 있습니다. 스케일링 문제가 투자자들이 고려해야 할 사안인가요?<br><br>콜렛 크레스<br><br>우리가 구축되고 있는 클러스터의 규모와 많은 고객들이 수행하고자 하는 작업을 보면, 특히 트레이닝 측면에서 우리가 보고 있는 스케일링 법칙들은 여전히 유효합니다.</td></tr>
<tr><td>I think you will see more and more larger models and complex models in this next-generation of Blackwell. What that means is, there is this phase of post-training that's coming back with reinforcement learning that are truly looking for the human piece of it and also using in terms of synthetic data to fine-tune that models. Another way of saying that is training’s never done, and there's a lot of work that continues. But there's also been new skilling laws that is focused on the inferencing phase. If you recall, we are the largest inferencing provider that exist today. We do the most inferencing versus any other different types of configuration, why? it's very hard.</td><td>다음 세대 Blackwell에서는 점점 더 크고 복잡한 모델들을 보게 될 것이라고 생각합니다. 이것이 의미하는 바는, 강화학습을 통한 사후 훈련(post-training) 단계가 등장하고 있으며, 이는 진정으로 인간적 요소를 찾고 있고 또한 해당 모델들을 미세 조정하기 위해 합성 데이터를 활용하고 있다는 것입니다. 다시 말해서, 훈련은 결코 끝나지 않으며 계속해서 많은 작업이 이어집니다. 하지만 추론(inferencing) 단계에 초점을 맞춘 새로운 스케일링 법칙들도 등장했습니다. 기억하시겠지만, 우리는 현재 존재하는 가장 큰 추론 제공업체입니다. 우리는 다른 어떤 유형의 구성보다도 가장 많은 추론을 수행합니다. 왜냐하면 매우 어렵기 때문입니다.</td></tr>
<tr><td>And what we are seeing from a scaling, is an important part from the onset of Generative AI to now, more are looking in terms of the focus in terms of reasoning for deep thinking and taking the time to do that. That is still going to now require additional amount of compute and a compute that is able to do at the least amount of latency for that time that you will spend in terms of the reasoning factor of it. So we still see those scaling laws still being important and more and more new laws will be probably formed over the next decades. Tim Arcuri<br><br>You talk about a new and emerging piece of the demand picture, which is more in government-backed projects, Sovereign as we call them.</td><td>그리고 확장성 측면에서 우리가 보고 있는 것은, 생성형 AI 초기부터 지금까지 중요한 부분으로, 더 많은 기업들이 심층적 사고를 위한 추론과 그에 필요한 시간 투자에 초점을 맞추고 있다는 점입니다. 이는 여전히 추가적인 컴퓨팅 파워를 필요로 하며, 추론 과정에서 소요되는 시간 동안 최소한의 지연시간으로 처리할 수 있는 컴퓨팅 능력이 요구됩니다. 따라서 우리는 이러한 확장 법칙들이 여전히 중요하며, 향후 수십 년 동안 더 많은 새로운 법칙들이 형성될 것으로 보고 있습니다.<br><br>팀 아르쿠리(Tim Arcuri):<br><br>수요 전망에서 새롭게 부상하는 부분에 대해 말씀해 주셨는데, 이는 정부 지원 프로젝트, 즉 우리가 소버린(Sovereign) 프로젝트라고 부르는 분야에서 더 많이 나타나고 있습니다.</td></tr>
<tr><td>You said that you're going to do double-digit billion dollars this year in that - for those projects as a whole. Can you talk about some of the examples of where that demand is coming from? And sort of how to think about how big it could be? I kind of think of it as well maybe some of these larger projects in the Middle East could eventually be as large as a US BSP. So this could be a very large piece of demand and I am wondering how you sort of think about that you could get? Colette Kress<br><br>So Sovereign AI has been a very interesting part of what we've seen in terms of Generative AI.</td><td>콜레트 크레스<br><br>소버린 AI는 생성형 AI와 관련하여 우리가 목격한 매우 흥미로운 부분이었습니다.<br><br>---<br><br>**질문 (번역):**<br>올해 해당 프로젝트들 전체적으로 수백억 달러 규모의 매출을 달성할 것이라고 말씀하셨는데, 그러한 수요가 어디서 나오고 있는지 몇 가지 사례를 말씀해 주실 수 있나요? 그리고 그 규모가 얼마나 클 수 있는지에 대해 어떻게 생각해야 할까요? 중동의 일부 대규모 프로젝트들이 결국 미국 BSP만큼 클 수도 있다고 생각하는데, 이는 매우 큰 수요가 될 수 있고, 귀하께서 이를 어떻게 생각하고 계신지 궁금합니다.</td></tr>
<tr><td>Very simply said, what they saw here that we had in the US, every country, every country that has a duty to see when I want that too, okay? And they want a model, a foundational model in their own language, in their own culture to support their nation. As they see the importance of what AI will be in the next decades going forward. So, the amount of different countries that we are working with or even working in certain regions as you focused, is a very large part of our work that we are doing, spending around globally of AI. It is not just a West Coast of the US. It is really taking part around the world. Not all of it and even only parts of it are a government funding.</td><td>아주 간단히 말씀드리면, 미국에서 우리가 보유한 것을 다른 나라들이 보고 있고, 모든 국가, 의무를 가진 모든 국가들이 그것을 원하고 있습니다. 그들도 자국의 언어와 문화로 된, 자국을 지원할 수 있는 모델, 즉 파운데이션 모델을 원하고 있습니다. 향후 수십 년간 AI가 얼마나 중요할지를 그들이 인식하고 있기 때문입니다. <br><br>따라서 우리가 협력하고 있거나 특정 지역에서 작업하고 있는 다양한 국가들의 수는, 우리가 전 세계적으로 AI 확산을 위해 수행하고 있는 업무의 매우 큰 부분을 차지합니다. 이는 단순히 미국 서부 지역에만 국한된 것이 아닙니다. 실제로 전 세계적으로 참여하고 있습니다. 모든 것이 정부 자금 지원은 아니며, 일부만이 정부 자금 지원을 받고 있습니다.</td></tr>
<tr><td>Many of them are looking at very large companies that will start a new type of regional CSPs that they're able to support accelerated computing and may have a set of tenets. And we’ll likely have a foundational model with them in order to support the enterprises. You've seen our talk in terms of what is happening in Japan. There is an area where SoftBank is very interested in building a very, very sizable model. You see, in terms of India, and many of the CSPs there working in terms of what they will incorporate as well. That moves all the way to the Europe. It moves to the Nordics and it’s also very important part in the Asia-pacific area.</td><td>이들 중 다수는 가속 컴퓨팅을 지원할 수 있는 새로운 유형의 지역 CSP(클라우드 서비스 제공업체)를 시작할 매우 대규모 기업들을 검토하고 있으며, 일련의 원칙을 가지고 있을 것입니다. 그리고 기업들을 지원하기 위해 이들과 함께 파운데이션 모델을 보유하게 될 가능성이 높습니다. 일본에서 일어나고 있는 상황에 대한 저희의 논의를 보셨을 것입니다. 소프트뱅크가 매우 대규모 모델 구축에 큰 관심을 보이고 있는 영역이 있습니다. 인도의 경우에도 보시면, 그곳의 많은 CSP들이 무엇을 통합할지에 대해 작업하고 있습니다. 이는 유럽 전체로 확산되고 있습니다. 북유럽 지역으로도 확산되고 있으며, 아시아-태평양 지역에서도 매우 중요한 부분입니다.</td></tr>
<tr><td>So this will continue some parts of it that you want to think about is the next-generation of what we saw in terms of supercomputing in each of those countries. You will see from GDP what they need to do for AI and the Sovereign AI. Tim Arcuri<br><br>Great. Can you talk about your Software business for just a minute or so? You had said that it's going to be crossing over the $2 billion a year runrate exiting this year. If I sort of do some back of the envelope of math and I try to figure out how many of your GPUs are you directly monetizing on for your modification of those.</td><td>이는 각 국가에서 슈퍼컴퓨팅 측면에서 우리가 본 차세대 기술의 일부가 계속될 것입니다. GDP 관점에서 그들이 AI와 소버린 AI를 위해 무엇을 해야 하는지 보실 수 있을 것입니다.<br><br>Tim Arcuri<br><br>좋습니다. 소프트웨어 사업에 대해 잠깐 말씀해 주실 수 있나요? 올해 말 기준으로 연간 20억 달러 런레이트를 넘어설 것이라고 말씀하셨는데요. 제가 대략적으로 계산해보고 귀하의 GPU 중 얼마나 많은 수를 직접 수익화하고 계신지 파악해보려고 합니다.</td></tr>
<tr><td>I get something like 10% attach rate, where you're roughly directly licensing 10% of your So can you talk about sort of how you think about the attach rate, and how and how successful you are and directly licensing software for your GPUs? Colette Kress<br><br>Yeah. Our software platform is so essential to many of our enterprises and many of our regional CSPs, our future AI factories, our AI foundations work that we're doing. Why is that the case?</td><td>저는 대략 10% 정도의 부착률(attach rate)을 보고 있는데, 이는 GPU에 대해 직접 라이선싱하는 비율이 대략 10% 정도라는 의미입니다. 부착률에 대해 어떻게 생각하시는지, 그리고 GPU용 소프트웨어 직접 라이선싱에서 얼마나 성공적인지에 대해 말씀해 주실 수 있나요?<br><br>콜레트 크레스(Colette Kress):<br><br>네. 저희 소프트웨어 플랫폼은 많은 기업들과 지역 CSP(클라우드 서비스 제공업체)들, 미래의 AI 팩토리들, 그리고 저희가 진행하고 있는 AI 파운데이션 작업에 매우 필수적입니다. 왜 그런지 말씀드리겠습니다.</td></tr>
<tr><td>What you have is a situation where that first steps of understanding how to move and get started on AI, we have thousands of different applications, as well as CUDA libraries and CUDA work that we have done for each industry, as well as each major workload within those industries. Your enterprises have to have that piece, not only for the work that they need to do to do on their own, but their work that they need to do to support the infrastructure in that datacenter. So, we are building that for them and in many cases, your enterprise customers will have a very strong attachment to that software as they will need that for the work that they're doing.</td><td>여러분이 직면한 상황은 AI를 어떻게 활용하고 시작할지에 대한 첫 번째 단계를 이해하는 것인데, 저희는 수천 개의 다양한 애플리케이션과 CUDA 라이브러리, 그리고 각 산업별로, 또한 해당 산업 내 주요 워크로드별로 저희가 개발한 CUDA 작업들을 보유하고 있습니다. 기업 고객들은 자체적으로 수행해야 하는 작업뿐만 아니라 데이터센터 내 인프라를 지원하기 위해 필요한 작업을 위해서도 이러한 요소들을 반드시 갖춰야 합니다. 따라서 저희는 이를 위해 구축하고 있으며, 많은 경우 기업 고객들은 자신들이 수행하는 작업에 필요하기 때문에 해당 소프트웨어에 대해 매우 강한 의존성을 갖게 될 것입니다.</td></tr>
<tr><td>Those that have very, very large, software teams and as I have been self-building for several decades is different. But as you can imagine the world, can't go back to building all of those software engineers. And so we have spent a very quality amount of time helping a lot of enterprises. It's working with the enterprises from the onset of them choosing what type of compute they're doing to the delivery to helping them with their models and setting up all of their different apps and all of the overall inferencing where there are the entire way. So, it's more than just the actual software in there. That software also comes with true support and services from the company.</td><td>매우 대규모의 소프트웨어 팀을 보유하고 있으며 수십 년간 자체 구축을 해온 기업들의 경우는 다릅니다. 하지만 아시다시피 전 세계가 모든 소프트웨어 엔지니어를 다시 구축하는 방향으로 돌아갈 수는 없습니다. 따라서 저희는 많은 기업들을 지원하는 데 상당한 시간을 투자해왔습니다. 기업들이 어떤 유형의 컴퓨팅을 선택할지 결정하는 초기 단계부터 배포, 모델 지원, 다양한 애플리케이션 설정, 그리고 전체적인 추론 과정에 이르기까지 전 과정에 걸쳐 기업들과 협력하고 있습니다. 따라서 이는 단순한 소프트웨어 그 자체를 넘어서는 것입니다. 이 소프트웨어에는 회사의 진정한 지원과 서비스도 함께 제공됩니다.</td></tr>
<tr><td>Tim Arcuri<br><br>So we looked just the enterprise market, your attach rate could be actually quite a bit higher than that? Colette Kress<br><br>Absolutely. That’s correct. Tim Arcuri<br><br>Got it. Great. We all talk about datacentre, but inference at the Edge is going to become a much bigger theme. So can you talk about your position at the Edge? You have a large installed base in PC. That should play pretty well for you and you have Omniverse. Robotics is a huge theme. So can you talk about some of your offerings and how we should think of you as a player at the Edge? Colette Kress<br><br>Yes, Edge Computing, Edge AI, very similar will likely go hand-in-hand and be there.</td><td>Tim Arcuri<br><br>그래서 기업 시장만 보면, 실제로 귀하의 어태치 레이트(attach rate)가 그보다 훨씬 높을 수 있다는 말씀이신가요?<br><br>Colette Kress<br><br>맞습니다. 그렇습니다.<br><br>Tim Arcuri<br><br>알겠습니다. 훌륭합니다. 우리 모두 데이터센터에 대해 이야기하지만, 엣지에서의 추론(inference)이 훨씬 더 큰 테마가 될 것입니다. 그래서 엣지에서의 귀하의 포지션에 대해 말씀해 주실 수 있나요? PC에서 대규모 설치 기반을 보유하고 계시죠. 이는 귀하에게 꽤 유리하게 작용할 것이고, 옴니버스(Omniverse)도 있습니다. 로보틱스는 거대한 테마입니다. 그래서 귀하의 일부 제품들과 엣지 플레이어로서 귀하를 어떻게 생각해야 하는지에 대해 말씀해 주실 수 있나요?<br><br>Colette Kress<br><br>네, 엣지 컴퓨팅, 엣지 AI는 매우 유사하며 함께 발전하고 그곳에 존재할 가능성이 높습니다.</td></tr>
<tr><td>What that means is, you will have factories. You will see folks in their datacenter collecting data and providing that data to go into many of the overall Edge appliances, Edge appliances that you may think, the cars. The cars that are autonomous-driven. The next phase will likely be in terms of the robotics. A very, very big industry where the data and the learning is happening back in the datacenter and inside of those different devices includes our capabilities, to support them. It's an important industry. We do know the - I would say the datacenter piece of that is a very large market and very important for what we will see going forward.</td><td>이것이 의미하는 바는, 여러분이 공장들을 보게 될 것이라는 점입니다. 데이터센터에서 데이터를 수집하고 그 데이터를 다양한 전체 엣지 어플라이언스로 제공하는 사람들을 보게 될 것입니다. 여러분이 생각할 수 있는 엣지 어플라이언스, 즉 자동차들 말입니다. 자율주행 자동차들 말이죠. 다음 단계는 로보틱스 측면에서 나타날 가능성이 높습니다. 데이터와 학습이 데이터센터에서 그리고 이러한 다양한 디바이스 내부에서 일어나는 매우, 매우 큰 산업이며, 이들을 지원하기 위한 우리의 역량이 포함되어 있습니다. 이는 중요한 산업입니다. 우리는 - 이 중에서 데이터센터 부분이 매우 큰 시장이며 앞으로 우리가 보게 될 것에 있어 매우 중요하다는 점을 알고 있습니다.</td></tr>
<tr><td>That incorporates even a new set of software that we're doing. As, you know, we're doing the software for autonomous vehicles that will come to market later in this next calendar year. Additionally, when you think about the work that we can do inside of the robotics and also from that software and the work that we can do with many of the factories with Omniverse and the overall layout of how that will work. So, these are very strong areas of focus even outside of just a standard datacentre. But yes, Edge Computing will be an important piece too. Tim Arcuri<br><br>Great. Can we talk just for a minute about inference versus training? You have been saying that inference is about 40% of your revenue.</td><td>이는 우리가 개발하고 있는 새로운 소프트웨어 세트까지 포함하는 것입니다. 아시다시피, 우리는 다음 연도 후반에 시장에 출시될 자율주행차용 소프트웨어를 개발하고 있습니다. 또한 로보틱스 분야에서 할 수 있는 작업과 해당 소프트웨어로부터, 그리고 Omniverse를 통해 많은 공장들과 함께 할 수 있는 작업 및 이것이 어떻게 작동할지에 대한 전반적인 레이아웃을 생각해보면 말입니다. 따라서 이러한 영역들은 일반적인 데이터센터를 넘어서는 매우 강력한 집중 분야입니다. 하지만 네, 엣지 컴퓨팅도 중요한 부분이 될 것입니다.<br><br>Tim Arcuri<br><br>좋습니다. 추론 대 훈련에 대해 잠시 이야기해볼 수 있을까요? 추론이 매출의 약 40%를 차지한다고 말씀하셨는데요.</td></tr>
<tr><td>Can you talk about how you see that evolving? Colette Kress<br><br>It is about 40%, when we had communicated that we start thinking through what we are seeing the use cases for what they're doing. We see a lot of time spent in terms of the inferencing. And this is even before you were seeing a lot of the Generative AI applications that are still in the worst to be put out there. So, with the recommend - recommender engines, that is a very significant part of the inferencing today. So our growth of that 40% will likely be seen as we move forward. But as I discussed earlier, we are still the largest in terms of inferencing.</td><td>콜렛 크레스<br><br>약 40%입니다. 저희가 고객들의 사용 사례를 살펴보며 분석한 결과를 말씀드린 바 있는데, 추론(inferencing)에 상당한 시간이 소요되고 있음을 확인했습니다. 이는 아직 출시되지 않은 많은 생성형 AI 애플리케이션들이 나오기 전의 상황입니다. 따라서 추천 엔진(recommender engines)이 현재 추론 작업의 매우 중요한 부분을 차지하고 있습니다. 앞으로 나아가면서 이 40%의 성장을 지속적으로 볼 수 있을 것으로 예상됩니다. 하지만 앞서 말씀드린 바와 같이, 저희는 여전히 추론 분야에서 가장 큰 점유율을 차지하고 있습니다.</td></tr>
<tr><td>And when we think about the Blackwell architecture, particularly the GB200, NVL that is an important configuration that is 30X Improvement in terms of inferencing performance from our current generation. That is such an important piece for many of the customers. They will likely use at the very onset building, what they need for their foundational model. But that important part of inferencing going forward with Blackwell is - has been very well received by many of our customers. Tim Arcuri<br><br>Great. And then, you talked about some constraints on Blackwell, and it sounds like they're going to go away maybe mid-‘25 that they begin to ease. Can you talk about what some of those are?</td><td>그리고 Blackwell 아키텍처, 특히 GB200, NVL에 대해 생각해보면, 이는 현재 세대 대비 추론 성능에서 30배 개선을 보여주는 중요한 구성입니다. 이는 많은 고객들에게 매우 중요한 요소입니다. 고객들은 초기에 파운데이션 모델에 필요한 것을 구축하는 데 이를 활용할 가능성이 높습니다. 하지만 향후 Blackwell과 함께하는 추론의 중요한 부분은 많은 고객들로부터 매우 좋은 반응을 얻고 있습니다.<br><br>Tim Arcuri<br><br>좋습니다. 그리고 Blackwell의 일부 제약사항에 대해 말씀하셨는데, 25년 중반경에 완화되기 시작할 것 같다고 들렸습니다. 그러한 제약사항들이 무엇인지 말씀해 주실 수 있나요?</td></tr>
<tr><td>And maybe is that right to assume that they do sort of begin to go away in the middle of ‘25<br><br>Colette Kress<br><br>When we think through the building of Blackwell and the designing and working with our customers on the configuration, the demand Cane's Fast and Furious in terms of what demand is exceptional. And we are working with a tremendous set of partners. We talk with our suppliers each and every day to help them. So right now, yes, we need to scale to build enough Blackwell for what we see in the demand in front of us. And we are probably going to be supply constrained pretty much through the first parts of the new fiscal year. When you say in terms of where there is constraint?</td><td>그리고 혹시 그런 제약들이 25년 중반쯤부터 해소되기 시작한다고 가정하는 것이 맞을까요?<br><br>**Colette Kress**<br><br>Blackwell 구축과 설계, 그리고 고객들과의 구성 작업을 진행하면서 생각해보면, 수요가 정말 빠르고 격렬합니다. 수요가 정말 예외적인 상황입니다. 그리고 저희는 엄청난 파트너들과 함께 작업하고 있습니다. 저희는 공급업체들과 매일 대화하며 그들을 지원하고 있습니다. 따라서 현재로서는, 네, 저희 앞에 보이는 수요에 맞춰 충분한 Blackwell을 구축하기 위해 규모를 확대해야 합니다. 그리고 저희는 아마도 새 회계연도 초반 내내 공급 제약을 받을 것으로 보입니다. 어디에 제약이 있는지에 대해 말씀하시는 건가요?</td></tr>
<tr><td>It depends in terms of the configurations, but some of the challenges that you have are working again in terms of the co-op space. So the work that you need to do in terms of the different configurations and all of the work that we do in terms of the Networking those switching to get that right. Depending on those configurations that can be supply constrained. But we will have right out of the gate in terms of this quarter, we are on track to ship Blackwell. Blackwell is doing just fine and we're very excited to bring multiple configurations to our customers this quarter. Tim Arcuri<br><br>Well, I think it's going to be an amazing year next year for sure. So, anyway, thank you, Colette.</td><td>구성에 따라 다르지만, 몇 가지 과제들이 있습니다. 특히 co-op 공간에서 작업할 때 발생하는 문제들이죠. 다양한 구성에 대한 작업과 네트워킹, 스위칭을 올바르게 구현하기 위한 모든 작업들이 필요합니다. 이러한 구성에 따라 공급 제약이 있을 수 있습니다. 하지만 이번 분기부터 바로 Blackwell 출하 계획대로 진행하고 있습니다. Blackwell은 순조롭게 진행되고 있으며, 이번 분기에 고객들에게 다양한 구성을 제공할 수 있게 되어 매우 기대하고 있습니다.<br><br>Tim Arcuri: 내년은 분명히 놀라운 한 해가 될 것 같습니다. 어쨌든, Colette, 감사합니다.</td></tr>
<tr><td>Believe you are appreciated. Colette Kress<br><br>Yes. Okay. Bye.</td><td>감사합니다. 콜레트 크레스<br><br>네. 알겠습니다. 안녕히 계세요.</td></tr>
    </table>
    <h3>📌 요약</h3>
    <p style="background:#f0f0f0; padding:15px; border-left: 5px solid #333;">• 주요 실적/전망:<br>- 블랙웰(Blackwell) 아키텍처가 2024년 1분기 출시 예정이며, 공급 제약은 2025년 중반까지 지속될 전망<br>- 그로스마진은 블랙웰 초기 출하로 71-72.5%대로 하락했다가 연말에는 중반 70%대로 회복 예상<br>- 소프트웨어 사업 연간 매출이 20억 달러 규모로 성장 중<br><br>• 수요 동향:<br>- 데이터센터/AI 수요는 여전히 강세이며 공급 부족 상태 지속<br>- 추론(Inference) 부문이 전체 매출의 약 40% 차지하며 성장세<br>- 글로벌 정부/기업들의 자국 AI 구축 수요가 새로운 성장 동력으로 부상<br><br>• 리스크/기회 요인:<br>- 블랙웰 초기 생산에 따른 마진 압박이 있으나 장기적으로는 회복 전망<br>- 엣지 컴퓨팅, 로보틱스 등 신규 시장 진출로 성장 기회 확대<br>- 현금 보유고 급증에 따른 효율적 자본 배분이 과제로 대두</p>
    <hr style="margin:50px 0;">
    

    <h2>❓ Q&A</h2>
    <table style="width:100%; border-collapse:collapse; margin-bottom: 40px;">
        <tr>
            <th style="width:50%; border-bottom: 2px solid #333;">Original</th>
            <th style="width:50%; border-bottom: 2px solid #333;">Translation</th>
        </tr>
        <tr><td>Question-and-Answer Session</td><td>질의응답 세션</td></tr>
    </table>
    <h3>📌 요약</h3>
    <p style="background:#f0f0f0; padding:15px; border-left: 5px solid #333;">I don't see any transcript provided to summarize. Please share the earnings call transcript you'd like me to analyze, and I'll provide a clear 3-5 bullet point summary in Korean focusing on:<br><br>- 주요 재무 지표<br>- 가이던스 업데이트<br>- 경영진의 톤<br>- 잠재적 리스크와 강점</p>
    <hr style="margin:50px 0;">
    
</body></html>