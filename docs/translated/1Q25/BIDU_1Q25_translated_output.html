<!DOCTYPE html>
<html><head><meta charset="UTF-8">
<title>Earnings Call 번역</title>
<style>
    body { font-family: Arial; margin: 40px; background-color: #fdfdfd; }
    h1 { text-align: center; }
    h2 { margin-top: 50px; color: #003366; }
    h3 { color: #333; }
    table { border: 1px solid #ddd; width: 100%; border-collapse: collapse; }
    th { background: #f0f0f0; padding: 10px; border-bottom: 2px solid #ccc; }
    td { padding: 10px; border-bottom: 1px dotted #ccc; vertical-align: top; }
    p { line-height: 1.6; }
    hr { margin: 50px 0; border: none; border-top: 1px solid #ccc; }
    .back-button {
        display: inline-block;
        background-color: #5f5f5f;
        color: white;
        padding: 10px 16px;
        border-radius: 6px;
        text-decoration: none;
        font-weight: 500;
        box-shadow: 0 2px 6px rgba(0,0,0,0.1);
        margin-bottom: 30px;
    }
</style>
</head><body>
<a href="../../index.html" class="back-button">←</a>
<h1>📄 Earnings Call Transcript 번역 결과</h1>

    <h2>📊 Presentation</h2>
    <table style="width:100%; border-collapse:collapse; margin-bottom: 40px;">
        <tr>
            <th style="width:50%; border-bottom: 2px solid #333;">Original</th>
            <th style="width:50%; border-bottom: 2px solid #333;">Translation</th>
        </tr>
        <tr><td>Baidu, Inc. (NASDAQ:BIDU) Q1 2025 Earnings Conference Call May 21, 2025 8:00 AM ET<br><br>Company Participants<br><br>Juan Lin - Director, IR<br>Robin Li - Co-Founder & CEO<br>Junjie He - Interim CFO<br>Dou Shen - EVP<br><br>Conference Call Participants<br><br>Alicia Yap - Citigroup<br>Lincoln Kong - Goldman Sachs<br>Alex Yao - JPMorgan<br>Gary Yu - Morgan Stanley<br>Miranda Zhuang - Bank of America Securities<br>Wei Xiong - UBS<br>Thomas Chong - Jefferies<br><br>Operator<br><br>Hello, and thank you for standing by, for Baidu's First Quarter 2025 Earnings Conference Call. At this time, all participants are in a listen-only mode. After management's prepared remarks, there will be a question-and-answer session. Today's conference is being recorded.</td><td>바이두 주식회사(나스닥: BIDU) 2025년 1분기 실적발표 컨퍼런스콜<br>2025년 5월 21일 오전 8시 (미국 동부시간)<br><br>참석자<br><br>회사 측<br>Juan Lin - IR 디렉터<br>Robin Li - 공동창업자 겸 CEO<br>Junjie He - 임시 CFO<br>Dou Shen - EVP<br><br>컨퍼런스콜 참가 애널리스트<br>Alicia Yap - 시티그룹<br>Lincoln Kong - 골드만삭스<br>Alex Yao - JP모건<br>Gary Yu - 모건스탠리<br>Miranda Zhuang - 뱅크오브아메리카 증권<br>Wei Xiong - UBS<br>Thomas Chong - 제프리스<br><br>진행자<br><br>안녕하십니까. 바이두의 2025년 1분기 실적발표 컨퍼런스콜에 참석해 주셔서 감사합니다. 현재 모든 참가자는 청취 전용 모드로 접속되어 있습니다. 경영진의 발표 이후에는 질의응답 시간이 이어질 예정입니다. 오늘 컨퍼런스는 녹음될 예정입니다.</td></tr>
<tr><td>If you have any objections, you may disconnect at this time. I would now like to turn the meeting over to your host for today's conference, Juan Lin, Baidu's Director of Investor Relations. Juan Lin<br><br>Hello, everyone, and welcome to Baidu's first quarter 2025 earnings conference call. Baidu's earnings release was distributed earlier today and you can find a copy on our website, as well as on Newswire services. On the call today, we have Robin Li, our Co-Founder and CEO; Julius Rong Luo, our EVP in-charge of Baidu Mobile Ecosystem Group, MEG; Dou Shen, our EVP in-charge of Baidu AI Cloud Group, ACG; and Jackson Junjie He, our Interim CFO.</td><td>반대하시는 분들은 지금 전화를 끊으셔도 좋습니다. 지금부터 오늘 컨퍼런스의 진행을 바이두의 투자자 관계 이사인 Juan Lin에게 넘기도록 하겠습니다. Juan Lin입니다.<br><br>안녕하세요, 바이두의 2025년 1분기 실적발표 컨퍼런스콜에 오신 것을 환영합니다. 바이두의 실적 보도자료는 오늘 일찍 배포되었으며, 당사 웹사이트와 뉴스와이어 서비스에서 확인하실 수 있습니다. 오늘 컨퍼런스콜에는 Robin Li 공동창업자 겸 CEO, 바이두 모바일 생태계 그룹(MEG)을 담당하는 Julius Rong Luo 수석부사장, 바이두 AI 클라우드 그룹(ACG)을 담당하는 Dou Shen 수석부사장, 그리고 Jackson Junjie He 임시 최고재무책임자가 참석해 있습니다.</td></tr>
<tr><td>After our prepared remarks, we will hold a Q&A session. Please note that the discussion today will contain forward-looking statements made under the Safe Harbor provisions of the U.S. Credit (ph) Securities Litigation Reform Act of 1995. Forward-looking statements are subject to risks and uncertainties that may cause actual results to differ materially from our current expectations. For detailed discussions of these risks and uncertainties, please refer to our latest Annual Report and other filings with SEC and Hong Kong Stock Exchange. Baidu does not undertake any obligation to update any forward-looking statements except as required under applicable law.</td><td>준비된 발표 이후에는 질의응답 시간을 가질 예정입니다. 오늘 논의되는 내용에는 1995년 미국 증권소송개혁법의 면책조항(Safe Harbor provisions)에 의거한 미래예측진술이 포함되어 있음을 알려드립니다. 미래예측진술은 리스크와 불확실성의 영향을 받으며, 이로 인해 실제 결과가 현재의 예상과 크게 다를 수 있습니다. 이러한 리스크와 불확실성에 대한 자세한 논의는 당사의 최신 연차보고서 및 미국 증권거래위원회(SEC)와 홍콩증권거래소에 제출된 기타 공시 자료를 참고하시기 바랍니다. 바이두는 관련 법률에서 요구하는 경우를 제외하고 미래예측진술을 업데이트할 의무가 없습니다.</td></tr>
<tr><td>Our earnings press release and this call include discussions of certain unaudited non-GAAP financial measures. Our press release contains a reconciliation of the unaudited non-GAAP measures to the unaudited most directly comparable GAAP measures, and is available on our IR website at ir.baidu.com. As a reminder, this conference will be recorded. In addition, a webcast of this conference call will be available on Baidu's IR website. I will now turn the call over to our CEO, Robin. Robin Li<br><br>Hello, everyone. We kicked-off 2025 with a solid start. In the first quarter, Baidu Core’s total revenue reached RMB25.5 billion, representing a 7% year-over-year increase.</td><td>당사의 실적 보도자료와 본 컨퍼런스콜에서는 비감사 기준 비(非)GAAP 재무지표에 대해 논의합니다. 보도자료에는 비감사 기준 비GAAP 지표와 이에 직접적으로 대응되는 비감사 기준 GAAP 지표 간의 조정내역이 포함되어 있으며, ir.baidu.com의 IR 웹사이트에서 확인하실 수 있습니다. 참고로 본 컨퍼런스는 녹음될 예정입니다. 또한 본 컨퍼런스콜의 웹캐스트는 바이두 IR 웹사이트에서 시청하실 수 있습니다. 이제 로빈 CEO께 마이크를 넘기겠습니다. 로빈 리입니다.<br><br>안녕하십니까, 여러분. 저희는 2025년을 견실하게 시작했습니다. 1분기 바이두 코어의 총 매출은 255억 위안을 기록하며 전년 동기 대비 7% 증가했습니다.</td></tr>
<tr><td>The growth was primarily attributable to the robust performance of our AI Cloud business. In Q1, AI Cloud revenue reached RMB6.7 billion, increased by 42% year-over-year, representing a significant acceleration for our cloud business. Such performance reinforces the widespread market recognition of our distinctive AI capabilities, underpinned by our unique four layer AI architecture, while affirming the ongoing demand for our full-stack end-to-end AI products and solutions. Notably, AI Cloud accounted for 26% of Baidu Core revenue, up from 20% a year ago, reflecting the growing significance of our AI Cloud business within our business portfolio.</td><td>이러한 성장은 주로 당사의 AI 클라우드 사업부의 견실한 실적에 기인했습니다. 1분기 AI 클라우드 매출은 67억 위안을 기록하며 전년 동기 대비 42% 증가했고, 이는 당사의 클라우드 사업이 크게 가속화되었음을 보여줍니다. 이러한 실적은 당사만의 차별화된 4계층 AI 아키텍처를 기반으로 한 독보적인 AI 역량에 대한 시장의 광범위한 인정을 반영하며, 동시에 당사의 풀스택 엔드투엔드 AI 제품 및 솔루션에 대한 지속적인 수요를 확인시켜 주었습니다. 특히 주목할 만한 점은 AI 클라우드가 바이두 코어 매출에서 차지하는 비중이 전년도 20%에서 26%로 증가했다는 것이며, 이는 당사의 사업 포트폴리오 내에서 AI 클라우드 사업의 중요성이 증가하고 있음을 보여줍니다.</td></tr>
<tr><td>Throughout the first quarter, amid rapid evolution across the AI landscape, advancing our AI capabilities remains our core priority. We have accelerated the iteration of our foundation models, allowing us to maintain our leading position as one of the top players in this dynamic field. In March, we released ERNIE 4.5 and ERNIE X1. ERNIE 4.5 is our first flagship model with multimodal capabilities, and it excels at understanding, analyzing and processing multimodal content precisely. ERNIE X1, our first reasoning model brings advanced reasoning capabilities with best-in-class function calling, tackling complex problems with extended chains (ph) of thought.</td><td>1분기 동안 AI 분야 전반에 걸친 급속한 발전 속에서, AI 역량 강화는 당사의 핵심 우선순위로 유지되었습니다. 당사는 기반 모델의 반복 개발을 가속화하여, 이 역동적인 분야에서 최상위 기업 중 하나로서의 선도적 위치를 유지할 수 있었습니다. 3월에는 ERNIE 4.5와 ERNIE X1을 출시했습니다. ERNIE 4.5는 멀티모달 기능을 갖춘 당사의 첫 번째 플래그십 모델로, 멀티모달 콘텐츠를 정확하게 이해하고 분석하며 처리하는 데 탁월한 성능을 보입니다. 당사의 첫 추론 모델인 ERNIE X1은 최고 수준의 함수 호출 기능을 갖추고 있으며, 확장된 사고 체인을 통해 복잡한 문제를 해결할 수 있는 고급 추론 기능을 제공합니다.</td></tr>
<tr><td>Notably, both ERNIE 4.5 and ERNIE X1 come with highly competitive pricing. Furthermore, in April, at Baidu Create 2025, we unveiled their upgraded version, ERNIE 4.5 Turbo and ERNIE X1 Turbo, which feature -- enhanced performance and dramatically lower pricing, making them among the most cost effective options on the market. Our rapid and continuous cost reductions stem from our unique four layer AI architecture and full-stack capabilities. This distinctive architecture enables end-to-end optimization at every layer, spanning infrastructure, framework, models and applications, allowing us to holistically enhance both performance and efficiency.</td><td>주목할 만한 점은 ERNIE 4.5와 ERNIE X1 모두 매우 경쟁력 있는 가격으로 제공된다는 것입니다. 더욱이 4월 바이두 크리에이트 2025 행사에서 저희는 이들의 업그레이드 버전인 ERNIE 4.5 터보와 ERNIE X1 터보를 공개했는데, 이는 성능이 향상되었을 뿐만 아니라 가격이 대폭 인하되어 시장에서 가장 비용 효율적인 옵션 중 하나가 되었습니다. 저희의 신속하고 지속적인 비용 절감은 독특한 4계층 AI 아키텍처와 풀스택 역량에서 비롯됩니다. 이러한 차별화된 아키텍처는 인프라스트럭처, 프레임워크, 모델, 애플리케이션을 아우르는 모든 계층에서 엔드투엔드 최적화를 가능하게 하여, 성능과 효율성을 전체적으로 향상시킬 수 있게 합니다.</td></tr>
<tr><td>As a result, we deliver superior performance and stability at highly competitive pricing, positioning us to offer industry leading foundation models and AI solutions with exceptional price performance ratios. With stronger capabilities and lower pricing, foundation models are becoming increasingly accessible, enabling diverse applications at scale and unlocking significant value across industries. Beyond the model iterations, we are also taking steps to make AI more open and collaborative.</td><td>그 결과, 당사는 매우 경쟁력 있는 가격으로 우수한 성능과 안정성을 제공하여, 탁월한 가격 대비 성능비를 갖춘 업계 최고의 기반 모델과 AI 솔루션을 제공할 수 있는 위치를 확보했습니다. 더욱 강화된 성능과 낮아진 가격으로, 기반 모델은 점차 접근성이 높아지고 있으며, 이를 통해 다양한 규모의 애플리케이션이 가능해지고 산업 전반에 걸쳐 상당한 가치를 창출하고 있습니다. 모델 반복 개선을 넘어서, 당사는 AI를 더욱 개방적이고 협력적으로 만들기 위한 조치도 취하고 있습니다.</td></tr>
<tr><td>As previously announced, we plan to open source our most advanced ERNIE 4.5 series of models on June 30, a move that reflects both our technological confidence and our efforts to make ERNIE more accessible. In parallel, we are proactively embracing open standards such as the model context protocol or MCP, which provides easier access to AI powered tools and further lowers barriers to AI development. As development becomes simpler, we expect to see a growing number of AI applications emerging on our platform. Together, these efforts echo our consistent application driven approach to innovation and our determination to make AI more accessible, applicable and impactful.</td><td>이전에 발표한 바와 같이, 저희는 6월 30일에 가장 진보된 ERNIE 4.5 시리즈 모델을 오픈소스로 공개할 예정입니다. 이는 저희의 기술적 자신감과 ERNIE를 보다 접근성 있게 만들고자 하는 노력을 반영하는 결정입니다. 이와 더불어, 저희는 모델 컨텍스트 프로토콜(MCP)과 같은 개방형 표준을 적극적으로 수용하고 있습니다. 이를 통해 AI 기반 도구에 대한 접근성이 향상되고 AI 개발에 대한 진입 장벽이 더욱 낮아질 것입니다. 개발 과정이 단순화됨에 따라, 저희 플랫폼에서 더 많은 AI 애플리케이션이 등장할 것으로 예상합니다. 이러한 모든 노력은 혁신에 대한 저희의 일관된 애플리케이션 중심 접근 방식과 AI를 보다 접근 가능하고, 실용적이며, 영향력 있게 만들고자 하는 저희의 의지를 반영합니다.</td></tr>
<tr><td>In our AI Cloud business, we are strengthening Qianfan, our industry leading MaaS platform, to better support developers and enterprise clients in building models and facilitating AI applications. Qianfan boasts a comprehensive model library of foundation models, covering nearly all mainstream options on the market. It offers not only our own ERNIE family of models, but also a wide range of open source and third-party models, including the latest reasoning and multimodal models. This breadth allows individual developers and enterprise clients to choose suitable models with greater flexibility. Importantly, Qianfan provides these models with industry leading cost effectiveness.</td><td>AI 클라우드 사업 부문에서는 개발자와 기업 고객이 모델을 구축하고 AI 애플리케이션을 용이하게 구현할 수 있도록 업계 선도적인 MaaS(Model-as-a-Service) 플랫폼인 첸판(Qianfan)을 강화하고 있습니다. 첸판은 시장의 거의 모든 주류 옵션을 망라하는 포괄적인 기반 모델 라이브러리를 보유하고 있습니다. 자체 개발한 ERNIE 계열 모델뿐만 아니라, 최신 추론 모델과 멀티모달 모델을 포함한 광범위한 오픈소스 및 서드파티 모델도 제공하고 있습니다. 이러한 폭넓은 선택지를 통해 개별 개발자와 기업 고객들은 보다 유연하게 적합한 모델을 선택할 수 있습니다. 특히 주목할 만한 점은 첸판이 이러한 모델들을 업계 최고 수준의 비용 효율성으로 제공한다는 것입니다.</td></tr>
<tr><td>We're running models like DeepSeek. Qianfan achieved what we believe to be some of the lowest inference costs in the industry today with lightning speed and massive concurrency. Qianfan also delivers an expanding tool chain continuously enrich to provide the most comprehensive and user friendly toolkits for AI development. This quarter, complementing our existing app builder, model builder and agent builder, we introduced data builder to support AI data processing and preparation, while rolling out system wide upgrades across the entire tool chain to further improve efficiency and ease of use.</td><td>저희는 DeepSeek와 같은 모델들을 운영하고 있습니다. Qianfan은 업계에서 가장 낮은 수준의 추론 비용을 달성했다고 자부하며, 이는 초고속 처리 속도와 대규모 동시 처리 능력을 바탕으로 합니다. Qianfan은 또한 AI 개발을 위한 가장 포괄적이고 사용자 친화적인 도구를 제공하기 위해 지속적으로 확장되는 툴체인을 제공하고 있습니다. 이번 분기에는 기존의 앱 빌더, 모델 빌더, 에이전트 빌더에 더해 AI 데이터 처리 및 준비를 지원하는 데이터 빌더를 도입했으며, 전체 툴체인에 걸쳐 시스템 전반적인 업그레이드를 진행하여 효율성과 사용 편의성을 더욱 향상시켰습니다.</td></tr>
<tr><td>First, we enhanced the model builder to support the customized development of reasoning models by incorporating advanced training techniques, including reinforcement learning methods, like, RFT and GRTO. Second, we extended our fine-tuning capabilities to multimodal models, offering multimodal reinforcement learning techniques and enabling full process support from model building and training to evaluation and development. Third, as foundation models grow in size, model distillation has become essential for enterprise adoption. Hence, we introduced a one-click distillation feature that streamlines the previous multi step process.</td><td>첫째, 모델 빌더를 개선하여 RFT와 GRTO와 같은 강화학습 방법을 포함한 고급 학습 기법을 통합함으로써 맞춤형 추론 모델 개발을 지원하도록 했습니다. 둘째, 미세조정(fine-tuning) 기능을 멀티모달 모델로 확장하여 멀티모달 강화학습 기법을 제공하고, 모델 구축과 학습에서부터 평가 및 개발에 이르는 전체 프로세스를 지원할 수 있게 되었습니다. 셋째, 기초 모델의 규모가 커짐에 따라 모델 증류(model distillation)가 기업 도입에 필수적인 요소가 되었습니다. 이에 따라 기존의 다단계 프로세스를 간소화하는 원클릭 증류 기능을 도입했습니다.</td></tr>
<tr><td>With our expanded model library now covering reasoning models, enterprise clients can effortlessly build smaller models that maintain reasoning capabilities with reduced costs, making it easier to adopt advanced AI technology. Together, these enhancements significantly strengthened Qianfan’s tool chain, lowering the barriers for AI adoption and enabling faster, more efficient innovation across diverse use cases. On our legacy consumer facing product, Baidu Search, we accelerated its AI transformation with an unrelenting focus on enhancing user experience.</td><td>당사의 확장된 모델 라이브러리는 이제 추론 모델까지 포함하게 되어, 기업 고객들이 합리적인 비용으로 추론 능력을 유지하면서도 더 작은 규모의 모델을 손쉽게 구축할 수 있게 되었으며, 이를 통해 고급 AI 기술 도입이 더욱 용이해졌습니다. 이러한 개선사항들을 통해 전반적으로 치엔판(Qianfan)의 툴체인이 크게 강화되었고, AI 도입에 대한 진입장벽을 낮추어 다양한 활용 사례에서 더욱 빠르고 효율적인 혁신이 가능해졌습니다. 당사의 기존 소비자 대상 제품인 바이두 검색의 경우, 사용자 경험 향상에 끊임없이 집중하며 AI 전환을 가속화했습니다.</td></tr>
<tr><td>Our journey exemplifies how complex AI capabilities can be applied to create meaningful improvements that directly benefit our hundreds of millions of users. After exploring and validating for several quarters and with consistent positive user feedback, we established a relatively mature and scalable product framework for our AI – for our Gen AI enabled search early this year. Building on this, we are determined to further accelerate the AI transformation of Search. In April, about 35% of mobile search result pages contain AI generated content, increasing from 22% in January.</td><td>우리의 여정은 복잡한 AI 기능을 어떻게 수억 명의 사용자들에게 직접적인 혜택을 주는 의미 있는 개선사항으로 구현할 수 있는지를 보여줍니다. 수 분기에 걸친 탐색과 검증 과정을 거치고 지속적으로 긍정적인 사용자 피드백을 받은 후, 올해 초 생성형 AI 기반 검색에 대한 비교적 성숙하고 확장 가능한 제품 프레임워크를 구축했습니다. 이를 기반으로, 우리는 검색의 AI 전환을 더욱 가속화하기로 결정했습니다. 4월에는 모바일 검색 결과 페이지의 약 35%가 AI 생성 콘텐츠를 포함하고 있었는데, 이는 1월의 22%에서 증가한 수치입니다.</td></tr>
<tr><td>We are further enhancing the search experience by prioritizing multimodal content, including images, videos, agents, digital humans and live streaming. We believe this is a more effective way to present search results, as it aligns with evolving user preferences and better addresses the growing complexity of search queries. The distribution of multimodal content has been rapidly increasing. This trend reflects our continued progress in delivering a more intuitive and effective search experience. Also, the volume of content accessible within Baidu has continued to expand, particularly with the empowerment of foundation models.</td><td>당사는 이미지, 동영상, 에이전트, 디지털 휴먼, 실시간 스트리밍을 포함한 멀티모달 콘텐츠를 우선시함으로써 검색 경험을 더욱 향상시키고 있습니다. 이는 진화하는 사용자 선호도에 부합하고 점차 복잡해지는 검색 쿼리에 더 효과적으로 대응할 수 있어, 검색 결과를 제시하는 더 효과적인 방법이라고 믿고 있습니다. 멀티모달 콘텐츠의 분포가 급속도로 증가하고 있는데, 이는 보다 직관적이고 효과적인 검색 경험을 제공하는 데 있어 당사의 지속적인 진전을 반영합니다. 또한, 파운데이션 모델의 지원으로 바이두 내에서 접근 가능한 콘텐츠의 양이 지속적으로 확대되고 있습니다.</td></tr>
<tr><td>One example is AI generated digital human videos, which have surged over 30-fold from the beginning of 2025 through April in just a few months. The growing volume of content enriches what users can discover and provides access to a more expensive information landscape. Our efforts have led to consistent improvements in user experience. Users exposed to AI generated search results, find their search intent fulfilled more easily and quickly, indicating they get the desired information more efficiently. These users are also increasingly inclined to search for more varied questions or topics, have demonstrated higher retention over time.</td><td>한 예로 AI가 생성한 디지털 휴먼 영상의 경우, 2025년 초부터 4월까지 불과 몇 개월 만에 30배 이상 급증했습니다. 이렇게 증가하는 콘텐츠 양은 사용자들이 발견할 수 있는 정보를 풍부하게 하고, 더욱 광범위한 정보 생태계에 대한 접근성을 제공합니다. 당사의 이러한 노력은 사용자 경험의 지속적인 개선으로 이어졌습니다. AI가 생성한 검색 결과에 노출된 사용자들은 검색 의도를 더욱 쉽고 빠르게 충족시킬 수 있었으며, 이는 원하는 정보를 더 효율적으로 얻을 수 있음을 보여줍니다. 또한 이러한 사용자들은 점차 더 다양한 질문이나 주제를 검색하는 경향을 보이고 있으며, 시간이 지날수록 더 높은 리텐션을 보여주고 있습니다.</td></tr>
<tr><td>We are delighted to see more users can enjoy this improvement. In March, the MAU of Baidu App increased by 7% year-over-year, reaching $724 million. We firmly believe that agents and intelligent digital humans represent promising real-world applications of AI technology that will open up vast market opportunities ahead. Last quarter, I introduced the convergence of agents and intelligent digital humans, a powerful combination that brings together foundation models capabilities and digital human technology. Today, they are already widely deployed throughout our mobile ecosystem, effectively supporting different scenarios across industries.</td><td>더 많은 사용자들이 이러한 개선사항을 체감할 수 있게 된 것을 매우 기쁘게 생각합니다. 3월에는 바이두 앱의 월간 활성 사용자수(MAU)가 전년 대비 7% 증가하여 7억 2,400만 명을 기록했습니다. 저희는 에이전트와 지능형 디지털 휴먼이 AI 기술의 유망한 실제 응용 사례를 대표하며, 앞으로 광대한 시장 기회를 열어줄 것이라고 굳게 믿고 있습니다. 지난 분기에 저는 기반 모델의 역량과 디지털 휴먼 기술을 결합한 강력한 조합인 에이전트와 지능형 디지털 휴먼의 융합에 대해 소개한 바 있습니다. 현재 이들은 이미 저희의 모바일 생태계 전반에 광범위하게 배치되어 다양한 산업 분야에서 효과적으로 각종 시나리오를 지원하고 있습니다.</td></tr>
<tr><td>At our recent Baidu Create 2025, I further introduced an upgraded version of intelligent digital human with hyper realistic interactions, delivering natural conversation with vivid facial expressions and fluid human like gestures. In the future, we believe they can match or even outperform humans in certain scenarios. We're preparing to launch and scale our next generation hyper realistic digital humans into production soon. Now turning to intelligent driving, which represents another compelling frontier of our AI applications in the physical world.</td><td>최근 개최된 Baidu Create 2025에서 저는 초실감형 상호작용이 가능한 업그레이드된 버전의 지능형 디지털 휴먼을 추가로 소개했습니다. 이는 생생한 표정과 자연스러운 사람과 같은 제스처를 통해 자연스러운 대화가 가능합니다. 향후 특정 시나리오에서는 이러한 디지털 휴먼이 실제 인간과 대등하거나 더 나은 성능을 보일 수 있을 것으로 믿고 있습니다. 저희는 차세대 초실감형 디지털 휴먼을 곧 출시하고 실제 운영 환경으로 확장할 준비를 하고 있습니다. 이제 물리적 세계에서 AI 응용의 또 다른 유망한 프론티어인 지능형 주행에 대해 말씀드리겠습니다.</td></tr>
<tr><td>As highlighted last quarter, Apollo Go, our autonomous ride-hailing service has successfully validated its business model in the key operational region with highly complex transport conditions and cost sensitive local passengers. And it has achieved 100% fully driverless operations in Mainland, China. This gives us strong confidence to expand into international markets with higher pricing for ride-hailing service, where we aim to replicate and further optimize our proven approach.</td><td>지난 분기에 강조했듯이, 저희의 자율주행 차량 호출 서비스인 Apollo Go는 복잡한 교통 상황과 가격에 민감한 현지 승객들이 있는 주요 운영 지역에서 성공적으로 비즈니스 모델을 검증했습니다. 또한 중국 본토에서 100% 완전 무인 운행을 달성했습니다. 이러한 성과는 승차 호출 서비스의 가격이 더 높은 해외 시장으로 진출하는 데 있어 큰 자신감을 주고 있으며, 저희는 이미 검증된 접근 방식을 해외에서도 재현하고 더욱 최적화하는 것을 목표로 하고 있습니다.</td></tr>
<tr><td>In Q1, we reached critical milestones in international expansion with Apollo Go entering both Dubai and Abu Dhabi, aiming to provide safe, comfortable and affordable autonomous ride-hailing services in this booming markets. In May, we began open road validation testing in Dubai and we expect to start testing in Abu Dhabi soon. Meanwhile, we have also expanded our testing area in Hong Kong and obtained permission to conduct open road testing with designated passengers in April. With over 1,000 fully driverless vehicles now deployed globally, we continue to solidify our position as world's leading autonomous ride-hailing service provider. We are scaling up our services globally.</td><td>1분기에 Apollo Go가 두바이와 아부다비에 진출하면서 국제 확장의 중요한 이정표를 달성했으며, 이러한 성장하는 시장에서 안전하고 편안하며 합리적인 가격의 자율주행 차량 호출 서비스를 제공하는 것을 목표로 하고 있습니다. 5월에는 두바이에서 개방도로 검증 테스트를 시작했으며, 곧 아부다비에서도 테스트를 시작할 예정입니다. 한편, 홍콩에서는 테스트 지역을 확대했으며, 4월에는 지정된 승객과 함께 개방도로 테스트를 수행할 수 있는 허가를 획득했습니다. 현재 전 세계적으로 1,000대 이상의 완전 무인 자율주행 차량을 배치하여, 세계 최고의 자율주행 차량 호출 서비스 제공업체로서의 입지를 계속 강화하고 있습니다. 당사는 글로벌 서비스 규모를 확대해 나가고 있습니다.</td></tr>
<tr><td>Looking ahead, we will deepen our presence in existing markets, while strategically entering new ones, capturing broader growth opportunities worldwide. Now let me review the key highlights for each business for the first quarter. AI Cloud revenue reached RMB6.7 billion in Q1, delivering a strong year-over-year increase of 42% with non-GAAP operating profit remaining positive. Gen AI and foundation model related revenue recorded triple digit year-over-year growth, as accelerating AI adoption across multiple sectors drove a notable increase in customer demand for our highly cost effective AI Cloud services.</td><td>앞으로의 전망에 대해 말씀드리면, 저희는 기존 시장에서의 입지를 더욱 강화하는 동시에 새로운 시장에 전략적으로 진출하여 전 세계적으로 더 폭넓은 성장 기회를 확보해 나갈 것입니다. 이제 1분기 각 사업부문의 주요 성과를 검토해 보겠습니다. AI 클라우드 매출은 1분기에 67억 위안을 기록하며 전년 동기 대비 42%의 강력한 성장을 달성했고, 비갭(Non-GAAP) 영업이익도 흑자를 유지했습니다. 생성형 AI와 기반 모델 관련 매출은 전년 동기 대비 세 자릿수 성장률을 기록했는데, 이는 여러 산업 분야에서 AI 도입이 가속화되면서 당사의 높은 비용 효율성을 갖춘 AI 클라우드 서비스에 대한 고객 수요가 크게 증가한 결과입니다.</td></tr>
<tr><td>As mentioned earlier, we also upgraded our MaaS platform, Qianfan, with an expanded model library and more comprehensive toolkits, extending support for the training and fine-tuning of multimodal and reasoning models to further facilitate AI native application development. On applications, we -- you may recall that at Baidu World last October, we previewed MiaoDA, which delivers no code capabilities. In this quarter, we officially launched MiaoDA, making it available to everyone, programmer or not. Now that reflects our mission to democratize AI and empower more people outside the developer community to create innovative applications with natural language inputs.</td><td>앞서 언급한 바와 같이, 저희는 MaaS 플랫폼인 첸판(Qianfan)을 업그레이드하여 모델 라이브러리를 확장하고 더욱 포괄적인 툴킷을 제공함으로써, 멀티모달 및 추론 모델의 학습과 미세조정을 지원하여 AI 네이티브 애플리케이션 개발을 더욱 용이하게 했습니다. 애플리케이션 측면에서는, 작년 10월 바이두 월드에서 노코드 기능을 제공하는 미아오DA(MiaoDA)를 미리 선보였던 것을 기억하실 것입니다. 이번 분기에 저희는 미아오DA를 정식 출시하여 프로그래머이든 아니든 모든 사용자가 이용할 수 있게 되었습니다. 이는 AI를 대중화하고 개발자 커뮤니티 외부의 더 많은 사람들이 자연어 입력을 통해 혁신적인 애플리케이션을 만들 수 있도록 지원한다는 저희의 미션을 반영합니다.</td></tr>
<tr><td>The growing market recognition of our AI expertise continues to drive strong customer growth. In Q1, we deepened our collaboration with existing clients, while also expanding our customer base with new partnerships. We worked with a wide range of leading enterprises such as China Merchants Group and a top e-commerce company in China, further validating our position as the AI partner of Choice. Our client pipeline remains healthy.</td><td>AI 전문성에 대한 시장의 인지도 상승이 지속적으로 강력한 고객 성장을 견인하고 있습니다. 1분기에는 기존 고객들과의 협력 관계를 더욱 강화하는 한편, 신규 파트너십을 통해 고객 기반을 확대했습니다. 중국 차이나머천트그룹(China Merchants Group) 및 중국의 한 선도적인 이커머스 기업 등 다양한 유수 기업들과 협력하며, 당사가 선호되는 AI 파트너로서의 입지를 더욱 공고히 했습니다. 당사의 고객 파이프라인은 여전히 견실한 상태를 유지하고 있습니다.</td></tr>
<tr><td>We saw strong growth in the automotive sector and began expanding into emerging verticals, such as embodied artificial intelligence, where we recently entered into a strategic partnership with Beijing Humanoid Robot Innovation Center, the developer of the Tiangong Ultra Humanoid Robot. For our mobile ecosystem, we accelerated the AI transformation of search in Q1, while continuing to improve the efficiency of our monetization approaches. Agents continue to demonstrate enhanced efficiency as a monetization channel for our advertising business.</td><td>자동차 부문에서 강력한 성장을 보였으며, 최근 천궁(天宮) 울트라 휴머노이드 로봇을 개발한 베이징 휴머노이드 로봇 혁신센터와 전략적 파트너십을 체결하는 등 실체형 인공지능(embodied artificial intelligence)과 같은 신흥 분야로의 확장을 시작했습니다. 모바일 생태계와 관련해서는 1분기에 검색의 AI 전환을 가속화하는 한편, 수익화 방식의 효율성을 지속적으로 개선했습니다. 에이전트들은 당사의 광고 사업에서 수익화 채널로서 향상된 효율성을 지속적으로 보여주고 있습니다.</td></tr>
<tr><td>In March, over 29,000 advertisers had daily ad spending through agents, with many demonstrating increased willingness to allocate more of their ad budget to our agents. Adoption spans sectors like healthcare, education, lifestyle services, B2B, real estate and business services including legal services. In Q1, revenue generated by our agents for advertisers increased 30-fold year-over-year, accounting for 9% of Baidu Core's online marketing revenue. On the other hand, our industry leading intelligent digital human have proven their transformative value across business scenarios. For example, our digital humans serve as live streaming hosts for merchants on our platform.</td><td>3월에는 29,000개 이상의 광고주들이 에이전트를 통해 일일 광고비를 지출했으며, 많은 광고주들이 에이전트에 더 많은 광고 예산을 할당하려는 의지를 보였습니다. 헬스케어, 교육, 라이프스타일 서비스, B2B, 부동산, 그리고 법률 서비스를 포함한 비즈니스 서비스 등 다양한 분야에서 도입이 이루어졌습니다. 1분기에 에이전트를 통해 광고주들이 창출한 매출은 전년 동기 대비 30배 증가했으며, 이는 바이두 코어의 온라인 마케팅 매출의 9%를 차지했습니다. 한편, 업계를 선도하는 당사의 지능형 디지털 휴먼은 다양한 비즈니스 시나리오에서 혁신적인 가치를 입증했습니다. 예를 들어, 당사의 디지털 휴먼은 플랫폼 내 판매자들을 위한 라이브 스트리밍 호스트 역할을 수행하고 있습니다.</td></tr>
<tr><td>Over the past few quarters, tens of thousands of such digital humans have been live streaming on our platform every month, serving not just the merchants, but also expanding into fields like legal services, health care, education and more. Turning to intelligent driving. As just highlighted, Apollo Go made solid progress with its international expansion. Following our entry into Dubai and Abu Dhabi, our global footprint now spans 15 cities. Backed by our validated business model and proven operational expertise, we aim to further broaden our presence across more cities globally. In terms of ride volume, we are seeing clear acceleration.</td><td>지난 몇 분기 동안, 매월 수만 명의 디지털 휴먼이 당사 플랫폼에서 라이브 스트리밍을 진행해왔으며, 이는 단순히 판매자들을 위한 서비스를 넘어 법률 서비스, 헬스케어, 교육 등 다양한 분야로 확장되고 있습니다. <br><br>자율주행 부문으로 넘어가면, 앞서 강조했듯이 아폴로 고(Apollo Go)는 국제 시장 확장에서 견실한 진전을 이루었습니다. 두바이와 아부다비 진출에 이어, 당사의 글로벌 사업 영역은 현재 15개 도시로 확대되었습니다. 검증된 비즈니스 모델과 입증된 운영 노하우를 바탕으로, 당사는 전 세계 더 많은 도시로 사업 영역을 확장해 나갈 계획입니다. 운행량 측면에서는 뚜렷한 가속화 추세를 보이고 있습니다.</td></tr>
<tr><td>Apollo Go provided approximately 1.4 million rides to the public in Q1, representing a robust year-over-year growth of 75%. As of May 2025, the cumulative rides provided to the public have exceeded RMB11 million. Meanwhile, we continue to scale up our service capabilities in cities where we have long been operating. Also, we are exploring asset light business models, as a key strategic direction for our future growth. And we have started to see early adoption in certain areas recently.</td><td>Apollo Go는 1분기에 일반 대중에게 약 140만 건의 운행 서비스를 제공했으며, 이는 전년 대비 75%의 견고한 성장을 보여주었습니다. 2025년 5월 기준으로 대중에게 제공된 누적 운행 건수는 1,100만 위안을 초과했습니다. 한편, 당사는 장기간 운영해 온 도시들에서 서비스 역량을 지속적으로 확대하고 있습니다. 또한, 미래 성장을 위한 핵심 전략 방향으로서 자산 경량화 비즈니스 모델을 모색하고 있으며, 최근 특정 지역에서 초기 도입이 이루어지고 있는 것을 확인하고 있습니다.</td></tr>
<tr><td>In May, Apollo Go entered into a long-term strategic partnership with CAR Inc, China's leading auto rental service provider to introduce fully autonomous vehicle rental services and explore new models for smart mobility together. As our technology and operations mature at scale, we see significant opportunities and commercial sustainability across more use cases and regions. Combined with our regionally validated business model and global expansion efforts, we believe we are well-positioned to create substantial value and reshape the future of mobility in the coming years.</td><td>5월에 Apollo Go는 중국 최대 자동차 렌탈 서비스 제공업체인 CAR Inc와 장기 전략적 파트너십을 체결하여, 완전 자율주행 차량 렌탈 서비스를 도입하고 스마트 모빌리티의 새로운 모델을 함께 모색하기로 했습니다. 당사의 기술과 운영이 규모있게 성숙해감에 따라, 더 많은 활용 사례와 지역에서 상당한 사업 기회와 상업적 지속가능성을 확인하고 있습니다. 지역별로 검증된 비즈니스 모델과 글로벌 확장 노력을 바탕으로, 당사는 향후 수년간 실질적인 가치를 창출하고 모빌리티의 미래를 재편할 수 있는 유리한 위치를 확보했다고 믿습니다.</td></tr>
<tr><td>Looking back at the quarter's divestments (ph), we are seeing encouraging progress in AI applications across the board from enterprise services to consumer facing products and intelligent mobility. AI technologies are beginning to generate tangible, meaningful value through applications, which embodies the ultimate goal of our application driven innovation and aligns perfectly with our long standing strategic focus on AI. With that, let me turn the call over to Jackson to go through the financial results. Junjie He<br><br>Thank you, Robin. So now let me walk through the details of our first quarter financial results. Total revenues were RMB32.5 billion, increasing 3% year-over-year.</td><td>분기별 매각(ph)을 돌아보면, 엔터프라이즈 서비스에서 소비자 대면 제품, 지능형 모빌리티에 이르기까지 AI 애플리케이션 전반에 걸쳐 고무적인 진전을 보이고 있습니다. AI 기술은 애플리케이션을 통해 실질적이고 의미 있는 가치를 창출하기 시작했는데, 이는 우리의 애플리케이션 주도 혁신의 궁극적인 목표를 구현하는 것이며 AI에 대한 우리의 오랜 전략적 초점과 완벽하게 부합합니다. 이제 재무 결과에 대해 설명할 Jackson에게 마이크를 넘기겠습니다. Junjie He<br><br>Robin님, 감사합니다. 이제 1분기 재무 실적의 세부 내용을 살펴보도록 하겠습니다. 총 매출은 전년 동기 대비 3% 증가한 325억 위안을 기록했습니다.</td></tr>
<tr><td>Revenue from Baidu Core was RMB25.5 billion, increasing 7% year-over-year. Baidu Core's online marketing revenue was RMB16.0 billion, decreasing 6% year-over-year. Baidu Core's non-online marketing revenue was RMB9.4 billion, up 40% year-over-year, mainly driven by AI Cloud business. Within Baidu Core's non-online marketing revenue, AI Cloud revenue was RMB6.7 billion, increased by 42% year-over-year and accounted for 26% of Baidu Core's revenue. Revenue from iQIYI was RMB7.2 billion, decreasing 9% year-over-year. Cost of revenues was RMB17.5 billion, increasing 14% year-over-year, primarily due to an increase in costs related to AI cloud business and traffic acquisition costs.</td><td>바이두 코어의 매출액은 전년 대비 7% 증가한 255억 위안을 기록했습니다. 바이두 코어의 온라인 마케팅 매출은 전년 대비 6% 감소한 160억 위안이었습니다. 바이두 코어의 비온라인 마케팅 매출은 AI 클라우드 사업의 성장에 힘입어 전년 대비 40% 증가한 94억 위안을 기록했습니다. 바이두 코어의 비온라인 마케팅 매출 중 AI 클라우드 매출은 67억 위안으로, 전년 대비 42% 증가했으며 바이두 코어 전체 매출의 26%를 차지했습니다. 아이치이(iQIYI)의 매출은 전년 대비 9% 감소한 72억 위안이었습니다. 매출원가는 AI 클라우드 사업 관련 비용과 트래픽 획득 비용의 증가로 인해 전년 대비 14% 증가한 175억 위안을 기록했습니다.</td></tr>
<tr><td>Operating expenses were RMB10.5 billion, decreasing 3% year-over-year, primarily due to a decrease in personnel related expenses, partially offset by the increase in channel spending and promotional marketing expenses. Baidu Core's operating expenses were RMB9.1 billion, decreasing 4% year-over-year. Baidu Core SG&A expenses were RMB4.9 billion, increasing 10% year-over-year. SG&A accounted for 19% of Baidu Core’s revenue this quarter, which is basically flat from last year. Baidu Core R&D expenses were RMB4.9 billion, decreasing 16% year-over-year. R&D accounted for 16% of Baidu Core's revenue this quarter, compared to 21% in the same period last year. Operating income was RMB4.5 billion.</td><td>영업비용은 전년 대비 3% 감소한 105억 위안을 기록했습니다. 이는 주로 인건비 감소에 기인하며, 채널 지출 및 프로모션 마케팅 비용의 증가로 일부 상쇄되었습니다. 바이두 코어의 영업비용은 전년 대비 4% 감소한 91억 위안이었습니다. 바이두 코어의 판매관리비(SG&A)는 전년 대비 10% 증가한 49억 위안을 기록했습니다. 판매관리비는 이번 분기 바이두 코어 매출의 19%를 차지했으며, 이는 전년과 비슷한 수준입니다. 바이두 코어의 연구개발(R&D) 비용은 전년 대비 16% 감소한 49억 위안을 기록했습니다. 연구개발비는 이번 분기 바이두 코어 매출의 16%를 차지했으며, 이는 전년 동기의 21%에서 감소한 수준입니다. 영업이익은 45억 위안을 기록했습니다.</td></tr>
<tr><td>Baidu Core's operating income was RMB4.2 billion and the Baidu Corre’s operating margin was 16%. Non-GAAP operating income was RMB5.3 billion. Non-GAAP Baidu Core operating income was RMB4.9 billion and non-GAAP Baidu Core operating margin was 19%. Total asset income net was RMB4.5 billion, including 260% year-over-year, mainly due to an increase in fair value gain and the pickup of earnings from long-term investments, partially offset by the decrease in net foreign exchange gain arising from exchange rate fluctuation between RMB and the U.S. dollar. Income tax expense was RMB1.2 billion compared to RMB883 million in the same period last year.</td><td>바이두 코어의 영업이익은 42억 위안이었으며, 바이두 코어의 영업이익률은 16%를 기록했습니다. 비갭(Non-GAAP) 영업이익은 53억 위안이었습니다. 비갭 바이두 코어 영업이익은 49억 위안이었으며, 비갭 바이두 코어 영업이익률은 19%를 기록했습니다. 총자산수익은 45억 위안으로, 전년 동기 대비 260% 증가했는데, 이는 주로 공정가치 평가이익의 증가와 장기투자자산의 수익 증가에 기인하며, 위안화와 미달러화 간의 환율 변동으로 인한 순외환차익 감소로 일부 상쇄되었습니다. 법인세비용은 12억 위안으로, 전년 동기의 8억 8,300만 위안과 비교할 수 있습니다.</td></tr>
<tr><td>Net income attributable to Baidu was RMB7.7 billion and diluted earnings per ADS was RMB21.59. Net income attributable to Baidu Core was RMB7.6 billion and net margin for Baidu Core was 30%. Non-GAAP net income attributable to Baidu RMB6.5 billion. Non-GAAP diluted earnings per ADS was RMB18.54. Non-GAAP net income attributable to Baidu Core was RMB6.3 billion and non-GAAP net margin for Baidu Core was 25%. As of March 31, 2025, cash, cash equivalents, restricted cash and short-term investments were RMB142.0 billion and the cash, cash equivalents, restricted cash and short-term investments excluding iQIYI were RMB136.7 billion.</td><td>바이두 귀속 순이익은 77억 위안이었으며, ADS당 희석주당순이익은 21.59위안이었습니다. 바이두 코어 귀속 순이익은 76억 위안이었으며, 바이두 코어의 순이익률은 30%를 기록했습니다. 비갭(Non-GAAP) 기준 바이두 귀속 순이익은 65억 위안이었습니다. 비갭 기준 ADS당 희석주당순이익은 18.54위안이었습니다. 비갭 기준 바이두 코어 귀속 순이익은 63억 위안이었으며, 바이두 코어의 비갭 기준 순이익률은 25%였습니다. 2025년 3월 31일 기준, 현금, 현금성자산, 제한성예금 및 단기투자자산은 1,420억 위안이었으며, iQIYI를 제외한 현금, 현금성자산, 제한성예금 및 단기투자자산은 1,367억 위안이었습니다.</td></tr>
<tr><td>Free cash flow was negative RMB8.9 billion and the free cash flow excluding iQIYI was negative RMB9.2 billion, mainly due to an increase of investments in AI business. We define net cash position as total cash, cash equivalents, restricted cash, short-term investments, net long-term, term deposits and held-to-maturity investments and others, less total loans, convertible senior loans and loans payable. As of March 31, 2025, net cash position for Baidu was RMB159.0 billion. Baidu Core had approximately 31,000 employees as of March 31, 2025. Finally, since last year, we have accelerated our share repurchase program.</td><td>잉여현금흐름은 마이너스 89억 위안을 기록했으며, iQIYI를 제외한 잉여현금흐름은 마이너스 92억 위안을 기록했습니다. 이는 주로 AI 사업에 대한 투자 증가에 기인합니다. 당사는 순현금 포지션을 현금 및 현금성자산, 사용제한현금, 단기투자자산, 순장기예금, 만기보유투자자산 및 기타 자산의 합계에서 총 차입금, 전환사채 및 지급채무를 차감한 금액으로 정의하고 있습니다. 2025년 3월 31일 기준 바이두의 순현금 포지션은 1,590억 위안입니다. 바이두 코어의 임직원 수는 2025년 3월 31일 기준 약 31,000명입니다. 마지막으로, 작년부터 당사는 자사주 매입 프로그램을 가속화했습니다.</td></tr>
<tr><td>From the beginning of Q1 2025, we repurchased a total of $445 million of our shares, reflecting our long standing commitment to delivering long term value to shareholders. With that, operator, let's now open the call to questions.</td><td>2025년 1분기 초부터 총 4억 4,500만 달러 규모의 자사주를 매입했으며, 이는 주주들에게 장기적 가치를 제공하겠다는 당사의 오랜 의지를 보여주는 것입니다. 그럼 이제 진행자님, 질의응답을 시작하도록 하겠습니다.<br><br>Note: The translation maintains key financial terms like "자사주 매입" (share repurchase) and preserves the formal, professional tone typical of earnings calls. The Korean version is natural while being faithful to the original message about shareholder value creation.</td></tr>
    </table>
    <h3>📌 요약</h3>
    <p style="background:#f0f0f0; padding:15px; border-left: 5px solid #333;">Here are the key points from the earnings call in Korean:<br><br>• 실적 하이라이트:<br>- 바이두 코어 매출 255억 위안 (전년 대비 7% 증가)<br>- AI 클라우드 매출 67억 위안 (전년 대비 42% 증가)으로 전체 매출의 26% 차지<br>- 비GAAP 영업이익률 19% 기록<br><br>• AI 사업 진전:<br>- ERNIE 4.5와 ERNIE X1 등 신규 AI 모델 출시<br>- Qianfan(첸판) MaaS 플랫폼 강화 및 툴체인 확대<br>- 검색 결과의 35%가 AI 생성 콘텐츠로 구성<br><br>• 자율주행 사업 확장:<br>- Apollo Go 서비스 두바이, 아부다비 등 해외 진출<br>- Q1 기준 140만 건의 자율주행 서비스 제공 (전년 대비 75% 증가)<br>- 전 세계 15개 도시에서 1,000대 이상의 완전 자율주행 차량 운영 중<br><br>• 투자자 관련 사항:<br>- Q1 기준 4.45억 달러 규모의 자사주 매입 진행<br>- 현금 및 현금성 자산 1,420억 위안 보유</p>
    <hr style="margin:50px 0;">
    

    <h2>❓ Q&A</h2>
    <table style="width:100%; border-collapse:collapse; margin-bottom: 40px;">
        <tr>
            <th style="width:50%; border-bottom: 2px solid #333;">Original</th>
            <th style="width:50%; border-bottom: 2px solid #333;">Translation</th>
        </tr>
        <tr><td>Question-and-Answer Session<br><br>Operator<br><br>Ladies and gentlemen, we will now begin the question-and-answer. [Operator Instructions] Your first question comes from Alicia Yap with Citigroup. Please go ahead. Alicia Yap<br><br>Thank you. Good evening, Robin, Jackson, Juan and management. Thanks for taking my questions. I wanted to ask about the AI model. So given the rapid pace of the model iterations and also your upcoming open source strategy. Can management share the latest update on your AI overall strategy? And then, what is the technology roadmap for earning in 2025? Will Baidu continue iterating on the foundation model such as the ERNIE 5.0, for example?</td><td>질의응답<br><br>진행자<br><br>신사 숙녀 여러분, 이제 질의응답을 시작하겠습니다. [진행자 안내사항] 첫 번째 질문은 시티그룹의 앨리시아 얍 님께서 하시겠습니다. 앨리시아 얍 님, 질문해 주시기 바랍니다.<br><br>앨리시아 얍<br><br>감사합니다. 안녕하세요, 로빈 님, 잭슨 님, 후안 님 그리고 경영진 여러분. 질문에 답변해 주셔서 감사합니다. AI 모델에 대해 여쭤보고 싶습니다. 모델 반복 개발의 빠른 속도와 앞으로의 오픈소스 전략을 고려할 때, 경영진께서 전반적인 AI 전략에 대한 최신 현황을 공유해 주실 수 있을까요? 그리고 2025년까지의 기술 로드맵은 어떻게 되나요? 바이두는 ERNIE 5.0과 같은 기초 모델을 계속해서 발전시켜 나갈 예정인가요?</td></tr>
<tr><td>Can you further reduce inference costs going forward? Thank you. Robin Li<br><br>Hi, Alicia. This is Robin. Over the past few months, we've seen an accelerated iteration of foundation models. But no matter how fast the models advance, I think one thing is always clear. The true value of foundation models ultimately lies in applications built on the models. That's why we stick to an application driven approach for innovation. The foundation model space is very broad. So, we don't necessarily have to make ERNIE lead in every possible direction. Instead, we strategically focus our model iteration efforts on areas with real application value, where we can build the most competitive capabilities.</td><td>네, 앞으로도 추론 비용을 더 줄일 수 있을까요? 감사합니다. Robin Li<br><br>안녕하세요, Alicia님. 저는 Robin입니다. 지난 몇 달 동안 기초 모델(foundation model)의 발전 속도가 가속화되는 것을 지켜보았습니다. 하지만 모델이 아무리 빠르게 발전하더라도, 한 가지 분명한 사실이 있습니다. 기초 모델의 진정한 가치는 결국 그 모델을 기반으로 구축된 애플리케이션에 있다는 것입니다. 그래서 저희는 혁신을 위해 애플리케이션 중심 접근 방식을 고수하고 있습니다. 기초 모델 분야는 매우 광범위합니다. 따라서 ERNIE가 모든 가능한 방향에서 선두를 차지할 필요는 없습니다. 대신 저희는 실제 응용 가치가 있고 가장 경쟁력 있는 역량을 구축할 수 있는 영역에 전략적으로 모델 개선 노력을 집중하고 있습니다.</td></tr>
<tr><td>For example, we make sure our model development matches what our products actually need. For over one year, we've been using foundation model to drive AI transformation across our mobile ecosystem, including search. This hands-on experiences have shown us which model capabilities bring real value and are worth prioritizing like, multimodality. We've also spotted some promising application areas. Take our digital humans for instance. By combining different model capabilities, we've created hyper realistic digital humans that can even perform better than real human in certain situations. We'll be rolling them out at scale soon, opening up their value in many new scenarios.</td><td>예를 들어, 저희는 모델 개발이 실제 제품의 필요사항과 일치하도록 보장하고 있습니다. 1년 이상 저희는 검색을 포함한 모바일 생태계 전반의 AI 혁신을 주도하기 위해 기반 모델(foundation model)을 활용해 왔습니다. 이러한 실무 경험을 통해 멀티모달리티(multimodality)와 같이 실질적 가치를 창출하고 우선순위를 둘 만한 모델 역량이 무엇인지 파악할 수 있었습니다. 또한 몇 가지 유망한 응용 분야도 발견했습니다. 예를 들어 저희의 디지털 휴먼을 보면, 다양한 모델 기능을 결합하여 특정 상황에서는 실제 인간보다 더 나은 성능을 발휘할 수 있는 초현실적 디지털 휴먼을 만들어냈습니다. 곧 이를 대규모로 출시하여 다양한 새로운 시나리오에서 그 가치를 창출할 예정입니다.</td></tr>
<tr><td>Our earnings technology roadmap, we're set to continue the evolution of ERNIE. We're already working on the next generation of [indiscernible] models, and we expect to further accelerate our pace of model iteration. And back to your question on inference costs, yes, we absolutely believe we can keep driving down costs. In fact, each new model we've launched recently has come with significant price cuts. As I mentioned before, we released ERNIE 4.5 and X1 in March. X1 matched DeepSeek R1's performance at only half the price. Then about a month later, we rolled out turbo versions with better performance and even more aggressive pricing.</td><td>당사의 실적 기술 로드맵에 있어서, 저희는 ERNIE의 진화를 지속적으로 추진할 예정입니다. 이미 차세대 [청취불가] 모델 개발에 착수했으며, 모델 반복 개발 속도를 더욱 가속화할 것으로 예상하고 있습니다. 추론 비용에 대한 질문으로 돌아가면, 네, 저희는 확실히 비용을 계속해서 낮출 수 있다고 믿습니다. 실제로 최근 출시한 각각의 새로운 모델은 상당한 가격 인하와 함께 제공되었습니다. 앞서 언급했듯이, 3월에 ERNIE 4.5와 X1을 출시했는데, X1은 DeepSeek R1의 성능에 맞추면서도 절반의 가격으로 제공되었습니다. 그로부터 약 한 달 후, 더 나은 성능과 더욱 공격적인 가격 정책을 갖춘 터보 버전을 출시했습니다.</td></tr>
<tr><td>ERNIE 4.5 Turbo at 80% lower price than 4.1 and Ernie X1 Turbo at half the price of Ernie X1. This price cuts are supported by our full-stack AI capabilities to continuously lower inference costs, making our model one of the most cost effective options on the market today. We're also opening up our best capabilities to the broader community. So, we are on track to open source ERNIE 4.5 series on June 30. And we are excited to see markets response and look forward to more people exploring what ERNIE can do. Ultimately, we hope this helps more users experience the true value of our models and explore new real world applications. Thank you.</td><td>ERNIE 4.5 Turbo를 4.1 대비 80% 낮은 가격에, 그리고 Ernie X1 Turbo를 Ernie X1 대비 절반 가격에 제공하게 되었습니다. 이러한 가격 인하는 당사의 풀스택 AI 역량을 바탕으로 추론 비용을 지속적으로 절감할 수 있었기에 가능했으며, 이를 통해 당사의 모델은 현재 시장에서 가장 비용 효율적인 옵션 중 하나가 되었습니다. 또한 저희는 최고의 기능들을 더 넓은 커뮤니티에 개방하고 있습니다. 6월 30일에는 계획대로 ERNIE 4.5 시리즈를 오픈소스로 공개할 예정이며, 시장의 반응을 확인하고 더 많은 사람들이 ERNIE의 가능성을 탐구하게 되기를 기대하고 있습니다. 궁극적으로, 이를 통해 더 많은 사용자들이 저희 모델의 진정한 가치를 경험하고 새로운 실제 응용 사례를 발굴하는 데 도움이 되기를 희망합니다. 감사합니다.</td></tr>
<tr><td>Operator<br><br>Your next question comes from Lincoln Kong with Goldman Sachs. Please go ahead. Lincoln Kong<br><br>Thank you, management for taking my questions. My question is about the cloud business. So, we have seen a very strong growth in the first quarter for the cloud revenue. So what are the key drivers for this strong growth? So, how should we think about sustainability here? And also could management provide us some breakdown in terms of the by category, for example, like infrastructure, industry solutions, project based service and as well as this personal cloud? So, how should we think about the outlook for the growth as well as the profitability within 2025 for cloud business?</td><td>오퍼레이터<br><br>다음 질문은 골드만삭스의 링컨 콩 님께서 하시겠습니다. 링컨 콩 님, 질문해 주시기 바랍니다.<br><br>질문의 기회를 주셔서 감사합니다. 제 질문은 클라우드 사업에 관한 것입니다. 1분기에 클라우드 매출이 매우 강한 성장세를 보였는데요. 이러한 강한 성장을 이끈 주요 동인이 무엇인지 궁금합니다. 이러한 성장세의 지속가능성은 어떻게 평가해야 할까요? 또한 경영진께서 카테고리별 세부 내역을 제공해 주실 수 있을까요? 예를 들어 인프라스트럭처, 산업 솔루션, 프로젝트 기반 서비스, 그리고 개인 클라우드 등에 대해서요. 2025년까지 클라우드 사업의 성장성과 수익성 전망은 어떻게 보아야 할까요?</td></tr>
<tr><td>And lastly, with the recent tightening of our U.S. export restrictions on those advanced AI chips, so what are the potential impact here on Baidu Cloud operation and our growth plan? Thank you. Dou Shen<br><br>This is Dou. Thank you for your question. In Q1, our AI Cloud revenue growth further accelerated to from 26% year-over-year growth in Q4 last year to 42% year-over-year, mainly driven by surging demand for Gen AI and foundation models across industries for both training and inference. So as foundation models have undergone faster iteration recently, we have seen a fast increase in the model training needs, not just for large language models, but also for other types of models.</td><td>마지막으로, 최근 미국의 첨단 AI 칩에 대한 수출 규제가 강화된 것과 관련하여, 이것이 바이두 클라우드 운영과 성장 계획에 미칠 수 있는 잠재적 영향은 무엇입니까? 감사합니다.<br><br>두 션입니다. 질문해 주셔서 감사합니다. 1분기에 우리의 AI 클라우드 매출 성장률은 작년 4분기의 전년 대비 26% 성장에서 42%로 더욱 가속화되었습니다. 이는 주로 학습(training)과 추론(inference) 모두에서 산업 전반에 걸쳐 생성형 AI와 기초 모델에 대한 수요가 급증했기 때문입니다. 최근 기초 모델의 반복 주기가 더욱 빨라짐에 따라, 대규모 언어 모델뿐만 아니라 다른 유형의 모델에 대해서도 모델 학습 수요가 급격히 증가하는 것을 확인했습니다.</td></tr>
<tr><td>Customers are increasingly choosing Baidu AI Cloud for our recognized leadership in AI infrastructure and our enhanced MaaS platform, Qianfan, which consistently lowers inference costs and improves toolchain efficiency. In terms of the revenue breakdown, Baidu AI Cloud primarily consists of two parts: personal cloud and enterprise cloud. And enterprise cloud contributes to the vast majority of AI cloud revenue, which has consistently outgrown overall AI cloud. And then, within the enterprise cloud, we have subscription based and project based revenue.</td><td>고객들은 AI 인프라 분야에서 인정받는 바이두의 리더십과, 추론 비용을 지속적으로 낮추고 툴체인 효율성을 향상시키는 개선된 MaaS(Model-as-a-Service) 플랫폼인 첸판(Qianfan)으로 인해 점차 바이두 AI 클라우드를 선택하고 있습니다. 매출 구성을 살펴보면, 바이두 AI 클라우드는 주로 개인 클라우드와 기업 클라우드 두 부분으로 구성됩니다. 기업 클라우드가 AI 클라우드 매출의 대부분을 차지하고 있으며, 전체 AI 클라우드 성장률을 지속적으로 상회하고 있습니다. 또한 기업 클라우드 내에서는 구독 기반 매출과 프로젝트 기반 매출로 나눌 수 있습니다.</td></tr>
<tr><td>For the subscription based revenue, it currently accounts for the majority of the enterprise cloud revenue, providing a sustainable revenue stream. Among subscription based revenue, Gen AI related revenue has maintained triple digit year-over-year growth for several consecutive quarters. Project based revenue may fluctuate from time-to-time, but in the long run, we believe the proportion for our subscription based revenue will continue to rise, supporting more sustainable and healthier long-term growth for our cloud business. On the profit side, AI Cloud's non-GAAP operating margin continues to expand year-over-year in Q1, maintaining its upward trend.</td><td>구독 기반 매출과 관련하여, 현재 이는 엔터프라이즈 클라우드 매출의 대부분을 차지하며 안정적인 수익원을 제공하고 있습니다. 구독 기반 매출 중에서도 생성형 AI 관련 매출은 연속 수분기 동안 전년 대비 3자릿수 성장률을 유지해왔습니다. 프로젝트 기반 매출은 단기적으로 변동성을 보일 수 있으나, 장기적으로는 구독 기반 매출의 비중이 계속해서 증가할 것으로 예상되며, 이는 당사의 클라우드 사업에 있어 보다 지속 가능하고 건전한 장기 성장을 뒷받침할 것입니다. 수익성 측면에서는, AI 클라우드의 비(非)GAAP 영업이익률이 1분기에도 전년 대비 확대되며 상승세를 이어가고 있습니다.</td></tr>
<tr><td>This was driven by an improved revenue mix towards higher value offerings as we focus on opportunities that align with our strategic priorities. As a result, our AI cloud's non-GAAP operating margin is now at the level of teens. Regarding AI chip export restrictions, as Robin just mentioned, we follow an application driven approach because we believe the greatest value of AI eventually lies at the application layer. Even without access to the most advanced chips, our unique full stack AI capabilities enable us to build strong applications and deliver meaningful value.</td><td>전략적 우선순위에 부합하는 기회에 집중하면서 고부가가치 제품군 중심으로 매출 구조가 개선된 결과입니다. 이에 따라 당사 AI 클라우드의 비(非)GAAP 영업이익률은 현재 10%대 수준을 기록하고 있습니다. AI 칩 수출 규제와 관련해서는, Robin이 언급했듯이 저희는 애플리케이션 중심 접근법을 따르고 있습니다. 이는 AI의 궁극적인 가치가 결국 애플리케이션 레이어에 있다고 믿기 때문입니다. 최첨단 칩에 대한 접근이 제한되더라도, 당사의 독보적인 풀스택 AI 역량을 통해 강력한 애플리케이션을 구축하고 의미 있는 가치를 제공할 수 있습니다.</td></tr>
<tr><td>Also, our AI infrastructure is both scalable and highly efficient, enabling strong GPU utilization to support both training and inference with high cost performance. In parallel, we have the flexibility to select from a range of chip solutions based on different business scenarios, especially for inference. So looking forward, we believe that in overtime, domestically developed self-sufficient chips, along with increasingly efficient homegrown software stack will jointly from a strong foundation for long-term innovation in China's AI ecosystem. Thank you. Operator<br><br>The next question comes from Alex Yao with JPMorgan. Please go ahead. Alex Yao<br><br>Thank you, management for taking my question.</td><td>또한 저희의 AI 인프라는 확장성과 고효율성을 모두 갖추고 있어, GPU 활용도를 극대화하여 학습과 추론 모두를 우수한 비용 효율성으로 지원할 수 있습니다. 이와 동시에 저희는 다양한 비즈니스 시나리오, 특히 추론 작업에 있어 여러 종류의 칩 솔루션 중에서 선택할 수 있는 유연성을 보유하고 있습니다. 앞으로의 전망을 봤을 때, 시간이 지남에 따라 국내에서 개발된 자급자족형 칩들이 점차 효율적으로 발전하는 자체 소프트웨어 스택과 함께 중국 AI 생태계의 장기적 혁신을 위한 견고한 기반을 형성할 것이라 믿습니다. 감사합니다. 진행자<br><br>다음 질문은 JP모건의 알렉스 야오 님께서 하시겠습니다. 알렉스 님, 질문해 주시기 바랍니다. 알렉스 야오<br><br>경영진 여러분, 질문의 기회를 주셔서 감사합니다.</td></tr>
<tr><td>So you accelerated the AI search transition this quarter. Was management's rationale behind the move? What are your expectations for AI answers penetration? And then any updates on upcoming testing for AI monetization in 2Q? And how should we think about the ramp up into second half this year in terms of monetization and the consumer behavior? Thank you. Robin Li<br><br>Thank you, Alex for your question and let me take your question. In Q1, actually, we have seen significantly accelerated our AI transformation of such aiming to further enhance the user experiences through innovative technology.</td><td>네, 이번 분기에 AI 검색 전환을 가속화하셨는데요. 경영진의 결정 배경이 무엇이었는지, 그리고 AI 답변의 침투율에 대한 기대치는 어떠신지 궁금합니다. 또한 2분기에 예정된 AI 수익화 테스트에 대한 업데이트와 함께, 올해 하반기의 수익화 및 소비자 행동 측면에서의 진행 방향에 대해 어떻게 보시는지 말씀해 주시겠습니까? 감사합니다. Robin Li<br><br>Alex님의 질문에 답변 드리겠습니다. 1분기에 저희는 혁신적인 기술을 통해 사용자 경험을 더욱 향상시키기 위해 검색의 AI 전환을 크게 가속화했습니다.<br><br>Note: The translation maintains the formal business tone appropriate for an earnings call, uses standard Korean financial terminology, and preserves the interactive Q&A format while ensuring natural flow in Korean.</td></tr>
<tr><td>And our top priority remains the same that is the user experiences as we believe that the high quality of the [indiscernible] continues the user metrics improvements are critical for sustainable long term growth. In April, we have seen that roughly 35%, 35% (ph) of the mobile search results, which is content -- AI generated content, up from 22% in January, which has making our largest expansion so far. We expect this percentage to keep rising rapidly in Q2. And there are a couple of reasons behind them. In the first place, today's AI landscape is evolving very quickly and the users' information seeking behaviors continue to diversify.</td><td>우리의 최우선 순위는 여전히 동일합니다. 바로 사용자 경험입니다. 우리는 [청취불가] 의 높은 품질이 사용자 지표 개선을 지속적으로 이끌어내는 것이 지속 가능한 장기 성장에 핵심이라고 믿고 있습니다. 4월에는 모바일 검색 결과 중 AI 생성 콘텐츠의 비중이 약 35%(ph)를 기록했는데, 이는 1월의 22%에서 상승한 수치로 지금까지 가장 큰 폭의 확장이었습니다. 우리는 2분기에도 이 비율이 계속해서 빠르게 증가할 것으로 예상하고 있습니다. 이러한 증가세에는 몇 가지 이유가 있습니다. 우선, 오늘날의 AI 환경이 매우 빠르게 진화하고 있으며, 사용자들의 정보 검색 행태도 계속해서 다양화되고 있습니다.</td></tr>
<tr><td>So it's more necessary than ever to make rapid innovations in such capabilities. Second, ongoing progress in the model's capabilities has also helped us to keep improving the quality, quantity and the presentation format of the search results, while generating the multimodal contents at a massive level. And meanwhile, the average cost per query will keep falling as the inference cost drops. And we can roll this out across more queries more quickly.</td><td>따라서 이러한 역량을 신속하게 혁신하는 것이 그 어느 때보다 필요한 상황입니다. 둘째로, 모델 역량의 지속적인 발전은 대규모로 멀티모달 콘텐츠를 생성하는 동시에, 검색 결과의 품질, 양, 그리고 프레젠테이션 형식을 계속해서 개선하는 데 도움이 되었습니다. 또한 추론 비용이 감소함에 따라 쿼리당 평균 비용도 계속 하락할 것이며, 이를 더 많은 쿼리에 더욱 신속하게 적용할 수 있을 것입니다.<br><br>Note: The translation maintains the formal business tone while accurately conveying technical terms like "멀티모달" (multimodal), "추론 비용" (inference cost), and "쿼리" (query). The Korean version follows natural Korean sentence structure while preserving the original message's professional and analytical nature.</td></tr>
<tr><td>And in the third place, we have established a solid product framework that was well with our capabilities to incorporate multimedia contents, which play a very important role in this whole process, which can help us to provide much easier to digest answers and aligns better with the users' behavior. And we have seen very clearly signs of improvement in the user experiences. The users who has been exposed to the AI generating search results are finding the information much more efficiently and exploring more types of queries and showing the stronger retentions. And therefore, we are actively investing to accelerate our AI transformations of search.</td><td>셋째로, 우리는 멀티미디어 콘텐츠를 통합할 수 있는 역량과 잘 부합하는 견고한 제품 프레임워크를 구축했습니다. 이는 전체 프로세스에서 매우 중요한 역할을 하며, 사용자들이 더욱 쉽게 이해할 수 있는 답변을 제공하고 사용자 행동 패턴과 더 잘 부합하도록 도와줍니다. 그리고 사용자 경험 측면에서 명확한 개선 징후를 확인했습니다. AI 기반 검색 결과에 노출된 사용자들은 정보를 훨씬 더 효율적으로 찾고 있으며, 더 다양한 유형의 검색어를 탐색하고 있고, 더 높은 리텐션을 보여주고 있습니다. 따라서 우리는 검색 서비스의 AI 전환을 가속화하기 위해 적극적으로 투자하고 있습니다.</td></tr>
<tr><td>On monetization, we are still very early had just starting to prepare for testing, Since our AI search differs significantly from the traditional search, the corresponding monetization approach needs to be rebuilt and refined and this takes some time. That said, we can see huge potential, perhaps currently, only a small percentage of the traditional search queries can be monetized, while the vast majority cannot. Over time, we anticipate AI search will greatly enhance our ability to monetize the long tail queries and previously untapped areas. And we expect more queries to become monetizable as compared to the traditional search.</td><td>수익화 측면에서는 아직 초기 단계로, 테스트를 위한 준비를 막 시작했습니다. 저희의 AI 검색은 기존의 전통적인 검색과는 상당히 다르기 때문에, 이에 상응하는 수익화 방식도 새롭게 구축하고 개선해야 하며, 이는 일정 시간이 소요될 것입니다. 하지만 저희는 이 분야에서 엄청난 잠재력을 확인할 수 있습니다. 현재는 전통적인 검색 쿼리 중 극히 일부만이 수익화가 가능하고 대다수는 그렇지 못한 상황입니다. 시간이 지남에 따라, AI 검색이 롱테일 쿼리와 이전에는 활용되지 않았던 영역의 수익화 능력을 크게 향상시킬 것으로 예상합니다. 또한 전통적인 검색에 비해 더 많은 쿼리가 수익화 가능한 형태로 전환될 것으로 기대하고 있습니다.</td></tr>
<tr><td>Plus, AI search can likely create formats that are more flexible and native and feed naturally into the new users' experiences. They can be less intrusive, but potentially even enhance overall expenses. And looking ahead, we believe that the long-term potential of this expanding monetization capabilities is quite promising, opening up the possibilities that go beyond what Chinese law search can achieve. While our clear move towards AI search will inevitably put a notable near term pressures on revenue and margin, I would still believe this is the right path to follow for the long term growth. Thank you, Alex. Operator<br><br>Your next question comes from Gary Yu with Morgan Stanley.</td><td>또한 AI 검색은 보다 유연하고 자연스러운 형태를 만들어내어 새로운 사용자 경험에 자연스럽게 녹아들 수 있습니다. 이는 덜 침습적이면서도 오히려 전반적인 지출을 증가시킬 수 있는 잠재력이 있습니다. 앞으로도 이러한 수익화 역량 확대의 장기적 잠재력은 매우 유망하며, 기존 중국 검색 광고가 달성할 수 있는 것을 넘어서는 가능성을 열어줄 것으로 믿습니다. AI 검색으로의 명확한 전환이 단기적으로는 불가피하게 매출과 마진에 상당한 압박을 가할 것이지만, 장기적 성장을 위해서는 이것이 올바른 방향이라고 확신합니다. 감사합니다, 알렉스.<br><br>진행자: <br>다음 질문은 모건스탠리의 게리 유 님께서 하시겠습니다.</td></tr>
<tr><td>Please go ahead. Gary Yu<br><br>Hi. Thank you, management. I have a question regarding robotaxi. Given the recent development in the robotaxi space, including some of the players announcing their new robotaxi vehicles and partnership with Uber. How do you feel the evolving competitive landscape and what differentiates by Baidu RT6 from other robotaxi vehicles? Also, are you exploring similar types of partnership like your peers? Should we expect faster expansion of Apollo Go this year? And lastly, what scale and unit economics are you targeting and how to think about the long term profitability potential? Thank you. Robin Li<br><br>Gary, we've been invested in autonomous driving for over 12 years.</td><td>네, Gary Yu 님 말씀해 주십시오.<br><br>안녕하세요. 경영진 여러분, 감사합니다. 로보택시에 관해 질문드리겠습니다. 최근 로보택시 분야에서 일부 업체들이 새로운 로보택시 차량을 발표하고 우버와 파트너십을 체결하는 등의 발전이 있었는데요. 이러한 경쟁 환경의 변화를 어떻게 보시는지, 그리고 바이두의 RT6가 다른 로보택시 차량과 비교해 어떤 차별점이 있는지 말씀해 주시겠습니까? 또한, 경쟁사들처럼 유사한 형태의 파트너십을 모색하고 계신가요? 올해 Apollo Go의 더 빠른 확장을 기대해도 될까요? 마지막으로, 목표로 하시는 규모와 단위당 경제성은 어떻게 되며, 장기적인 수익성 잠재력은 어떻게 전망하시는지요? 감사합니다.<br><br>Robin Li의 답변:<br><br>Gary님, 저희는 12년 이상 자율주행 분야에 투자해 왔습니다.</td></tr>
<tr><td>Today, Apollo Go is among the first and the very few players globally to operate autonomous ride-hailing services at scale, making us both China's largest and global leader in this space. RT6 is the world's first and as of today, the only purpose built maas produced Level 4 autonomous vehicle. It is designed from the ground up for fully driverless operations, with self-developed hardware design, algorithms and software and featuring top safety redundancy. RT6 is now running at meaningful scale across multiple cities. And its unit cost is below $30,000 far better than anyone else on the planet.</td><td>현재 Apollo Go는 전 세계적으로 대규모 자율주행 차량 호출 서비스를 운영하는 최초이자 소수의 기업 중 하나로서, 중국 내 최대 규모이자 글로벌 선도 기업의 위치를 차지하고 있습니다. RT6는 세계 최초이자 현재까지 유일한 대량 생산되는 레벨 4 자율주행 전용 차량입니다. RT6는 완전 무인 운행을 위해 처음부터 설계되었으며, 자체 개발한 하드웨어 설계, 알고리즘, 소프트웨어를 탑재하고 최고 수준의 안전 이중화 시스템을 갖추고 있습니다. RT6는 현재 여러 도시에서 의미 있는 규모로 운행되고 있으며, 대당 생산 단가가 3만 달러 미만으로, 전 세계 어떤 경쟁사보다도 훨씬 우수한 수준을 보여주고 있습니다.</td></tr>
<tr><td>With this unique strengths and proven business model, Apollo Go has been making steady progress in global expansion, most recently entering Dubai and Abu Dhabi. Altogether, our global footprint covers 15 cities, as I mentioned during the prepared remarks. And on expansion strategy, we are highly open and adaptive. We are ready to enter into any city worldwide. As long as regulations and conditions allow, we can enter quickly and scale efficiently. Our confidence comes from our long operating history, low cost structure and excellent safety record.</td><td>이러한 독보적인 강점과 검증된 비즈니스 모델을 바탕으로 Apollo Go는 최근 두바이와 아부다비에 진출하는 등 글로벌 확장에서 꾸준한 진전을 보이고 있습니다. 앞서 준비된 발표에서 언급했듯이, 저희의 글로벌 사업 영역은 총 15개 도시에 걸쳐 있습니다. 확장 전략과 관련하여, 저희는 매우 개방적이고 유연한 접근 방식을 취하고 있습니다. 전 세계 어느 도시라도 진출할 준비가 되어 있으며, 규제와 조건이 허용하는 한 신속하게 진입하여 효율적으로 규모를 확장할 수 있습니다. 이러한 자신감은 저희의 오랜 운영 경험과 낮은 비용 구조, 그리고 우수한 안전 기록에서 비롯됩니다.</td></tr>
<tr><td>With over 1,000 fully driverless vehicles deployed, we are expecting to see faster growth in our global fleet size, geographic range and right volumes this year and beyond. Meanwhile, we are proactively exploring new business models through partnerships, especially those that can scale fast and land quickly. We're in active discussions with various players, including ride-hailing platforms, fleet operators and more. While serious partnerships usually take time to work through all the details, some of them are already taking shape. We are happy to share progress that is really meaningful and concrete.</td><td>1,000대 이상의 완전 무인 자율주행 차량을 배치한 현재, 올해와 그 이후에는 글로벌 차량 규모, 지리적 범위, 그리고 운행량에서 더욱 빠른 성장을 기대하고 있습니다. 동시에 당사는 파트너십을 통해 새로운 비즈니스 모델을 적극적으로 모색하고 있으며, 특히 빠르게 확장하고 신속하게 안착할 수 있는 모델에 주목하고 있습니다. 현재 차량 호출 플랫폼, 차량 운영사 등 다양한 업체들과 적극적인 논의를 진행 중입니다. 중요한 파트너십의 경우 일반적으로 세부사항을 조율하는 데 시간이 소요되지만, 일부는 이미 구체화되고 있습니다. 실질적이고 의미 있는 진전 사항을 공유하게 되어 기쁘게 생각합니다.</td></tr>
<tr><td>Our strategic partnership with CAR Inc, Shenzhou Zuchu, our top auto rental -- China's top auto rental service provider is one example. And I'm sure there's more to come. Looking into the longer-term, we see a clear path to profitability as hardware and labor costs keep coming down and our growing operational scale brings more efficiencies. Given our leading position in both technology and operations, we are confident Apollo Go will continue to lead the field. We expect Apollo Go to be a key driver of Baidu's long-term growth. Thank you. Operator<br><br>Your next question comes from Miranda Zhuang with Bank of America Securities. Please go ahead.</td><td>중국 최대 렌터카 서비스 제공업체인 CAR Inc, 신주조처(神州租车)와의 전략적 파트너십이 그 한 예입니다. 앞으로도 이와 같은 협력이 더욱 늘어날 것으로 확신합니다. 장기적 관점에서 볼 때, 하드웨어 및 인건비가 지속적으로 감소하고 운영 규모 확대로 인한 효율성이 증가함에 따라 수익성 달성을 위한 명확한 경로가 보입니다. 기술과 운영 양면에서 우리의 선도적 위치를 고려할 때, Apollo Go가 계속해서 업계를 선도할 것이라 확신합니다. Apollo Go는 바이두의 장기 성장을 이끄는 핵심 동력이 될 것으로 기대됩니다. 감사합니다. <br><br>사회자: 다음 질문은 뱅크 오브 아메리카 증권의 미란다 쭝 애널리스트님께서 해주시겠습니다. 질문해 주시기 바랍니다.</td></tr>
<tr><td>Miranda Zhuang<br><br>Thank you for taking my questions and congrats on the good results. My question is about the competition. So, we see other AI applications are ramping users with enhanced models and offer more advanced functionalities like deep -- search or agent and some are leveraging existing large traffic super app platforms. So to this, how will Baidu compete with other AI application and platforms? Thank you. Robin Li<br><br>Thank you for your question. This is Julius. As I mentioned earlier, with AI evolving very quickly, people now have different ways and choices to find information and enjoy the contents.</td><td>Miranda Zhuang<br><br>질문에 답변해 주셔서 감사하고 좋은 실적을 달성하신 것을 축하드립니다. 제 질문은 경쟁 상황에 관한 것입니다. 현재 다른 AI 애플리케이션들이 향상된 모델을 통해 사용자를 확보하고 있으며, 심층 검색이나 에이전트와 같은 더욱 진보된 기능들을 제공하고 있습니다. 또한 일부는 기존의 대규모 트래픽을 보유한 슈퍼앱 플랫폼을 활용하고 있습니다. 이러한 상황에서 바이두는 다른 AI 애플리케이션 및 플랫폼들과 어떻게 경쟁할 계획인지 말씀해 주시겠습니까? 감사합니다.<br><br>Robin Li<br><br>질문 감사합니다. 저는 Julius입니다. 앞서 언급했듯이, AI가 매우 빠르게 진화하면서 사람들은 이제 정보를 찾고 콘텐츠를 즐기는 데 있어 다양한 방법과 선택지를 가지게 되었습니다.</td></tr>
<tr><td>So we understood early on that if we didn't take both steps to renovate search, we will be challenged sooner or later. That's why we were among the first major tech companies in China or globally to use AI to transform a legacy core business. In recent months, you have seen us accelerate these transformations. And as for AI chatbots specifically, for sure, they are one innovative form of AI applications. And we also have our own chatbot product, like, ERNIE bots, and we have also integrated conversational AI capabilities in the Baidu app. So I would say that AI chatbot represent one important exploration of AI applications, but they are now the ultimate form.</td><td>저희는 일찍부터 검색 서비스의 혁신을 위한 조치를 취하지 않으면 조만간 어려움에 직면하게 될 것이라는 점을 인식했습니다. 그래서 저희는 중국은 물론 전 세계 주요 기술 기업들 중에서도 선도적으로 AI를 도입하여 기존의 핵심 사업을 혁신하고자 했습니다. 최근 몇 달 동안 보셨듯이, 저희는 이러한 혁신을 가속화하고 있습니다. <br><br>AI 챗봇과 관련해서는, 이것이 AI 응용 분야의 혁신적인 형태 중 하나인 것은 분명합니다. 저희도 ERNIE 봇과 같은 자체 챗봇 제품을 보유하고 있으며, 바이두 앱에도 대화형 AI 기능을 통합했습니다. AI 챗봇은 AI 응용 분야에서 중요한 시도 중 하나를 대표한다고 할 수 있지만, 이것이 최종적인 형태는 아니라고 생각합니다.</td></tr>
<tr><td>Our goal is to find the most powerful applications that can create lasting value in these AI areas. So when we talk about the competition, it's not just about competing with the chatbots. I think it's about rethinking the value of search in AI times. From there, we have identified two directions, we are currently focused on. First, we believe AI search should efficiently meet the user needs while offering highly engaging experiences. Our AI search now looks very different from the traditional search. We prioritize the rich, impressive multimodal content that is easier to understand and nature to interact with. Second, we are reimaging the AI search to go beyond just finding information.</td><td>저희의 목표는 AI 분야에서 지속적인 가치를 창출할 수 있는 가장 강력한 애플리케이션을 발굴하는 것입니다. 따라서 경쟁에 대해 이야기할 때, 이는 단순히 챗봇과의 경쟁만을 의미하는 것이 아닙니다. AI 시대에서 검색의 가치를 재정립하는 것이 핵심이라고 생각합니다. 이러한 관점에서, 저희는 현재 집중하고 있는 두 가지 방향을 설정했습니다. 첫째, AI 검색은 사용자의 니즈를 효율적으로 충족시키는 동시에 매우 몰입도 높은 경험을 제공해야 한다고 믿습니다. 저희의 AI 검색은 이제 전통적인 검색과는 매우 다른 모습을 보여주고 있습니다. 저희는 이해하기 쉽고 자연스럽게 상호작용할 수 있는 풍부하고 인상적인 멀티모달 콘텐츠에 우선순위를 두고 있습니다. 둘째, 저희는 단순히 정보를 찾는 것을 넘어서는 AI 검색을 재구상하고 있습니다.</td></tr>
<tr><td>And our ambition is to expand the search to help users make decisions, provide solutions and ultimately deliver results. To support this, I think a key strategy initiative for us is to make Baidu more capable through innovative approaches like agents. Our agents today can already handle the users, handle complicated problems, support the decision making and connect them with the right qualities behind things. Looking ahead, we aim to further enhance our services capabilities through agents. This will now only improving the user experiences by meeting more needs, but also help our customers and our partners connect much better with users than before.</td><td>우리의 목표는 검색 기능을 확장하여 사용자들이 의사결정을 하고, 솔루션을 제공하며, 궁극적으로 결과물을 도출할 수 있도록 돕는 것입니다. 이를 지원하기 위해, 에이전트와 같은 혁신적인 접근 방식을 통해 바이두의 역량을 강화하는 것이 우리의 핵심 전략 이니셔티브라고 생각합니다. 현재 우리의 에이전트들은 이미 사용자들을 응대하고, 복잡한 문제를 처리하며, 의사결정을 지원하고, 그들을 적절한 서비스와 연결시켜 주고 있습니다. 앞으로 우리는 에이전트를 통해 서비스 역량을 더욱 강화하는 것을 목표로 하고 있습니다. 이는 더 많은 니즈를 충족시킴으로써 사용자 경험을 개선할 뿐만 아니라, 우리의 고객사들과 파트너들이 이전보다 사용자들과 훨씬 더 효과적으로 연결될 수 있도록 도울 것입니다.</td></tr>
<tr><td>Besides, we're also making Baidu more open. This quarter, we proactively embrace MCP and the third-party agents. On one hand, by connecting the third-party tools and capabilities, we are enabling the users and customers and the partners to even more -- to do even more things within our platform. And on the other hand, as we're also try to open up our capabilities through MCP. For example, our e-commerce MCP, by doing so, we are helping all parties in the ecosystem to benefit from greater flexibilities and unlock the broader opportunities, both within and beyond our platform.</td><td>또한 저희는 바이두를 더욱 개방적인 플랫폼으로 만들어가고 있습니다. 이번 분기에는 MCP(멀티 채널 파트너십)와 서드파티 에이전트들을 적극적으로 수용했습니다. 한편으로는 서드파티 도구와 기능들을 연동함으로써 사용자, 고객, 파트너들이 저희 플랫폼 내에서 더 많은 활동을 할 수 있도록 지원하고 있습니다. 다른 한편으로는 MCP를 통해 저희의 역량을 개방하고자 노력하고 있습니다. 예를 들어, 저희의 이커머스 MCP를 통해 생태계 내 모든 참여자들이 더 큰 유연성의 혜택을 누리고, 저희 플랫폼 내외에서 더 광범위한 기회를 창출할 수 있도록 돕고 있습니다.</td></tr>
<tr><td>And in the face of today's increasingly dynamic marketing, and we believe our innovative approaches can expand both the depth and breadth of what such can do and ultimately create the values for everyone in the ecosystem. Thank you. Operator<br><br>Your next question comes from Wei Xiong with UBS. Please go ahead. Wei Xiong<br><br>Hi. Good evening, management. Thank you for taking my question. I want to follow-up on the cloud side. So with accelerating enterprise AI adoption, how should we think about the enlarged TAM for China's cloud market? And how is our cloud business differentiated from competitors in terms of strategy, technology and customer base?</td><td>오늘날 점점 더 역동적으로 변화하는 마케팅 환경 속에서, 우리는 혁신적인 접근 방식을 통해 이러한 기능의 깊이와 범위를 확장하고 궁극적으로 생태계 내 모든 참여자들을 위한 가치를 창출할 수 있다고 믿습니다. 감사합니다. 오퍼레이터<br><br>다음 질문은 UBS의 웨이 시옹 님께서 하시겠습니다. 질문해 주시기 바랍니다. 웨이 시옹<br><br>안녕하세요, 경영진 여러분. 질문의 기회를 주셔서 감사합니다. 클라우드 부문에 대해 후속 질문을 드리고 싶습니다. 기업의 AI 도입이 가속화되는 상황에서, 중국 클라우드 시장의 확대된 TAM(전체 잠재 시장)에 대해 어떻게 전망하시는지요? 그리고 전략, 기술, 고객 기반 측면에서 우리의 클라우드 사업이 경쟁사와 어떤 차별화된 특징을 가지고 있는지 말씀해 주시겠습니까?</td></tr>
<tr><td>Also regarding the Qianfan platform, could you please maybe share more some updates here, which industries are seeing the fastest AI adoption and where do we see the largest long term potential? Thank you. Dou Shen<br><br>Thank you for the question. I'll take it. As AI adoption accelerates, the time for China's cloud market is expanding meaningfully, driven by changes across the stack. With foundation models driving up the need for a massive computing power, the abilities to build and manage large scale GPU clusters and to utilize GPUs effectively has become key competitive advantages. Meanwhile, as models evolve with different strengths and AI applications bring increasingly diverse needs.</td><td>Qianfan 플랫폼과 관련하여, 현재 어떤 산업에서 AI 도입이 가장 빠르게 진행되고 있으며, 장기적으로 가장 큰 잠재력을 보이는 분야가 어디인지 추가적인 업데이트 내용을 공유해 주시겠습니까? 감사합니다. Dou Shen<br><br>질문 감사합니다. 제가 답변 드리겠습니다. AI 도입이 가속화되면서 중국의 클라우드 시장은 전반적인 기술 스택의 변화에 힘입어 의미 있게 확장되고 있습니다. 기초 모델(foundation models)이 대규모 컴퓨팅 파워에 대한 수요를 증가시키면서, 대규모 GPU 클러스터를 구축하고 관리하는 능력, 그리고 GPU를 효과적으로 활용하는 능력이 핵심 경쟁 우위로 자리잡았습니다. 한편, 모델들이 각각 다른 강점을 가지고 발전하고 AI 애플리케이션들이 점차 다양한 요구사항을 가져오면서...</td></tr>
<tr><td>The cloud platforms with broad model portfolios and food stack capabilities are best positioned to offer the flexibility and scalability customers require. This industry shifts align perfectly with Baidu's positioning, making our unique AI capabilities increasingly valuable. Baidu is one of the very few cloud providers globally with end-to-end full-stack AI capabilities. So we offer China's most efficient AI cloud infrastructure, back end by strong GPU cluster management. This allows us to deliver high performance, stable and cost effective AI services, while continually improving training and inference efficiency. Qianfan, our MaaS platform is among the most advanced on the market.</td><td>광범위한 모델 포트폴리오와 풀스택 기능을 갖춘 클라우드 플랫폼들이 고객이 요구하는 유연성과 확장성을 제공하는 데 가장 유리한 위치에 있습니다. 이러한 산업의 변화는 바이두의 포지셔닝과 완벽하게 부합하며, 이는 당사의 독보적인 AI 역량의 가치를 더욱 높이고 있습니다. 바이두는 전 세계적으로 엔드투엔드 풀스택 AI 역량을 보유한 극소수의 클라우드 제공업체 중 하나입니다. 당사는 강력한 GPU 클러스터 관리를 기반으로 중국에서 가장 효율적인 AI 클라우드 인프라를 제공하고 있습니다. 이를 통해 학습 및 추론 효율성을 지속적으로 개선하면서도 고성능의 안정적이고 비용 효율적인 AI 서비스를 제공할 수 있습니다. 당사의 MaaS(Model-as-a-Service) 플랫폼인 첸판(Qianfan)은 시장에서 가장 진보된 플랫폼 중 하나입니다.</td></tr>
<tr><td>It offers a comprehensive model library covering both our ERNIE series and nearly all mainstream supporting and open source models. This quarter, so we further enhanced Qianfan’s to [indiscernible] with extended support for training and tuning and distillation especially for our newly added multimodel and reasoning models. Strategically, we remain firmly committed to an application driven approach. So as the AI landscape evolves, this approach positions us well to deliver differentiated value. We offer full-stack end-to-end AI products and solutions tailored to the needs of specific industries and scenarios.</td><td>당사는 자체 ERNIE 시리즈뿐만 아니라 거의 모든 주요 지원 및 오픈소스 모델을 포괄하는 종합적인 모델 라이브러리를 제공하고 있습니다. 이번 분기에는 특히 새롭게 추가된 멀티모달 및 추론 모델을 위한 학습, 튜닝, 증류 기능에 대한 확장된 지원을 통해 첨판(Qianfan)의 기능을 더욱 강화했습니다. 전략적 측면에서, 우리는 애플리케이션 중심 접근 방식에 계속해서 확고한 의지를 보이고 있습니다. AI 환경이 진화함에 따라, 이러한 접근 방식은 차별화된 가치를 제공하는 데 있어 우리에게 유리한 위치를 제공합니다. 당사는 특정 산업과 시나리오의 요구사항에 맞춘 풀스택 엔드투엔드 AI 제품 및 솔루션을 제공하고 있습니다.</td></tr>
<tr><td>By bringing AI into every aspect of their operations, so it'll help enterprises improve efficiency, reduce cost and eventually transform their interior workflows. With this [indiscernible], we have captured the opportunity presented by industry shift and repositioned ourselves as China's top tier cloud provider in the AI era. The increasing market recognition of our AI expertise continues to drive strong momentum in our client pipeline, as we build and deepen partnerships with leading enterprises. And we are also increasingly becoming the preferred choice for mid-tier businesses. As for enterprise adoption, so we are seeing rising interest across sectors.</td><td>AI를 기업 운영의 모든 측면에 도입함으로써, 기업들은 효율성을 개선하고 비용을 절감하며 궁극적으로 내부 업무 프로세스를 혁신할 수 있게 될 것입니다. 이러한 [청취불가] 상황에서, 저희는 산업 변화가 가져온 기회를 포착하여 AI 시대의 중국 최고 클라우드 제공업체로서 입지를 재정립했습니다. 저희의 AI 전문성에 대한 시장의 인정이 높아지면서 주요 기업들과의 파트너십을 구축하고 심화하는 과정에서 클라이언트 파이프라인이 지속적으로 강한 성장세를 보이고 있습니다. 또한 저희는 중견기업들의 선호도 높은 선택지로 자리잡고 있습니다. 기업 도입 측면에서는 전 산업 부문에 걸쳐 관심이 증가하는 것을 확인하고 있습니다.</td></tr>
<tr><td>Early movers like Internet, tech and online education companies are adopting AI quickly, while others such as automotive, financial services, utilities and the public sector are also actively exploring with openness. So as technology advances and costs decline, we're ready to lead the next wave of enterprise AI adoption and translate innovation into real world value. Thank you. Operator<br><br>Your next question comes from Thomas Chong with Jefferies. Please go ahead. Thomas Chong<br><br>Hi. Good evening. Thanks, management for taking my questions. Can management elaborate about the overall capital allocation trend and the key priorities for 2025? Thank you. Junjie He<br><br>Hi, Thomas. This is Jackson.</td><td>인터넷, 기술, 온라인 교육 기업과 같은 선도 기업들이 AI를 빠르게 도입하고 있으며, 자동차, 금융 서비스, 유틸리티 및 공공 부문과 같은 다른 산업들도 개방적인 자세로 적극적으로 탐색하고 있습니다. 따라서 기술이 발전하고 비용이 감소함에 따라, 우리는 기업 AI 도입의 다음 물결을 주도하고 혁신을 실질적인 가치로 전환할 준비가 되어 있습니다. 감사합니다. 진행자<br><br>다음 질문은 제프리스의 토마스 총 애널리스트님께서 하시겠습니다. 말씀해 주시기 바랍니다. 토마스 총<br><br>안녕하세요. 질문에 답변해 주셔서 감사합니다. 경영진께서는 전반적인 자본 배분 동향과 2025년 주요 우선순위에 대해 자세히 설명해 주실 수 있으신가요? 감사합니다. 준지에 허<br><br>안녕하세요, 토마스님. 잭슨입니다.</td></tr>
<tr><td>I will take your call. So, we are firmly committed to our investments in AI. So, as we believe this will generate meaningful returns over the long-term. So, when quantifying such investments, please note our AI investments are reflected not only in CapEx, but also in operating cash flow outflow. So we are taking these two together, so our total AI investments in 2024 significantly increased from 2023, reflecting our conviction in the huge future growth potentials. In 2025, we plan to continue to increase our AI investment to further solidify our AI foundation and prepare for future growth. So, let me walk through the key areas that we are now focusing on. The first in AI cloud business.</td><td>질문 받도록 하겠습니다. 당사는 AI 투자에 확고한 의지를 가지고 있습니다. 이러한 투자가 장기적으로 의미 있는 수익을 창출할 것이라고 믿기 때문입니다. AI 투자 규모를 정량화할 때 유의하실 점은, 당사의 AI 투자가 설비투자(CapEx)뿐만 아니라 영업현금흐름 유출에도 반영되어 있다는 것입니다. 이 두 가지를 종합적으로 고려했을 때, 2024년 총 AI 투자 규모는 2023년 대비 크게 증가했으며, 이는 미래 성장 잠재력에 대한 당사의 확신을 반영한 것입니다. 2025년에도 AI 기반을 더욱 공고히 하고 미래 성장을 준비하기 위해 AI 투자를 계속 확대할 계획입니다. 그럼 현재 당사가 주력하고 있는 핵심 분야들을 설명드리도록 하겠습니다. 첫 번째는 AI 클라우드 사업입니다.</td></tr>
<tr><td>We are investing in AI infra to meet rising market demand driven by accelerating AI adoption. So, this is prompting us to quickly scale up our AI infra to capture emerging opportunities. As you've seen, our AI Cloud revenue grew 42% year-over-year this quarter with non-GAAP operating margin in the teens. Secondly, we continue to invest in advancing our earning models. Ongoing technical progress has enabled us to train better models more efficiently and at a lower cost. As a result, we brought a series of high quality earning models to market in quick succession. Also, we are investing in autonomous driving technology.</td><td>우리는 AI 도입 가속화로 인한 시장 수요 증가에 대응하기 위해 AI 인프라에 투자하고 있습니다. 이에 따라 새롭게 부상하는 기회를 포착하기 위해 AI 인프라를 신속하게 확장하고 있습니다. 보시다시피, 당사의 AI 클라우드 매출은 이번 분기에 전년 대비 42% 성장했으며, 비(非)GAAP 영업이익률은 10%대를 기록했습니다. <br><br>둘째로, 우리는 수익 모델 발전에 지속적으로 투자하고 있습니다. 지속적인 기술 진보를 통해 더 나은 모델을 더욱 효율적이고 낮은 비용으로 학습시킬 수 있게 되었습니다. 그 결과, 우리는 일련의 고품질 수익 모델들을 빠른 속도로 시장에 출시할 수 있었습니다. 또한, 우리는 자율주행 기술에도 투자를 진행하고 있습니다.</td></tr>
<tr><td>Last quarter, Apollo Go validated its business model in its large operational area in China. This milestone has motivated us to move faster in expansion, including entering the Middle East market, while revenue volume continues to accelerate across our existing operations. We will continue this momentum going forward. Lastly, we continue to invest in AI search transformation with a focus on user experience. As Julius said, when we step up this investment, while monetization for AI search results remains at early stage, we do expect some margin pressure in the near term, but we see this as a necessary step to unlock long term growth.</td><td>지난 분기에 Apollo Go는 중국의 광범위한 운영 지역에서 비즈니스 모델의 타당성을 입증했습니다. 이러한 이정표적 성과는 기존 사업장에서의 매출 규모가 지속적으로 가속화되는 가운데, 중동 시장 진출을 포함한 사업 확장을 더욱 가속화하도록 하는 동기가 되었습니다. 앞으로도 이러한 모멘텀을 이어갈 것입니다. 마지막으로, 당사는 사용자 경험에 중점을 둔 AI 검색 혁신에 지속적으로 투자하고 있습니다. Julius가 언급했듯이, 이러한 투자를 확대함에 따라 AI 검색 결과의 수익화는 아직 초기 단계에 있어 단기적으로는 일정 수준의 마진 압박이 예상되지만, 이는 장기적 성장을 위한 필수적인 단계라고 판단하고 있습니다.</td></tr>
<tr><td>Another key focus of our capital allocation is shareholder returns. As I said earlier, since last year, we have significantly accelerated our share repurchase (ph) program. We further repurchased $445 million from the beginning of Q1 this year. These are strongest repurchase efforts in the past three years. We expect to keep a similar pace this year, reflecting our long standing commitment to shareholders and our confidence in our long term growth. Thank you. Operator<br><br>Ladies and gentlemen, that does conclude our conference for today. Thank you for participating. You may now all disconnect.</td><td>자본 배분에 있어 또 다른 주요 초점은 주주 환원입니다. 앞서 말씀드린 바와 같이, 작년부터 자사주 매입(ph) 프로그램을 크게 가속화했습니다. 올해 1분기 초부터 4억 4,500만 달러 규모의 추가 자사주를 매입했습니다. 이는 지난 3년간 가장 강력한 자사주 매입 규모입니다. 주주들에 대한 우리의 오랜 약속과 장기 성장에 대한 자신감을 반영하여, 올해도 비슷한 수준의 매입 속도를 유지할 것으로 예상합니다. 감사합니다. 오퍼레이터<br><br>여러분, 이것으로 오늘 컨퍼런스를 마치겠습니다. 참여해 주셔서 감사합니다. 이제 모두 연결을 종료하시면 됩니다.</td></tr>
    </table>
    <h3>📌 요약</h3>
    <p style="background:#f0f0f0; padding:15px; border-left: 5px solid #333;">• 핵심 재무/사업 성과:<br>- AI 클라우드 매출 42% YoY 성장, 비GAAP 영업이익률 10%대 기록<br>- 모바일 검색 결과의 35%가 AI 생성 콘텐츠로 전환 (1월 22%에서 상승)<br>- 로보택시 서비스 Apollo Go 15개 도시로 확장, 차량 단가 $30,000 이하 달성<br><br>• AI 전략 방향:<br>- ERNIE 모델 지속 개선 및 6월 30일 ERNIE 4.5 오픈소스 공개 예정<br>- 추론 비용 지속 감소 중이며, ERNIE 4.5 Turbo는 4.1 대비 80% 비용 절감<br>- 응용 중심 접근법 유지하며 실제 활용 가치가 있는 영역에 집중<br><br>• 리스크/도전 과제:<br>- AI 검색 전환에 따른 단기 수익성 압박 예상<br>- 미국의 AI칩 수출 제한에 대응하여 국산 칩/소프트웨어 스택 개발 필요<br>- AI 검색 수익화는 초기 단계로 새로운 모델 개발 중<br><br>• 투자/자본 배분:<br>- 2024년 AI 투자 규모 전년 대비 큰 폭 증가<br>- Q1에만 $445M 자사주 매입 진행, 연간 비슷한 수준 유지 계획<br>- AI 인프라, 모델 개발, 자율주행, 검색 전환이 주</p>
    <hr style="margin:50px 0;">
    
</body></html>