<!DOCTYPE html>
<html><head><meta charset="UTF-8">
<title>Earnings Call ë²ˆì—­</title>
<style>
    body { font-family: Arial; margin: 40px; background-color: #fdfdfd; }
    h1 { text-align: center; }
    h2 { margin-top: 50px; color: #003366; }
    h3 { color: #333; }
    table { border: 1px solid #ddd; width: 100%; border-collapse: collapse; }
    th { background: #f0f0f0; padding: 10px; border-bottom: 2px solid #ccc; }
    td { padding: 10px; border-bottom: 1px dotted #ccc; vertical-align: top; }
    p { line-height: 1.6; }
    hr { margin: 50px 0; border: none; border-top: 1px solid #ccc; }
    .back-button {
        display: inline-block;
        background-color: #5f5f5f;
        color: white;
        padding: 10px 16px;
        border-radius: 6px;
        text-decoration: none;
        font-weight: 500;
        box-shadow: 0 2px 6px rgba(0,0,0,0.1);
        margin-bottom: 30px;
    }
</style>
</head><body>
<a href="../../index.html" class="back-button">â†</a>
<h1>ğŸ“„ Earnings Call Transcript ë²ˆì—­ ê²°ê³¼</h1>

    <h2>ğŸ“Š Presentation</h2>
    <table style="width:100%; border-collapse:collapse; margin-bottom: 40px;">
        <tr>
            <th style="width:50%; border-bottom: 2px solid #333;">Original</th>
            <th style="width:50%; border-bottom: 2px solid #333;">Translation</th>
        </tr>
        <tr><td>NVIDIA Corporation (NVDA) Q3 2026 Earnings Call November 19, 2025 5:00 PM EST<br><br>Company Participants<br><br>Toshiya Hari - Vice President of Investor Relations & Strategic Finance<br>Colette Kress - Executive VP & CFO<br>Jen-Hsun Huang - Co-Founder, CEO, President & Director<br><br>Conference Call Participants<br><br>Joseph Moore - Morgan Stanley, Research Division<br>Christopher Muse - Cantor Fitzgerald & Co., Research Division<br>Vivek Arya - BofA Securities, Research Division<br>Benjamin Reitzes - Melius Research LLC<br>James Schneider - Goldman Sachs Group, Inc., Research Division<br>Timothy Arcuri - UBS Investment Bank, Research Division<br>Stacy Rasgon - Sanford C.</td><td># ì—”ë¹„ë””ì•„ ì½”í¼ë ˆì´ì…˜ (NVDA) 2026ë…„ 3ë¶„ê¸° ì‹¤ì  ë°œí‘œ ì»¨í¼ëŸ°ìŠ¤ ì½œ<br>2025ë…„ 11ì›” 19ì¼ ì˜¤í›„ 5ì‹œ (ë¯¸êµ­ ë™ë¶€ í‘œì¤€ì‹œ)<br><br>## íšŒì‚¬ ì°¸ì„ì<br><br>**í† ì‹œì•¼ í•˜ë¦¬** - íˆ¬ìì ê´€ê³„ ë° ì „ëµ ì¬ë¬´ ë¶€ì‚¬ì¥<br>**ì½œë ˆíŠ¸ í¬ë ˆìŠ¤** - ìµœê³ ì¬ë¬´ì±…ì„ì(CFO) ê²¸ ì „ë¬´ì´ì‚¬<br>**ì  ìŠ¨ í™©** - ê³µë™ì°½ì—…ì, ìµœê³ ê²½ì˜ì(CEO), ì‚¬ì¥ ê²¸ ì´ì‚¬<br><br>## ì»¨í¼ëŸ°ìŠ¤ ì½œ ì°¸ì„ ì• ë„ë¦¬ìŠ¤íŠ¸<br><br>**ì¡°ì…‰ ë¬´ì–´** - ëª¨ê±´ìŠ¤íƒ ë¦¬, ë¦¬ì„œì¹˜ ë¶€ë¬¸<br>**í¬ë¦¬ìŠ¤í† í¼ ë®¤ì¦ˆ** - ìº”í„° í”¼ì¸ ì œëŸ´ë“œ, ë¦¬ì„œì¹˜ ë¶€ë¬¸<br>**ë¹„ë²¡ ì•„ë¦¬ì•¼** - ë±…í¬ì˜¤ë¸Œì•„ë©”ë¦¬ì¹´ ì¦ê¶Œ, ë¦¬ì„œì¹˜ ë¶€ë¬¸<br>**ë²¤ìë¯¼ ë¼ì´ì²´ìŠ¤** - ë©œë¦¬ìš°ìŠ¤ ë¦¬ì„œì¹˜<br>**ì œì„ìŠ¤ ìŠˆë‚˜ì´ë”** - ê³¨ë“œë§Œì‚­ìŠ¤ ê·¸ë£¹, ë¦¬ì„œì¹˜ ë¶€ë¬¸<br>**í‹°ëª¨ì‹œ ì•„ì¿ ë¦¬** - UBS ì¸ë² ìŠ¤íŠ¸ë¨¼íŠ¸ ë±…í¬, ë¦¬ì„œì¹˜ ë¶€ë¬¸<br>**ìŠ¤í…Œì´ì‹œ ë¼ìŠ¤ê³¤** - ìƒŒí¬ë“œ C.</td></tr>
<tr><td>Bernstein & Co., LLC., Research Division<br>Aaron Rakers - Wells Fargo Securities, LLC, Research Division<br><br>Presentation<br><br>Operator<br><br>Good afternoon. My name is Sarah, and I will be your conference operator today. At this time, I would like to welcome everyone to NVIDIA's Third Quarter Earnings Call. [Operator Instructions]. Toshiya Hari, you may begin your conference. Toshiya Hari<br>Vice President of Investor Relations & Strategic Finance<br><br>Thank you. Good afternoon, everyone, and welcome to NVIDIA's conference call for the third quarter of fiscal 2026.</td><td>ì¢‹ì€ ì˜¤í›„ì…ë‹ˆë‹¤. ì €ëŠ” ì‚¬ë¼ì´ë©°, ì˜¤ëŠ˜ ì—¬ëŸ¬ë¶„ì˜ ì»¨í¼ëŸ°ìŠ¤ ì§„í–‰ìë¥¼ ë§¡ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. ì§€ê¸ˆë¶€í„° NVIDIAì˜ 3ë¶„ê¸° ì‹¤ì  ë°œí‘œ ì»¨í¼ëŸ°ìŠ¤ ì½œì„ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤. [ìš´ì˜ì ì•ˆë‚´ì‚¬í•­]. í† ì‹œì•¼ í•˜ë¦¬ ë‹˜, ì»¨í¼ëŸ°ìŠ¤ë¥¼ ì‹œì‘í•˜ì…”ë„ ë©ë‹ˆë‹¤.<br><br>í† ì‹œì•¼ í•˜ë¦¬<br>íˆ¬ìì ê´€ê³„ ë° ì „ëµ ì¬ë¬´ ë‹´ë‹¹ ë¶€ì‚¬ì¥<br><br>ê°ì‚¬í•©ë‹ˆë‹¤. ì¢‹ì€ ì˜¤í›„ì…ë‹ˆë‹¤, ì—¬ëŸ¬ë¶„. NVIDIAì˜ 2026 íšŒê³„ì—°ë„ 3ë¶„ê¸° ì»¨í¼ëŸ°ìŠ¤ ì½œì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤.</td></tr>
<tr><td>With me today from NVIDIA are Jensen Huang, President and Chief Executive Officer; and Colette Kress, Executive Vice President and Chief Financial Officer. I'd like to remind you that our call is being webcast live on NVIDIA's Investor Relations website. The webcast will be available for replay until the conference call to discuss our financial results for the fourth quarter of fiscal 2026. The content of today's call is NVIDIA's property. It can't be reproduced or transcribed without our prior written consent. During this call, we may make forward-looking statements based on current expectations.</td><td>ì˜¤ëŠ˜ NVIDIAì—ì„œ ì  ìŠ¨ í™©(Jensen Huang) ì‚¬ì¥ ê²¸ ìµœê³ ê²½ì˜ìì™€ ì½œë ˆíŠ¸ í¬ë ˆìŠ¤(Colette Kress) ì „ë¬´ì´ì‚¬ ê²¸ ìµœê³ ì¬ë¬´ì±…ì„ìê°€ í•¨ê»˜ ìë¦¬í–ˆìŠµë‹ˆë‹¤. ë³¸ ì»¨í¼ëŸ°ìŠ¤ ì½œì€ NVIDIA íˆ¬ìì ê´€ê³„(Investor Relations) ì›¹ì‚¬ì´íŠ¸ë¥¼ í†µí•´ ì‹¤ì‹œê°„ìœ¼ë¡œ ì›¹ìºìŠ¤íŠ¸ë˜ê³  ìˆìŒì„ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤. ì´ ì›¹ìºìŠ¤íŠ¸ëŠ” 2026 íšŒê³„ì—°ë„ 4ë¶„ê¸° ì¬ë¬´ ì‹¤ì ì„ ë…¼ì˜í•˜ëŠ” ì»¨í¼ëŸ°ìŠ¤ ì½œê¹Œì§€ ë‹¤ì‹œë³´ê¸°ë¡œ ì œê³µë  ì˜ˆì •ì…ë‹ˆë‹¤. ì˜¤ëŠ˜ ì»¨í¼ëŸ°ìŠ¤ ì½œì˜ ë‚´ìš©ì€ NVIDIAì˜ ìì‚°ì´ë©°, ë‹¹ì‚¬ì˜ ì‚¬ì „ ì„œë©´ ë™ì˜ ì—†ì´ëŠ” ë³µì œí•˜ê±°ë‚˜ ì „ì‚¬(è½‰å¯«)í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë³¸ ì»¨í¼ëŸ°ìŠ¤ ì½œ ì¤‘ì— ë‹¹ì‚¬ëŠ” í˜„ì¬ì˜ ì˜ˆìƒì— ê¸°ë°˜í•œ ë¯¸ë˜ì˜ˆì¸¡ì§„ìˆ (forward-looking statements)ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</td></tr>
<tr><td>These are subject to a number of significant risks and uncertainties, and our actual results may differ materially. For a discussion of factors that could affect our future financial results and business, please refer to the disclosure in today's earnings release, our most recent Forms 10-K and 10-Q. And the reports that we may file on Form 8-K with the Securities and Exchange Commission. All our statements are made as of today, November 19, 2025, based on information currently available to us. Except as required by law, we assume no obligation to update any such statements. During this call, we will discuss non-GAAP financial measures.</td><td>ì´ëŸ¬í•œ ë‚´ìš©ë“¤ì€ ë‹¤ìˆ˜ì˜ ì¤‘ìš”í•œ ìœ„í—˜ê³¼ ë¶ˆí™•ì‹¤ì„±ì„ ìˆ˜ë°˜í•˜ë©°, ë‹¹ì‚¬ì˜ ì‹¤ì œ ê²°ê³¼ëŠ” í¬ê²Œ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¹ì‚¬ì˜ ë¯¸ë˜ ì¬ë¬´ ì‹¤ì ê³¼ ì‚¬ì—…ì— ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆëŠ” ìš”ì¸ë“¤ì— ëŒ€í•œ ë…¼ì˜ëŠ” ì˜¤ëŠ˜ ë°œí‘œëœ ì‹¤ì  ìë£Œ, ë‹¹ì‚¬ì˜ ìµœê·¼ Form 10-K ë° 10-Q, ê·¸ë¦¬ê³  ì¦ê¶Œê±°ë˜ìœ„ì›íšŒì— ì œì¶œí•  ìˆ˜ ìˆëŠ” Form 8-K ë³´ê³ ì„œì˜ ê³µì‹œ ë‚´ìš©ì„ ì°¸ì¡°í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤. ëª¨ë“  ì§„ìˆ ì€ í˜„ì¬ ë‹¹ì‚¬ê°€ ì´ìš© ê°€ëŠ¥í•œ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì˜¤ëŠ˜, 2025ë…„ 11ì›” 19ì¼ ê¸°ì¤€ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤. ë²•ë¥ ì—ì„œ ìš”êµ¬í•˜ëŠ” ê²½ìš°ë¥¼ ì œì™¸í•˜ê³ , ë‹¹ì‚¬ëŠ” ì´ëŸ¬í•œ ì§„ìˆ ì„ ì—…ë°ì´íŠ¸í•  ì˜ë¬´ë¥¼ ì§€ì§€ ì•ŠìŠµë‹ˆë‹¤. ë³¸ ì»¨í¼ëŸ°ìŠ¤ ì½œì—ì„œëŠ” ë¹„-GAAP ì¬ë¬´ ì§€í‘œì— ëŒ€í•´ ë…¼ì˜í•  ì˜ˆì •ì…ë‹ˆë‹¤.</td></tr>
<tr><td>You can find a reconciliation of these non-GAAP measures to GAAP financial measures in our CFO Commentary which is posted on our website. With that, let me turn the call over to Colette. Colette Kress<br>Executive VP & CFO<br><br>Thank you, Toshiya. We delivered another outstanding quarter with revenue of $57 billion, up 62% and a record sequential revenue growth of $10 billion or 22%. Our customers continued to lean into 3 platform shifts, fueling exponential growth for accelerated computing, powerful AI models and agentic applications yet we are still in the early innings of these transitions that will impact our work across every industry.</td><td>ì´ëŸ¬í•œ ë¹„GAAP ì§€í‘œì™€ GAAP ì¬ë¬´ ì§€í‘œ ê°„ì˜ ì¡°ì • ë‚´ì—­ì€ ë‹¹ì‚¬ ì›¹ì‚¬ì´íŠ¸ì— ê²Œì‹œëœ CFO ë…¼í‰ì—ì„œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¼ ì½œë ›ì—ê²Œ ë°œì–¸ê¶Œì„ ë„˜ê¸°ê² ìŠµë‹ˆë‹¤.<br><br>ì½œë › í¬ë ˆìŠ¤<br>ë¶€ì‚¬ì¥ ê²¸ CFO<br><br>ê°ì‚¬í•©ë‹ˆë‹¤, í† ì‹œì•¼. ìš°ë¦¬ëŠ” ë§¤ì¶œ 570ì–µ ë‹¬ëŸ¬ë¡œ ì „ë…„ ëŒ€ë¹„ 62% ì¦ê°€í•˜ë©° ë˜ í•œ ë²ˆ íƒì›”í•œ ë¶„ê¸° ì‹¤ì ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤. ì´ëŠ” ì „ ë¶„ê¸° ëŒ€ë¹„ 100ì–µ ë‹¬ëŸ¬ ë˜ëŠ” 22% ì¦ê°€í•œ ê¸°ë¡ì ì¸ ìˆœì°¨ ë§¤ì¶œ ì„±ì¥ì…ë‹ˆë‹¤. ìš°ë¦¬ ê³ ê°ë“¤ì€ ê°€ì† ì»´í“¨íŒ…, ê°•ë ¥í•œ AI ëª¨ë¸, ê·¸ë¦¬ê³  ì—ì´ì „í‹± ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ê¸°í•˜ê¸‰ìˆ˜ì  ì„±ì¥ì„ ê²¬ì¸í•˜ëŠ” ì„¸ ê°€ì§€ í”Œë«í¼ ì „í™˜ì— ì§€ì†ì ìœ¼ë¡œ ì§‘ì¤‘í•˜ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ìš°ë¦¬ëŠ” ì—¬ì „íˆ ëª¨ë“  ì‚°ì—… ë¶„ì•¼ì˜ ì—…ë¬´ì— ì˜í–¥ì„ ë¯¸ì¹  ì´ëŸ¬í•œ ì „í™˜ì˜ ì´ˆê¸° ë‹¨ê³„ì— ìˆìŠµë‹ˆë‹¤.</td></tr>
<tr><td>We currently have visibility to $0.5 trillion in Blackwell and Rubin revenue from the start of this year through the end of calender year 2026. By executing our annual product cadence and extending our performance leadership through full stack design we believe NVIDIA will be the superior choice for the $3 trillion to $4 trillion in annual AI infrastructure build we estimate by the end of the decade. Demand for AI infrastructure continues to exceed our expectations. The clouds are sold out and our GPU installed base, both new and previous generations, including Blackwell, Hopper and Ampere is fully utilized.</td><td>í˜„ì¬ ìš°ë¦¬ëŠ” ì˜¬í•´ ì´ˆë¶€í„° 2026ë…„ ë§ê¹Œì§€ Blackwellê³¼ Rubinì—ì„œ 5ì²œì–µ ë‹¬ëŸ¬ì˜ ë§¤ì¶œ ê°€ì‹œì„±ì„ í™•ë³´í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì—°ê°„ ì œí’ˆ ì¶œì‹œ ì£¼ê¸°ë¥¼ ì‹¤í–‰í•˜ê³  í’€ìŠ¤íƒ ì„¤ê³„ë¥¼ í†µí•´ ì„±ëŠ¥ ë¦¬ë”ì‹­ì„ í™•ëŒ€í•¨ìœ¼ë¡œì¨, NVIDIAëŠ” 2020ë…„ëŒ€ ë§ê¹Œì§€ ì—°ê°„ 3ì¡°~4ì¡° ë‹¬ëŸ¬ ê·œëª¨ë¡œ ì¶”ì •ë˜ëŠ” AI ì¸í”„ë¼ êµ¬ì¶• ì‹œì¥ì—ì„œ ìµœê³ ì˜ ì„ íƒì´ ë  ê²ƒìœ¼ë¡œ ë¯¿ìŠµë‹ˆë‹¤. AI ì¸í”„ë¼ì— ëŒ€í•œ ìˆ˜ìš”ëŠ” ê³„ì†í•´ì„œ ìš°ë¦¬ì˜ ì˜ˆìƒì„ ì´ˆê³¼í•˜ê³  ìˆìŠµë‹ˆë‹¤. í´ë¼ìš°ë“œëŠ” ë§¤ì§„ ìƒíƒœì´ë©°, Blackwell, Hopper, Ampereë¥¼ í¬í•¨í•œ ì‹ êµ¬ ì„¸ëŒ€ì˜ GPU ì„¤ì¹˜ ê¸°ë°˜ì€ ëª¨ë‘ ì™„ì „íˆ ê°€ë™ë˜ê³  ìˆìŠµë‹ˆë‹¤.</td></tr>
<tr><td>Record Q3 data center revenue of $51 billion (sic) [ $51.2 billion ] increased 66% year-over-year, a significant feat at our scale. Compute grew 56% year-over-year, driven primarily by the GB300 ramp, while networking more than doubled, given the onset of NVLink scale up and robust double-digit growth across Spectrum-X Ethernet and Quantum-X InfiniBand. The world hyperscalers, a trillion-dollar industry are transforming search recommendations and content understanding from classical machine learning to generative AI. NVIDIA CUDA excels at both and is the ideal platform for this transition. Driving infrastructure investment measured in hundreds of billions of dollars.</td><td>3ë¶„ê¸° ë°ì´í„°ì„¼í„° ë¶€ë¬¸ ë§¤ì¶œì€ 512ì–µ ë‹¬ëŸ¬ë¡œ ì‚¬ìƒ ìµœê³ ì¹˜ë¥¼ ê¸°ë¡í•˜ë©° ì „ë…„ ë™ê¸° ëŒ€ë¹„ 66% ì¦ê°€í–ˆìŠµë‹ˆë‹¤. ì´ëŠ” ìš°ë¦¬ ê·œëª¨ì—ì„œ ë§¤ìš° ì˜ë¯¸ ìˆëŠ” ì„±ê³¼ì…ë‹ˆë‹¤. ì»´í“¨íŒ… ë¶€ë¬¸ì€ GB300 ë¨í”„ì—…ì— í˜ì…ì–´ ì „ë…„ ëŒ€ë¹„ 56% ì„±ì¥í–ˆìœ¼ë©°, ë„¤íŠ¸ì›Œí‚¹ ë¶€ë¬¸ì€ NVLink ìŠ¤ì¼€ì¼ì—… ì‹œì‘ê³¼ Spectrum-X ì´ë”ë„· ë° Quantum-X ì¸í”¼ë‹ˆë°´ë“œì˜ ê²¬ì¡°í•œ ë‘ ìë¦¿ìˆ˜ ì„±ì¥ì— í˜ì…ì–´ ë‘ ë°° ì´ìƒ ì¦ê°€í–ˆìŠµë‹ˆë‹¤.<br><br>1ì¡° ë‹¬ëŸ¬ ê·œëª¨ì˜ ì‚°ì—…ì¸ ê¸€ë¡œë²Œ í•˜ì´í¼ìŠ¤ì¼€ì¼ëŸ¬ë“¤ì€ ê²€ìƒ‰, ì¶”ì²œ, ì½˜í…ì¸  ì´í•´ ë¶„ì•¼ë¥¼ ê¸°ì¡´ ë¨¸ì‹ ëŸ¬ë‹ì—ì„œ ìƒì„±í˜• AIë¡œ ì „í™˜í•˜ê³  ìˆìŠµë‹ˆë‹¤. NVIDIA CUDAëŠ” ë‘ ì˜ì—­ ëª¨ë‘ì—ì„œ íƒì›”í•œ ì„±ëŠ¥ì„ ë°œíœ˜í•˜ë©° ì´ëŸ¬í•œ ì „í™˜ì„ ìœ„í•œ ì´ìƒì ì¸ í”Œë«í¼ì…ë‹ˆë‹¤. ì´ëŠ” ìˆ˜ì²œì–µ ë‹¬ëŸ¬ ê·œëª¨ì˜ ì¸í”„ë¼ íˆ¬ìë¥¼ ê²¬ì¸í•˜ê³  ìˆìŠµë‹ˆë‹¤.</td></tr>
<tr><td>At Meta, AI recommendation systems are delivering higher quality and more relevant content, leading to more time spent on apps such as Facebook and Threads, any expectations for the top CSPs and hyperscalers in 2026, aggregate CapEx have continued to increase and now sit roughly at $600 billion, more than $200 billion higher relative to the start of the year. We see the transition to accelerate computing in generative AI across current hyper workloads contributing toward roughly half of our long-term opportunity.</td><td>ë©”íƒ€ì—ì„œëŠ” AI ì¶”ì²œ ì‹œìŠ¤í…œì´ ë” ë†’ì€ í’ˆì§ˆê³¼ ê´€ë ¨ì„± ë†’ì€ ì½˜í…ì¸ ë¥¼ ì œê³µí•˜ë©´ì„œ í˜ì´ìŠ¤ë¶ê³¼ ìŠ¤ë ˆë“œì™€ ê°™ì€ ì•±ì—ì„œ ì‚¬ìš© ì‹œê°„ì´ ì¦ê°€í•˜ê³  ìˆìŠµë‹ˆë‹¤. 2026ë…„ ì£¼ìš” CSP(í†µì‹  ì„œë¹„ìŠ¤ ì œê³µì—…ì²´)ì™€ í•˜ì´í¼ìŠ¤ì¼€ì¼ëŸ¬ë“¤ì— ëŒ€í•œ ì „ë§ì„ ë³´ë©´, ì´ ìë³¸ì§€ì¶œ(CapEx)ì´ ì§€ì†ì ìœ¼ë¡œ ì¦ê°€í•˜ì—¬ í˜„ì¬ ì•½ 6,000ì–µ ë‹¬ëŸ¬ ìˆ˜ì¤€ìœ¼ë¡œ, ì—°ì´ˆ ëŒ€ë¹„ 2,000ì–µ ë‹¬ëŸ¬ ì´ìƒ ì¦ê°€í–ˆìŠµë‹ˆë‹¤. ìš°ë¦¬ëŠ” í˜„ì¬ í•˜ì´í¼ìŠ¤ì¼€ì¼ ì›Œí¬ë¡œë“œ ì „ë°˜ì— ê±¸ì¹œ ê°€ì† ì»´í“¨íŒ…ê³¼ ìƒì„±í˜• AIë¡œì˜ ì „í™˜ì´ ìš°ë¦¬ì˜ ì¥ê¸° ê¸°íšŒ ì¤‘ ì•½ ì ˆë°˜ì— ê¸°ì—¬í•  ê²ƒìœ¼ë¡œ ë³´ê³  ìˆìŠµë‹ˆë‹¤.</td></tr>
<tr><td>Another growth pillar is the ongoing increase in compute spend driven by foundation model builders such as Anthropic, Mistral, OpenAI, Reflection, Safe Superintelligence, Thinking Machines Lab and xAI, all scaling, compute aggressively to scale intelligence. The 3 scaling laws, pretraining post training and inference remain intact, in fact, we see a positive virtuous cycle emerging whereby the 3 scaling laws and access to compute are generating better intelligence and in turn, increasing adoption and profits. OpenAI recently shared that their weekly user base has grown to 800 million. Enterprise customers has increased to 1 million and that their gross margins were healthy.</td><td>ë˜ ë‹¤ë¥¸ ì„±ì¥ ë™ë ¥ì€ Anthropic, Mistral, OpenAI, Reflection, Safe Superintelligence, Thinking Machines Lab, xAI ë“± íŒŒìš´ë°ì´ì…˜ ëª¨ë¸ êµ¬ì¶•ì—…ì²´ë“¤ì´ ì¸í…”ë¦¬ì „ìŠ¤ í™•ì¥ì„ ìœ„í•´ ì»´í“¨íŒ…ì— ê³µê²©ì ìœ¼ë¡œ íˆ¬ìí•˜ë©´ì„œ ì»´í“¨íŒ… ì§€ì¶œì´ ì§€ì†ì ìœ¼ë¡œ ì¦ê°€í•˜ê³  ìˆë‹¤ëŠ” ì ì…ë‹ˆë‹¤. ì‚¬ì „í•™ìŠµ(pretraining), ì‚¬í›„í•™ìŠµ(post training), ì¶”ë¡ (inference)ì´ë¼ëŠ” 3ê°€ì§€ ìŠ¤ì¼€ì¼ë§ ë²•ì¹™ì€ ì—¬ì „íˆ ìœ íš¨í•˜ë©°, ì‹¤ì œë¡œ ì´ 3ê°€ì§€ ìŠ¤ì¼€ì¼ë§ ë²•ì¹™ê³¼ ì»´í“¨íŒ… ì ‘ê·¼ì„±ì´ ë” ë‚˜ì€ ì¸í…”ë¦¬ì „ìŠ¤ë¥¼ ìƒì„±í•˜ê³ , ì´ê²ƒì´ ë‹¤ì‹œ ì±„íƒë¥ ê³¼ ìˆ˜ìµì„± ì¦ê°€ë¡œ ì´ì–´ì§€ëŠ” ê¸ì •ì ì¸ ì„ ìˆœí™˜ êµ¬ì¡°ê°€ ë‚˜íƒ€ë‚˜ê³  ìˆìŠµë‹ˆë‹¤. OpenAIëŠ” ìµœê·¼ ì£¼ê°„ ì‚¬ìš©ì ê¸°ë°˜ì´ 8ì–µ ëª…ìœ¼ë¡œ ì„±ì¥í–ˆê³ , ê¸°ì—… ê³ ê°ì´ 100ë§Œ ê°œë¡œ ì¦ê°€í–ˆìœ¼ë©°, ë§¤ì¶œì´ì´ìµë¥ ì´ ì–‘í˜¸í•œ ìˆ˜ì¤€ì´ë¼ê³  ë°í˜”ìŠµë‹ˆë‹¤.</td></tr>
<tr><td>Well, Anthropic recently reported that its annualized run rate revenue has reached $7 billion as of last month, up from $1 billion at the start of the year. We are also witnessing a proliferation of agentic AI across various industries and tasks, companies such as Cursor, Anthropic, OpenEvidence, Epic and Abridge are experiencing a surge in user growth as they supercharge the existing workforce, delivering unquestionable ROI for coders and health care professionals. The world's most important enterprise software platforms like ServiceNow, CrowdStrike, and SAP are integrating NVIDIA's accelerated computing and AI stack.</td><td>ìµœê·¼ Anthropicì€ ì§€ë‚œë‹¬ ê¸°ì¤€ ì—°ê°„ í™˜ì‚° ë§¤ì¶œì´ 70ì–µ ë‹¬ëŸ¬ì— ë„ë‹¬í–ˆë‹¤ê³  ë°œí‘œí–ˆìŠµë‹ˆë‹¤. ì´ëŠ” ì—°ì´ˆ 10ì–µ ë‹¬ëŸ¬ì—ì„œ ì¦ê°€í•œ ìˆ˜ì¹˜ì…ë‹ˆë‹¤. ë˜í•œ ìš°ë¦¬ëŠ” ë‹¤ì–‘í•œ ì‚°ì—…ê³¼ ì—…ë¬´ ì˜ì—­ì—ì„œ ì—ì´ì „í‹± AIì˜ í™•ì‚°ì„ ëª©ê²©í•˜ê³  ìˆìŠµë‹ˆë‹¤. Cursor, Anthropic, OpenEvidence, Epic, Abridgeì™€ ê°™ì€ ê¸°ì—…ë“¤ì€ ê¸°ì¡´ ì¸ë ¥ì˜ ìƒì‚°ì„±ì„ ê·¹ëŒ€í™”í•˜ë©´ì„œ ì‚¬ìš©ì ì¦ê°€ì„¸ë¥¼ ê²½í—˜í•˜ê³  ìˆìœ¼ë©°, ê°œë°œìì™€ ì˜ë£Œ ì „ë¬¸ê°€ë“¤ì—ê²Œ ëª…ë°±í•œ íˆ¬ììˆ˜ìµë¥ (ROI)ì„ ì œê³µí•˜ê³  ìˆìŠµë‹ˆë‹¤. ServiceNow, CrowdStrike, SAPì™€ ê°™ì€ ì„¸ê³„ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ì—”í„°í”„ë¼ì´ì¦ˆ ì†Œí”„íŠ¸ì›¨ì–´ í”Œë«í¼ë“¤ì´ NVIDIAì˜ ê°€ì† ì»´í“¨íŒ…ê³¼ AI ìŠ¤íƒì„ í†µí•©í•˜ê³  ìˆìŠµë‹ˆë‹¤.</td></tr>
<tr><td>Our new partner, Palantir, is supercharging the incredibly popular oncology platform with NVIDIA CUDA-X libraries and AI models for the first time. Previously, like most enterprise software platforms, Anthology runs only on CPUs. Lowe's is leveraging the platform to build supply chain agility, reducing costs and improving customer satisfaction. Enterprises broadly are leveraging AI to boost productivity, increase efficiency and reduce cost. RBC is leveraging agent AI to drive significant analyst productivity slashing, report generation, time from hours to minutes. AI and digital twins are helping Unilever accelerate content creation by 2x and cut costs by 50%.</td><td>ìš°ë¦¬ì˜ ìƒˆë¡œìš´ íŒŒíŠ¸ë„ˆì¸ PalantirëŠ” NVIDIA CUDA-X ë¼ì´ë¸ŒëŸ¬ë¦¬ì™€ AI ëª¨ë¸ì„ ì²˜ìŒìœ¼ë¡œ ì ìš©í•˜ì—¬ ë§¤ìš° ì¸ê¸° ìˆëŠ” ì¢…ì–‘í•™ í”Œë«í¼ì„ ëŒ€í­ ê°•í™”í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ì „ì—ëŠ” ëŒ€ë¶€ë¶„ì˜ ì—”í„°í”„ë¼ì´ì¦ˆ ì†Œí”„íŠ¸ì›¨ì–´ í”Œë«í¼ê³¼ ë§ˆì°¬ê°€ì§€ë¡œ Anthologyê°€ CPUì—ì„œë§Œ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤. Lowe'sëŠ” ì´ í”Œë«í¼ì„ í™œìš©í•˜ì—¬ ê³µê¸‰ë§ ë¯¼ì²©ì„±ì„ êµ¬ì¶•í•˜ê³  ë¹„ìš©ì„ ì ˆê°í•˜ë©° ê³ ê° ë§Œì¡±ë„ë¥¼ ê°œì„ í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì „ë°˜ì ìœ¼ë¡œ ê¸°ì—…ë“¤ì€ ìƒì‚°ì„±ì„ ë†’ì´ê³  íš¨ìœ¨ì„±ì„ ì¦ëŒ€í•˜ë©° ë¹„ìš©ì„ ì ˆê°í•˜ê¸° ìœ„í•´ AIë¥¼ í™œìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤. RBCëŠ” ì—ì´ì „íŠ¸ AIë¥¼ í™œìš©í•˜ì—¬ ì• ë„ë¦¬ìŠ¤íŠ¸ ìƒì‚°ì„±ì„ í¬ê²Œ í–¥ìƒì‹œí‚¤ê³  ìˆìœ¼ë©°, ë³´ê³ ì„œ ìƒì„± ì‹œê°„ì„ ìˆ˜ ì‹œê°„ì—ì„œ ìˆ˜ ë¶„ìœ¼ë¡œ ëŒ€í­ ë‹¨ì¶•í•˜ê³  ìˆìŠµë‹ˆë‹¤. AIì™€ ë””ì§€í„¸ íŠ¸ìœˆì€ Unileverê°€ ì½˜í…ì¸  ì œì‘ì„ 2ë°° ê°€ì†í™”í•˜ê³  ë¹„ìš©ì„ 50% ì ˆê°í•˜ëŠ” ë° ë„ì›€ì„ ì£¼ê³  ìˆìŠµë‹ˆë‹¤.</td></tr>
<tr><td>Salesforce's engineering team has seen at least 30% productivity increase in new co-development after adopting Cursor. This past quarter, we announced AI factory and infrastructure projects amounting to an aggregate of 5 million GPUs. This demand spans every market, CSPs, sovereigns, modern builders, enterprises and supercomputing centers and includes multiple landmark build-outs. xAI's Colossus 2, the world's first gigawatt scale data center, Lilly's AI Factory for drug discovery, the pharmaceutical industry's most powerful data center.</td><td>ì„¸ì¼ì¦ˆí¬ìŠ¤ì˜ ì—”ì§€ë‹ˆì–´ë§ íŒ€ì€ Cursorë¥¼ ë„ì…í•œ í›„ ì‹ ê·œ ê³µë™ ê°œë°œì—ì„œ ìµœì†Œ 30%ì˜ ìƒì‚°ì„± ì¦ê°€ë¥¼ ê²½í—˜í–ˆìŠµë‹ˆë‹¤. ì§€ë‚œ ë¶„ê¸°ì— ìš°ë¦¬ëŠ” ì´ 500ë§Œ ê°œì˜ GPU ê·œëª¨ì— ë‹¬í•˜ëŠ” AI íŒ©í† ë¦¬ ë° ì¸í”„ë¼ í”„ë¡œì íŠ¸ë¥¼ ë°œí‘œí–ˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ìˆ˜ìš”ëŠ” CSP(í´ë¼ìš°ë“œ ì„œë¹„ìŠ¤ ì œê³µì—…ì²´), êµ­ê°€ ì£¼ê¶Œ ê¸°ê´€, í˜„ëŒ€ì  ë¹Œë”, ê¸°ì—… ë° ìŠˆí¼ì»´í“¨íŒ… ì„¼í„° ë“± ëª¨ë“  ì‹œì¥ì— ê±¸ì³ ìˆìœ¼ë©°, ì—¬ëŸ¬ íšê¸°ì ì¸ êµ¬ì¶• í”„ë¡œì íŠ¸ë¥¼ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì„¸ê³„ ìµœì´ˆì˜ ê¸°ê°€ì™€íŠ¸ ê·œëª¨ ë°ì´í„°ì„¼í„°ì¸ xAIì˜ Colossus 2, ì œì•½ ì—…ê³„ì—ì„œ ê°€ì¥ ê°•ë ¥í•œ ë°ì´í„°ì„¼í„°ì¸ ë¦´ë¦¬ì˜ ì‹ ì•½ ë°œê²¬ì„ ìœ„í•œ AI íŒ©í† ë¦¬ê°€ ê·¸ ì˜ˆì…ë‹ˆë‹¤.</td></tr>
<tr><td>And just today, AWS and HUMAIN expanded their partnership, including the deployment of up to 150,000 AI accelerators, including our GB300, xAI and HUMAIN also announced a partnership in which the 2 will jointly develop a network of world-class GPU data centers anchored by the flagship 500-megawatt facility. Blackwell gained further momentum in Q3, as GB300 crossed over GB200 and contributed roughly 2/3 of the total Blackwell revenue. The transition to GB300 has been seamless, with production shipments to the majority -- to the major cloud service providers, hyperscalers and GP clouds and is already driving their growth.</td><td>ê·¸ë¦¬ê³  ì˜¤ëŠ˜ AWSì™€ íœ´ë©”ì¸(HUMAIN)ì´ íŒŒíŠ¸ë„ˆì‹­ì„ í™•ëŒ€í–ˆìœ¼ë©°, ì—¬ê¸°ì—ëŠ” GB300ì„ í¬í•¨í•œ ìµœëŒ€ 15ë§Œ ê°œì˜ AI ê°€ì†ê¸° ë°°ì¹˜ê°€ í¬í•¨ë©ë‹ˆë‹¤. xAIì™€ íœ´ë©”ì¸ë„ íŒŒíŠ¸ë„ˆì‹­ì„ ë°œí‘œí–ˆëŠ”ë°, ì–‘ì‚¬ëŠ” 500ë©”ê°€ì™€íŠ¸ ê·œëª¨ì˜ í”Œë˜ê·¸ì‹­ ì‹œì„¤ì„ ì¤‘ì‹¬ìœ¼ë¡œ ì„¸ê³„ ìµœê³  ìˆ˜ì¤€ì˜ GPU ë°ì´í„°ì„¼í„° ë„¤íŠ¸ì›Œí¬ë¥¼ ê³µë™ ê°œë°œí•  ì˜ˆì •ì…ë‹ˆë‹¤. ë¸”ë™ì›°ì€ 3ë¶„ê¸°ì— ë”ìš± íƒ„ë ¥ì„ ë°›ì•˜ìœ¼ë©°, GB300ì´ GB200ì„ ë„˜ì–´ì„œë©° ì „ì²´ ë¸”ë™ì›° ë§¤ì¶œì˜ ì•½ 2/3ë¥¼ ê¸°ì—¬í–ˆìŠµë‹ˆë‹¤. GB300ìœ¼ë¡œì˜ ì „í™˜ì€ ì›í™œí•˜ê²Œ ì§„í–‰ë˜ì—ˆìœ¼ë©°, ì£¼ìš” í´ë¼ìš°ë“œ ì„œë¹„ìŠ¤ ì œê³µì—…ì²´, í•˜ì´í¼ìŠ¤ì¼€ì¼ëŸ¬, GP í´ë¼ìš°ë“œì— ëŒ€í•œ ì–‘ì‚° ì¶œí•˜ê°€ ì´ë£¨ì–´ì§€ê³  ìˆê³ , ì´ë¯¸ ì´ë“¤ì˜ ì„±ì¥ì„ ê²¬ì¸í•˜ê³  ìˆìŠµë‹ˆë‹¤.</td></tr>
<tr><td>The Hopper platform in its 13th quarter since inception, recorded approximately $2 billion in revenue in Q3. H20 sales were approximately $50 million, sizable purchase orders never materialized in the quarter due to geopolitical issues and the increasingly competitive market in China. While we were disappointed in the current state that prevents us from shipping more competitive data center compute products to China, we are committed to continued engagement with the U.S. and China governments and will continue to advocate for America's ability to compete around the world.</td><td>Hopper í”Œë«í¼ì€ ì¶œì‹œ ì´í›„ 13ë¶„ê¸° ë™ì•ˆ 3ë¶„ê¸°ì— ì•½ 20ì–µ ë‹¬ëŸ¬ì˜ ë§¤ì¶œì„ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤. H20 ë§¤ì¶œì€ ì•½ 5ì²œë§Œ ë‹¬ëŸ¬ì˜€ìœ¼ë©°, ì§€ì •í•™ì  ì´ìŠˆì™€ ì¤‘êµ­ ì‹œì¥ì˜ ê²½ìŸ ì‹¬í™”ë¡œ ì¸í•´ ëŒ€ê·œëª¨ êµ¬ë§¤ ì£¼ë¬¸ì´ ë¶„ê¸° ì¤‘ ì‹¤í˜„ë˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë³´ë‹¤ ê²½ìŸë ¥ ìˆëŠ” ë°ì´í„°ì„¼í„° ì»´í“¨íŒ… ì œí’ˆì„ ì¤‘êµ­ì— ì¶œí•˜í•˜ì§€ ëª»í•˜ê²Œ í•˜ëŠ” í˜„ì¬ ìƒí™©ì— ì‹¤ë§ìŠ¤ëŸ½ì§€ë§Œ, ìš°ë¦¬ëŠ” ë¯¸êµ­ê³¼ ì¤‘êµ­ ì •ë¶€ì™€ì˜ ì§€ì†ì ì¸ í˜‘ë ¥ì— ì „ë…í•˜ê³  ìˆìœ¼ë©°, ì „ ì„¸ê³„ì—ì„œ ë¯¸êµ­ì´ ê²½ìŸí•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì„ ê³„ì†í•´ì„œ ì˜¹í˜¸í•  ê²ƒì…ë‹ˆë‹¤.</td></tr>
<tr><td>To establish a sustainable leadership position in AI computing, America must win the support of every developer and be the platform of choice for every commercial business, including those in China. The Rubin platform is on track to ramp in the second half of 2026. Powered by 7 chips, the Vera Rubin platform will once again deliver an x-factor improvement in performance relative to Blackwell. We have received silicon back from our supply chain partners and are happy to report that NVIDIA teams across the world are executing to bring up beautifully. Rubin is our third-generation rack-scale system substantially redefined the manufacturability while remaining compatible with Grace Blackwell.</td><td>AI ì»´í“¨íŒ…ì—ì„œ ì§€ì† ê°€ëŠ¥í•œ ë¦¬ë”ì‹­ ì§€ìœ„ë¥¼ í™•ë¦½í•˜ê¸° ìœ„í•´, ë¯¸êµ­ì€ ëª¨ë“  ê°œë°œìì˜ ì§€ì§€ë¥¼ ì–»ê³  ì¤‘êµ­ ê¸°ì—…ì„ í¬í•¨í•œ ëª¨ë“  ìƒì—… ê¸°ì—…ì˜ ì„ íƒ í”Œë«í¼ì´ ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. Rubin í”Œë«í¼ì€ 2026ë…„ í•˜ë°˜ê¸° ì–‘ì‚°ì„ ëª©í‘œë¡œ ìˆœì¡°ë¡­ê²Œ ì§„í–‰ë˜ê³  ìˆìŠµë‹ˆë‹¤. 7ê°œì˜ ì¹©ìœ¼ë¡œ êµ¬ë™ë˜ëŠ” Vera Rubin í”Œë«í¼ì€ Blackwell ëŒ€ë¹„ ë‹¤ì‹œ í•œë²ˆ xë°°ì˜ ì„±ëŠ¥ í–¥ìƒì„ ì œê³µí•  ê²ƒì…ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ê³µê¸‰ë§ íŒŒíŠ¸ë„ˆë“¤ë¡œë¶€í„° ì‹¤ë¦¬ì½˜ì„ ë°›ì•˜ìœ¼ë©°, ì „ ì„¸ê³„ NVIDIA íŒ€ë“¤ì´ í›Œë¥­í•˜ê²Œ êµ¬ë™ ì‘ì—…ì„ ìˆ˜í–‰í•˜ê³  ìˆë‹¤ëŠ” ì ì„ ê¸°ì˜ê²Œ ë³´ê³ ë“œë¦½ë‹ˆë‹¤. Rubinì€ ìš°ë¦¬ì˜ 3ì„¸ëŒ€ ë™ ìŠ¤ì¼€ì¼ ì‹œìŠ¤í…œìœ¼ë¡œ, Grace Blackwellê³¼ì˜ í˜¸í™˜ì„±ì„ ìœ ì§€í•˜ë©´ì„œ ì œì¡° ê°€ëŠ¥ì„±ì„ ëŒ€í­ ì¬ì •ì˜í–ˆìŠµë‹ˆë‹¤.</td></tr>
<tr><td>Our supply chain data center ecosystem and cloud partners have now mastered the build to installation process of NVIDIA's rack architecture. Our ecosystem will be ready for a fast Rubin ramp. Our annual X factor performance leap increases performance per dollar while driving down computing costs for our customers. The long useful life of NVIDIA's CUDA GPUs is a significant TCO advantage over accelerators. CUDA's compatibility in our massive installed base, extend the life NVIDIA Systems well beyond their original estimated useful life.</td><td>ìš°ë¦¬ì˜ ê³µê¸‰ë§, ë°ì´í„°ì„¼í„° ìƒíƒœê³„ ë° í´ë¼ìš°ë“œ íŒŒíŠ¸ë„ˆë“¤ì€ ì´ì œ NVIDIA ë™ ì•„í‚¤í…ì²˜ì˜ ì œì¡°ë¶€í„° ì„¤ì¹˜ê¹Œì§€ì˜ í”„ë¡œì„¸ìŠ¤ë¥¼ ì™„ë²½í•˜ê²Œ ìŠµë“í–ˆìŠµë‹ˆë‹¤. ìš°ë¦¬ ìƒíƒœê³„ëŠ” Rubinì˜ ë¹ ë¥¸ ë¨í”„ì—…(ramp-up)ì— ëŒ€ë¹„ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ë§¤ë…„ Xë°°ì˜ ì„±ëŠ¥ í–¥ìƒì€ ë‹¬ëŸ¬ë‹¹ ì„±ëŠ¥ì„ ì¦ê°€ì‹œí‚¤ëŠ” ë™ì‹œì— ê³ ê°ë“¤ì˜ ì»´í“¨íŒ… ë¹„ìš©ì„ ì ˆê°ì‹œí‚µë‹ˆë‹¤. NVIDIA CUDA GPUì˜ ê¸´ ë‚´ìš©ì—°ìˆ˜(useful life)ëŠ” ë‹¤ë¥¸ ê°€ì†ê¸° ëŒ€ë¹„ ìƒë‹¹í•œ TCO(ì´ì†Œìœ ë¹„ìš©) ìš°ìœ„ë¥¼ ì œê³µí•©ë‹ˆë‹¤. CUDAì˜ í˜¸í™˜ì„±ê³¼ ìš°ë¦¬ì˜ ë°©ëŒ€í•œ ì„¤ì¹˜ ê¸°ë°˜(installed base)ì€ NVIDIA ì‹œìŠ¤í…œì˜ ìˆ˜ëª…ì„ ë‹¹ì´ˆ ì˜ˆìƒ ë‚´ìš©ì—°ìˆ˜ë¥¼ í›¨ì”¬ ë„˜ì–´ì„œê¹Œì§€ ì—°ì¥ì‹œí‚µë‹ˆë‹¤.</td></tr>
<tr><td>For more than 2 decades, we have optimized the CUDA ecosystem, improving existing workloads, accelerating new ones and increasing throughput with every software release. Most accelerators without CUDA and NVIDIA's time-tested and versatile architecture became obsolete within a few years as model technologies evolve. Thanks to CUDA, the A100 GPUs we shipped 6 years ago are still running at full utilization today, powered by vastly improved software stack. We have evolved over the past 25 years from a gaming GPU company to now an AI data center infrastructure company.</td><td>20ë…„ ì´ìƒ ìš°ë¦¬ëŠ” CUDA ìƒíƒœê³„ë¥¼ ìµœì í™”í•˜ë©° ê¸°ì¡´ ì›Œí¬ë¡œë“œë¥¼ ê°œì„ í•˜ê³ , ìƒˆë¡œìš´ ì›Œí¬ë¡œë“œë¥¼ ê°€ì†í™”í•˜ë©°, ì†Œí”„íŠ¸ì›¨ì–´ ë¦´ë¦¬ìŠ¤ë§ˆë‹¤ ì²˜ë¦¬ëŸ‰ì„ ì¦ê°€ì‹œì¼œ ì™”ìŠµë‹ˆë‹¤. CUDAì™€ NVIDIAì˜ ê²€ì¦ëœ ë‹¤ëª©ì  ì•„í‚¤í…ì²˜ê°€ ì—†ëŠ” ëŒ€ë¶€ë¶„ì˜ ê°€ì†ê¸°ë“¤ì€ ëª¨ë¸ ê¸°ìˆ ì´ ì§„í™”í•¨ì— ë”°ë¼ ëª‡ ë…„ ë‚´ì— êµ¬ì‹ì´ ë˜ì—ˆìŠµë‹ˆë‹¤. CUDA ë•ë¶„ì— 6ë…„ ì „ ì¶œì‹œí•œ A100 GPUëŠ” ëŒ€í­ ê°œì„ ëœ ì†Œí”„íŠ¸ì›¨ì–´ ìŠ¤íƒìœ¼ë¡œ êµ¬ë™ë˜ì–´ ì˜¤ëŠ˜ë‚ ì—ë„ ì—¬ì „íˆ ì™„ì „ ê°€ë™ ìƒíƒœë¡œ ìš´ì˜ë˜ê³  ìˆìŠµë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì§€ë‚œ 25ë…„ê°„ ê²Œì´ë° GPU íšŒì‚¬ì—ì„œ í˜„ì¬ AI ë°ì´í„°ì„¼í„° ì¸í”„ë¼ íšŒì‚¬ë¡œ ì§„í™”í•´ ì™”ìŠµë‹ˆë‹¤.</td></tr>
<tr><td>Our ability to innovate across the CPU, the GPU, networking and software and ultimately drive down cost per token is unmatched across the industry. Our networking business purpose built for AI and now the largest in the world, generated revenue of $8.2 billion, up 162% year-over-year with NVLink, InfiniBand and Spectrum-X Ethernet, all contributing to growth. We are winning in data center networking, as the majority of AI deployments now include our switches with Ethernet GPU attach rates roughly on par with InfiniBand.</td><td>ìš°ë¦¬ì˜ CPU, GPU, ë„¤íŠ¸ì›Œí‚¹ ë° ì†Œí”„íŠ¸ì›¨ì–´ ì „ë°˜ì— ê±¸ì¹œ í˜ì‹  ëŠ¥ë ¥ê³¼ ê¶ê·¹ì ìœ¼ë¡œ í† í°ë‹¹ ë¹„ìš©ì„ ì ˆê°í•˜ëŠ” ëŠ¥ë ¥ì€ ì—…ê³„ ì „ë°˜ì—ì„œ íƒ€ì˜ ì¶”ì¢…ì„ ë¶ˆí—ˆí•©ë‹ˆë‹¤. AIë¥¼ ìœ„í•´ íŠ¹ë³„íˆ êµ¬ì¶•ëœ ìš°ë¦¬ì˜ ë„¤íŠ¸ì›Œí‚¹ ì‚¬ì—…ì€ í˜„ì¬ ì„¸ê³„ ìµœëŒ€ ê·œëª¨ë¡œ, 82ì–µ ë‹¬ëŸ¬ì˜ ë§¤ì¶œì„ ê¸°ë¡í–ˆìœ¼ë©°, ì´ëŠ” ì „ë…„ ëŒ€ë¹„ 162% ì¦ê°€í•œ ìˆ˜ì¹˜ì…ë‹ˆë‹¤. NVLink, InfiniBand ë° Spectrum-X Ethernetì´ ëª¨ë‘ ì„±ì¥ì— ê¸°ì—¬í–ˆìŠµë‹ˆë‹¤. ìš°ë¦¬ëŠ” ë°ì´í„°ì„¼í„° ë„¤íŠ¸ì›Œí‚¹ì—ì„œ ìŠ¹ë¦¬í•˜ê³  ìˆìœ¼ë©°, í˜„ì¬ ëŒ€ë¶€ë¶„ì˜ AI ë°°í¬ì— ìš°ë¦¬ì˜ ìŠ¤ìœ„ì¹˜ê°€ í¬í•¨ë˜ì–´ ìˆê³ , Ethernet GPU ì—°ê²° ë¹„ìœ¨ì´ InfiniBandì™€ ê±°ì˜ ë™ë“±í•œ ìˆ˜ì¤€ì…ë‹ˆë‹¤.</td></tr>
<tr><td>Meta, Microsoft, Oracle and xAI are building gigawatt AI factories with Spectrum-X Ethernet switches and each will run its operating system of choice, highlighting the flexibility and openness of our platform. We recently introduced Spectrum-XGS, a scale across technology that enables gigascale AI factories And NVIDIA is the only company with AI scale up, scale out and scale across platforms, reinforcing our unique position in the market as the AI infrastructure provider. Customer interest in NVLink Fusion continues to grow.</td><td>ë©”íƒ€, ë§ˆì´í¬ë¡œì†Œí”„íŠ¸, ì˜¤ë¼í´, ê·¸ë¦¬ê³  xAIëŠ” Spectrum-X ì´ë”ë„· ìŠ¤ìœ„ì¹˜ë¥¼ í™œìš©í•˜ì—¬ ê¸°ê°€ì™€íŠ¸ê¸‰ AI íŒ©í† ë¦¬ë¥¼ êµ¬ì¶•í•˜ê³  ìˆìœ¼ë©°, ê°ì‚¬ëŠ” ìì²´ ì„ íƒí•œ ìš´ì˜ì²´ì œë¥¼ ì‹¤í–‰í•  ì˜ˆì •ì…ë‹ˆë‹¤. ì´ëŠ” ìš°ë¦¬ í”Œë«í¼ì˜ ìœ ì—°ì„±ê³¼ ê°œë°©ì„±ì„ ì˜ ë³´ì—¬ì¤ë‹ˆë‹¤. ìµœê·¼ ìš°ë¦¬ëŠ” ê¸°ê°€ìŠ¤ì¼€ì¼ AI íŒ©í† ë¦¬ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” ìŠ¤ì¼€ì¼ ì–´í¬ë¡œìŠ¤(scale across) ê¸°ìˆ ì¸ Spectrum-XGSë¥¼ ì¶œì‹œí–ˆìŠµë‹ˆë‹¤. NVIDIAëŠ” AI ìŠ¤ì¼€ì¼ ì—…(scale up), ìŠ¤ì¼€ì¼ ì•„ì›ƒ(scale out), ê·¸ë¦¬ê³  ìŠ¤ì¼€ì¼ ì–´í¬ë¡œìŠ¤(scale across) í”Œë«í¼ì„ ëª¨ë‘ ë³´ìœ í•œ ìœ ì¼í•œ ê¸°ì—…ìœ¼ë¡œì„œ, AI ì¸í”„ë¼ ì œê³µì—…ì²´ë¡œì„œì˜ ë…ë³´ì ì¸ ì‹œì¥ ì§€ìœ„ë¥¼ ë”ìš± ê³µê³ íˆ í•˜ê³  ìˆìŠµë‹ˆë‹¤. NVLink Fusionì— ëŒ€í•œ ê³ ê°ë“¤ì˜ ê´€ì‹¬ë„ ì§€ì†ì ìœ¼ë¡œ ì¦ê°€í•˜ê³  ìˆìŠµë‹ˆë‹¤.</td></tr>
<tr><td>We announced a strategic collaboration with Fujitsu in October, where we will integrate Fujitsu's CPUs and NVIDIA GPUs, via and NVLink Fusion, connecting our large ecosystems. We also announced a collaboration with Intel to develop multiple generations of custom data center and PC products, connecting NVIDIA and Intel's ecosystems using NVLink. This week at Supercomputing '25, Arm announced that it will be integrating NVLink IP for customers to build CPU SoCs that connect with NVIDIA currently on its fifth generation. NVLink is the only proven scale up technology available on the market today.</td><td>ìš°ë¦¬ëŠ” 10ì›”ì— í›„ì§€ì¯”ì™€ ì „ëµì  í˜‘ë ¥ì„ ë°œí‘œí–ˆìœ¼ë©°, ì´ë¥¼ í†µí•´ í›„ì§€ì¯”ì˜ CPUì™€ NVIDIA GPUë¥¼ NVLink Fusionì„ í†µí•´ í†µí•©í•˜ì—¬ ì–‘ì‚¬ì˜ ëŒ€ê·œëª¨ ìƒíƒœê³„ë¥¼ ì—°ê²°í•  ê²ƒì…ë‹ˆë‹¤. ë˜í•œ ì¸í…”ê³¼ì˜ í˜‘ë ¥ë„ ë°œí‘œí–ˆëŠ”ë°, ì—¬ëŸ¬ ì„¸ëŒ€ì— ê±¸ì¹œ ë§ì¶¤í˜• ë°ì´í„°ì„¼í„° ë° PC ì œí’ˆì„ ê°œë°œí•˜ì—¬ NVLinkë¥¼ ì‚¬ìš©í•´ NVIDIAì™€ ì¸í…”ì˜ ìƒíƒœê³„ë¥¼ ì—°ê²°í•  ì˜ˆì •ì…ë‹ˆë‹¤. ì´ë²ˆ ì£¼ ìŠˆí¼ì»´í“¨íŒ… '25ì—ì„œ Armì€ ê³ ê°ë“¤ì´ í˜„ì¬ 5ì„¸ëŒ€ì¸ NVIDIAì™€ ì—°ê²°ë˜ëŠ” CPU SoCë¥¼ êµ¬ì¶•í•  ìˆ˜ ìˆë„ë¡ NVLink IPë¥¼ í†µí•©í•  ê²ƒì´ë¼ê³  ë°œí‘œí–ˆìŠµë‹ˆë‹¤. NVLinkëŠ” í˜„ì¬ ì‹œì¥ì—ì„œ ìœ ì¼í•˜ê²Œ ê²€ì¦ëœ ìŠ¤ì¼€ì¼ ì—… ê¸°ìˆ ì…ë‹ˆë‹¤.</td></tr>
<tr><td>In the latest MLPerf training results, Blackwell Ultra delivered 5x faster time to train than Hopper, NVIDIA swept every benchmark. Notably, NVIDIA is the only training platform to leverage FP4 while meeting the MLPerf's strict accuracy standards. In semi-analysis, InferenceMAX benchmark, Blackwell achieved the highest performance and lowest total cost of ownership across every model and use case. Particularly important is Blackwell's NVLinks performance on a mixture of experts. The architecture for the world's most popular reasoning models.</td><td>ìµœì‹  MLPerf íŠ¸ë ˆì´ë‹ ê²°ê³¼ì—ì„œ Blackwell UltraëŠ” Hopper ëŒ€ë¹„ 5ë°° ë¹ ë¥¸ í•™ìŠµ ì‹œê°„ì„ ê¸°ë¡í–ˆìœ¼ë©°, NVIDIAëŠ” ëª¨ë“  ë²¤ì¹˜ë§ˆí¬ë¥¼ ì„ê¶Œí–ˆìŠµë‹ˆë‹¤. íŠ¹íˆ ì£¼ëª©í•  ì ì€ NVIDIAê°€ MLPerfì˜ ì—„ê²©í•œ ì •í™•ë„ ê¸°ì¤€ì„ ì¶©ì¡±í•˜ë©´ì„œ FP4ë¥¼ í™œìš©í•˜ëŠ” ìœ ì¼í•œ íŠ¸ë ˆì´ë‹ í”Œë«í¼ì´ë¼ëŠ” ê²ƒì…ë‹ˆë‹¤. ë°˜ë„ì²´ ë¶„ì„ ê¸°ê´€ì¸ InferenceMAX ë²¤ì¹˜ë§ˆí¬ì—ì„œ Blackwellì€ ëª¨ë“  ëª¨ë¸ê³¼ ì‚¬ìš© ì‚¬ë¡€ì—ì„œ ìµœê³  ì„±ëŠ¥ê³¼ ìµœì € ì´ì†Œìœ ë¹„ìš©(TCO)ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤. íŠ¹íˆ ì¤‘ìš”í•œ ê²ƒì€ ì „ ì„¸ê³„ì—ì„œ ê°€ì¥ ì¸ê¸° ìˆëŠ” ì¶”ë¡  ëª¨ë¸ì˜ ì•„í‚¤í…ì²˜ì¸ Mixture of Expertsì—ì„œ Blackwellì˜ NVLink ì„±ëŠ¥ì…ë‹ˆë‹¤.</td></tr>
<tr><td>On DeepSeek-R1 Blackwell delivered 10x higher performance per watt and 10x lower cost per token versus H200, a huge generational leap fueled by our extreme co-design approach. NVIDIA Dynamo an open source, low latency modular inference framework has now been adopted by every major cloud service provider, leveraging Dynamo's enablement, and disaggregated inference, the resulting increase in performance of complex AI models, such as MoE models, AWS, Google Cloud, Microsoft Azure and OCI have boosted AI inference performance for enterprise cloud customers. We are working on a strategic partnership with OpenAI focused on helping them build and deploy at least 10 gigawatts of AI data centers.</td><td>DeepSeek-R1ì—ì„œ Blackwellì€ H200 ëŒ€ë¹„ ì™€íŠ¸ë‹¹ ì„±ëŠ¥ì€ 10ë°° í–¥ìƒë˜ê³  í† í°ë‹¹ ë¹„ìš©ì€ 10ë°° ì ˆê°ë˜ëŠ” ì„±ê³¼ë¥¼ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤. ì´ëŠ” ë‹¹ì‚¬ì˜ ê·¹í•œ ê³µë™ ì„¤ê³„(extreme co-design) ì ‘ê·¼ë°©ì‹ì´ ì´ëŒì–´ë‚¸ ì—„ì²­ë‚œ ì„¸ëŒ€ì  ë„ì•½ì…ë‹ˆë‹¤. ì˜¤í”ˆì†ŒìŠ¤ ì €ì§€ì—° ëª¨ë“ˆí˜• ì¶”ë¡  í”„ë ˆì„ì›Œí¬ì¸ NVIDIA DynamoëŠ” í˜„ì¬ ëª¨ë“  ì£¼ìš” í´ë¼ìš°ë“œ ì„œë¹„ìŠ¤ ì œê³µì—…ì²´ì— ì±„íƒë˜ì—ˆìœ¼ë©°, Dynamoì˜ ì§€ì›ê³¼ ë¶„ì‚° ì¶”ë¡ (disaggregated inference)ì„ í™œìš©í•˜ì—¬ MoE(Mixture of Experts) ëª¨ë¸ê³¼ ê°™ì€ ë³µì¡í•œ AI ëª¨ë¸ì˜ ì„±ëŠ¥ì´ í–¥ìƒë˜ë©´ì„œ, AWS, Google Cloud, Microsoft Azure, OCIê°€ ê¸°ì—… í´ë¼ìš°ë“œ ê³ ê°ì„ ìœ„í•œ AI ì¶”ë¡  ì„±ëŠ¥ì„ ëŒ€í­ ê°œì„ í–ˆìŠµë‹ˆë‹¤. ë‹¹ì‚¬ëŠ” OpenAIì™€ ì „ëµì  íŒŒíŠ¸ë„ˆì‹­ì„ ì¶”ì§„í•˜ê³  ìˆìœ¼ë©°, ì´ëŠ” ìµœì†Œ 10ê¸°ê°€ì™€íŠ¸ ê·œëª¨ì˜ AI ë°ì´í„°ì„¼í„° êµ¬ì¶• ë° ë°°í¬ë¥¼ ì§€ì›í•˜ëŠ” ë° ì¤‘ì ì„ ë‘ê³  ìˆìŠµë‹ˆë‹¤.</td></tr>
<tr><td>In addition, we have the opportunity to invest in the company. We serve OpenAI through their cloud partners, Microsoft Azure, OCI and CoreWeave. We will continue to do so for the foreseeable future. As they continue to scale, we are delighted to support the company to add self-build infrastructure and we are working towards a definitive agreement and are excited to support OpenAI's growth. Yesterday, we celebrated an announcement with Anthropic. For the first time, Anthropic is adopting NVIDIA and we are establishing a deep technology partnership to support Anthropic's fast growth.</td><td>ë˜í•œ, ìš°ë¦¬ëŠ” íšŒì‚¬ì— íˆ¬ìí•  ê¸°íšŒë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ìš°ë¦¬ëŠ” OpenAIì˜ í´ë¼ìš°ë“œ íŒŒíŠ¸ë„ˆì¸ Microsoft Azure, OCI, CoreWeaveë¥¼ í†µí•´ OpenAIë¥¼ ì§€ì›í•˜ê³  ìˆìŠµë‹ˆë‹¤. ê°€ê¹Œìš´ ë¯¸ë˜ì—ë„ ê³„ì† ê·¸ë ‡ê²Œ í•  ê²ƒì…ë‹ˆë‹¤. ê·¸ë“¤ì´ ê³„ì† í™•ì¥í•¨ì— ë”°ë¼, ìš°ë¦¬ëŠ” íšŒì‚¬ê°€ ìì²´ êµ¬ì¶• ì¸í”„ë¼ë¥¼ ì¶”ê°€í•˜ëŠ” ê²ƒì„ ì§€ì›í•˜ê²Œ ë˜ì–´ ê¸°ì˜ê²Œ ìƒê°í•˜ë©°, ìµœì¢… ê³„ì•½ì„ ìœ„í•´ ë…¸ë ¥í•˜ê³  ìˆê³  OpenAIì˜ ì„±ì¥ì„ ì§€ì›í•˜ê²Œ ë˜ì–´ ë§¤ìš° ê¸°ì©ë‹ˆë‹¤. ì–´ì œ, ìš°ë¦¬ëŠ” Anthropicê³¼ì˜ ë°œí‘œë¥¼ ì¶•í•˜í–ˆìŠµë‹ˆë‹¤. Anthropicì´ ì²˜ìŒìœ¼ë¡œ NVIDIAë¥¼ ì±„íƒí–ˆìœ¼ë©°, ìš°ë¦¬ëŠ” Anthropicì˜ ë¹ ë¥¸ ì„±ì¥ì„ ì§€ì›í•˜ê¸° ìœ„í•´ ê¸´ë°€í•œ ê¸°ìˆ  íŒŒíŠ¸ë„ˆì‹­ì„ êµ¬ì¶•í•˜ê³  ìˆìŠµë‹ˆë‹¤.</td></tr>
<tr><td>We will collaborate to optimize Anthropic models for CUDA and deliver the best possible performance, efficiency and TCO. We will also optimize future NVIDIA architectures for Anthropic workloads. Anthropic's compute commitment is initially including up to 1 gigawatt of compute capacity with Grace Blackwell and Vera Rubin Systems. Our strategic investments in Anthropic, Mistral, OpenAI, Reflection, Thinking Machines and other represent partnerships that grow the NVIDIA CUDA AI ecosystem and enable every model to run optimally on NVIDIAs everywhere. We will continue to invest strategically while preserving our disciplined approach to cash flow management.</td><td>ìš°ë¦¬ëŠ” Anthropic ëª¨ë¸ì„ CUDAì— ìµœì í™”í•˜ê³  ìµœìƒì˜ ì„±ëŠ¥, íš¨ìœ¨ì„± ë° TCOë¥¼ ì œê³µí•˜ê¸° ìœ„í•´ í˜‘ë ¥í•  ê²ƒì…ë‹ˆë‹¤. ë˜í•œ Anthropic ì›Œí¬ë¡œë“œì— ë§ì¶° ì°¨ì„¸ëŒ€ NVIDIA ì•„í‚¤í…ì²˜ë¥¼ ìµœì í™”í•  ê²ƒì…ë‹ˆë‹¤. Anthropicì˜ ì»´í“¨íŒ… ì•½ì •ì—ëŠ” ì´ˆê¸°ì— Grace Blackwell ë° Vera Rubin ì‹œìŠ¤í…œìœ¼ë¡œ ìµœëŒ€ 1ê¸°ê°€ì™€íŠ¸ì˜ ì»´í“¨íŒ… ìš©ëŸ‰ì´ í¬í•¨ë©ë‹ˆë‹¤. Anthropic, Mistral, OpenAI, Reflection, Thinking Machines ë“±ì— ëŒ€í•œ ìš°ë¦¬ì˜ ì „ëµì  íˆ¬ìëŠ” NVIDIA CUDA AI ìƒíƒœê³„ë¥¼ ì„±ì¥ì‹œí‚¤ê³  ëª¨ë“  ëª¨ë¸ì´ ì „ ì„¸ê³„ NVIDIA í”Œë«í¼ì—ì„œ ìµœì ìœ¼ë¡œ ì‹¤í–‰ë  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” íŒŒíŠ¸ë„ˆì‹­ì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” í˜„ê¸ˆíë¦„ ê´€ë¦¬ì— ëŒ€í•œ ê·œìœ¨ ìˆëŠ” ì ‘ê·¼ë°©ì‹ì„ ìœ ì§€í•˜ë©´ì„œ ì „ëµì  íˆ¬ìë¥¼ ì§€ì†í•  ê²ƒì…ë‹ˆë‹¤.</td></tr>
<tr><td>Physical AI is already a multibillion-dollar business addressing a multitrillion dollar opportunity on the next leg of growth for NVIDIA. Leading U.S. manufacturers and robotics innovators are leveraging NVIDIA's 3 computer architecture to train on NVIDIA, test on Omniverse's computer and deploy real-world AI and just in robotic computers. PTC and Siemens introduced new services that bring Omniverse powered digital twin workflows to their extensive installed base of customers. companies, including Belden, Caterpillar, Foxconn, Lucid Motors, Toyota, TSMC and Wistron, are building Omniverse digital twin factories to accelerate AI-driven manufacturing and automation.</td><td>í”¼ì§€ì»¬ AIëŠ” ì´ë¯¸ ìˆ˜ì‹­ì–µ ë‹¬ëŸ¬ ê·œëª¨ì˜ ì‚¬ì—…ì´ë©°, NVIDIAì˜ ì°¨ì„¸ëŒ€ ì„±ì¥ ë™ë ¥ìœ¼ë¡œì„œ ìˆ˜ì¡° ë‹¬ëŸ¬ ê·œëª¨ì˜ ê¸°íšŒë¥¼ ë‹¤ë£¨ê³  ìˆìŠµë‹ˆë‹¤. ë¯¸êµ­ì˜ ì£¼ìš” ì œì¡°ì—…ì²´ë“¤ê³¼ ë¡œë³´í‹±ìŠ¤ í˜ì‹  ê¸°ì—…ë“¤ì€ NVIDIAì˜ 3-ì»´í“¨í„° ì•„í‚¤í…ì²˜ë¥¼ í™œìš©í•˜ì—¬ NVIDIAì—ì„œ í•™ìŠµí•˜ê³ , Omniverse ì»´í“¨í„°ì—ì„œ í…ŒìŠ¤íŠ¸í•˜ë©°, ì‹¤ì œ í™˜ê²½ì—ì„œ AIì™€ ë¡œë³´í‹±ìŠ¤ ì»´í“¨í„°ë¥¼ ë°°í¬í•˜ê³  ìˆìŠµë‹ˆë‹¤. PTCì™€ SiemensëŠ” Omniverse ê¸°ë°˜ ë””ì§€í„¸ íŠ¸ìœˆ ì›Œí¬í”Œë¡œìš°ë¥¼ ê´‘ë²”ìœ„í•œ ê¸°ì¡´ ê³ ê° ê¸°ë°˜ì— ì œê³µí•˜ëŠ” ìƒˆë¡œìš´ ì„œë¹„ìŠ¤ë¥¼ ì¶œì‹œí–ˆìŠµë‹ˆë‹¤. Belden, Caterpillar, Foxconn, Lucid Motors, Toyota, TSMC, Wistronì„ í¬í•¨í•œ ê¸°ì—…ë“¤ì€ AI ê¸°ë°˜ ì œì¡° ë° ìë™í™”ë¥¼ ê°€ì†í™”í•˜ê¸° ìœ„í•´ Omniverse ë””ì§€í„¸ íŠ¸ìœˆ ê³µì¥ì„ êµ¬ì¶•í•˜ê³  ìˆìŠµë‹ˆë‹¤.</td></tr>
<tr><td>Agility Robotics, Amazon Robotics, Figure and Skild at AI are building our platform, tapping offerings such as NVIDIA, Cosmos, World Foundation Models for development, Omniverse for simulation and validation and Jetson to power next-generation intelligent robots. We remain focused on building resiliency and redundancy in our global supply chain. Last month, in partnership with TSMC, we celebrated the first Blackwell wafer produced on U.S. soil. We will continue to work with Foxconn, Wistron, Amkor, SPIL and others to grow our presence in the U.S. over the next 4 years. Gaming revenue was $4.3 billion, up 30% year-on-year, driven by strong demand as Blackwell momentum continued.</td><td>Agility Robotics, Amazon Robotics, Figure ë° Skild at AIëŠ” ê°œë°œì„ ìœ„í•œ NVIDIA Cosmos World Foundation Models, ì‹œë®¬ë ˆì´ì…˜ ë° ê²€ì¦ì„ ìœ„í•œ Omniverse, ê·¸ë¦¬ê³  ì°¨ì„¸ëŒ€ ì§€ëŠ¥í˜• ë¡œë´‡ì„ êµ¬ë™í•˜ëŠ” Jetsonê³¼ ê°™ì€ ì œí’ˆë“¤ì„ í™œìš©í•˜ì—¬ ìš°ë¦¬ì˜ í”Œë«í¼ì„ êµ¬ì¶•í•˜ê³  ìˆìŠµë‹ˆë‹¤. ìš°ë¦¬ëŠ” ê¸€ë¡œë²Œ ê³µê¸‰ë§ì˜ ë³µì›ë ¥ê³¼ ì´ì¤‘í™” êµ¬ì¶•ì— ê³„ì† ì§‘ì¤‘í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì§€ë‚œë‹¬, TSMCì™€ì˜ íŒŒíŠ¸ë„ˆì‹­ì„ í†µí•´ ë¯¸êµ­ ë³¸í† ì—ì„œ ìƒì‚°ëœ ì²« ë²ˆì§¸ Blackwell ì›¨ì´í¼ë¥¼ ê¸°ë…í–ˆìŠµë‹ˆë‹¤. í–¥í›„ 4ë…„ê°„ Foxconn, Wistron, Amkor, SPIL ë“±ê³¼ í˜‘ë ¥í•˜ì—¬ ë¯¸êµ­ ë‚´ ì…ì§€ë¥¼ í™•ëŒ€í•´ ë‚˜ê°ˆ ê²ƒì…ë‹ˆë‹¤. ê²Œì´ë° ë§¤ì¶œì€ 43ì–µ ë‹¬ëŸ¬ë¡œ ì „ë…„ ëŒ€ë¹„ 30% ì¦ê°€í–ˆìœ¼ë©°, ì´ëŠ” Blackwellì˜ ëª¨ë©˜í…€ì´ ì§€ì†ë˜ë©´ì„œ ê°•ë ¥í•œ ìˆ˜ìš”ì— í˜ì…ì€ ê²ƒì…ë‹ˆë‹¤.</td></tr>
<tr><td>End market sell-through remains robust and channel inventories are at normal levels heading into the holiday season. Steam recently broke its concurrent user record with 42 million gamers while thousands of fans pack the GeForce Gamer Festival in South Korea to celebrate 25 years of GeForce. NVIDIA pro visualization has evolved into computers for engineers and developers, whether for graphics or for AI. Professional Visualization revenue was $760 million, up 56% year-over-year, was another record. Growth was driven by DGX Spark, the world's smallest AI supercomputer built on a small configuration of Grace Blackwell.</td><td>ìµœì¢… ì‹œì¥ì˜ íŒë§¤ëŠ” ê²¬ì¡°í•œ íë¦„ì„ ìœ ì§€í•˜ê³  ìˆìœ¼ë©°, ì±„ë„ ì¬ê³ ëŠ” ì—°ë§ ì‹œì¦Œì„ ì•ë‘ê³  ì •ìƒ ìˆ˜ì¤€ì„ ìœ ì§€í•˜ê³  ìˆìŠµë‹ˆë‹¤. Steamì€ ìµœê·¼ 4,200ë§Œ ê²Œì´ë¨¸ë¼ëŠ” ë™ì‹œ ì ‘ì†ì ê¸°ë¡ì„ ê²½ì‹ í–ˆìœ¼ë©°, í•œêµ­ì—ì„œ ì—´ë¦° GeForce ê²Œì´ë¨¸ í˜ìŠ¤í‹°ë²Œì—ëŠ” GeForce 25ì£¼ë…„ì„ ì¶•í•˜í•˜ê¸° ìœ„í•´ ìˆ˜ì²œ ëª…ì˜ íŒ¬ë“¤ì´ ëª¨ì˜€ìŠµë‹ˆë‹¤. NVIDIA í”„ë¡œ ë¹„ì£¼ì–¼ë¼ì´ì œì´ì…˜ì€ ê·¸ë˜í”½ì´ë“  AIë“  ì—”ì§€ë‹ˆì–´ì™€ ê°œë°œìë¥¼ ìœ„í•œ ì»´í“¨í„°ë¡œ ì§„í™”í–ˆìŠµë‹ˆë‹¤. í”„ë¡œí˜ì…”ë„ ë¹„ì£¼ì–¼ë¼ì´ì œì´ì…˜ ë§¤ì¶œì€ 7ì–µ 6,000ë§Œ ë‹¬ëŸ¬ë¡œ ì „ë…„ ëŒ€ë¹„ 56% ì¦ê°€í•˜ì—¬ ë˜ ë‹¤ì‹œ ê¸°ë¡ì„ ê²½ì‹ í–ˆìŠµë‹ˆë‹¤. ì„±ì¥ì€ Grace Blackwellì˜ ì†Œí˜• êµ¬ì„±ì„ ê¸°ë°˜ìœ¼ë¡œ êµ¬ì¶•ëœ ì„¸ê³„ì—ì„œ ê°€ì¥ ì‘ì€ AI ìŠˆí¼ì»´í“¨í„°ì¸ DGX Sparkê°€ ì£¼ë„í–ˆìŠµë‹ˆë‹¤.</td></tr>
<tr><td>Automotive revenue was $592 million, up 32% year-over-year, primarily driven by self-driving solutions. We are partnering with Uber to scale the world's largest Level 4 ready autonomous fleet built on the new NVIDIA Hyperion L4 robotaxi reference architecture. Moving to the rest of the P&L. GAAP gross margins were 73.4% and non-GAAP gross margins was 73.6%, exceeding our outlook. Gross margins increased sequentially due to our data center mix, improved cycle time and cost structure. GAAP operating expenses were up 8% sequentially and up 11% on non-GAAP basis. The growth was driven by infrastructure compute as well as higher compensation and benefits and engineering development costs.</td><td>ìë™ì°¨ ë¶€ë¬¸ ë§¤ì¶œì€ 5ì–µ 9,200ë§Œ ë‹¬ëŸ¬ë¡œ ì „ë…„ ëŒ€ë¹„ 32% ì¦ê°€í–ˆìœ¼ë©°, ì´ëŠ” ì£¼ë¡œ ììœ¨ì£¼í–‰ ì†”ë£¨ì…˜ì— ì˜í•´ ê²¬ì¸ë˜ì—ˆìŠµë‹ˆë‹¤. ìš°ë¦¬ëŠ” Uberì™€ í˜‘ë ¥í•˜ì—¬ ìƒˆë¡œìš´ NVIDIA Hyperion L4 ë¡œë³´íƒì‹œ ë ˆí¼ëŸ°ìŠ¤ ì•„í‚¤í…ì²˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ êµ¬ì¶•ëœ ì„¸ê³„ ìµœëŒ€ ê·œëª¨ì˜ ë ˆë²¨ 4 ëŒ€ì‘ ììœ¨ì£¼í–‰ ì°¨ëŸ‰êµ°ì„ í™•ëŒ€í•˜ê³  ìˆìŠµë‹ˆë‹¤. <br><br>ì†ìµê³„ì‚°ì„œì˜ ë‚˜ë¨¸ì§€ í•­ëª©ìœ¼ë¡œ ë„˜ì–´ê°€ê² ìŠµë‹ˆë‹¤. GAAP ê¸°ì¤€ ë§¤ì¶œì´ì´ìµë¥ ì€ 73.4%ì˜€ê³ , non-GAAP ê¸°ì¤€ ë§¤ì¶œì´ì´ìµë¥ ì€ 73.6%ë¡œ ë‹¹ì‚¬ì˜ ì „ë§ì¹˜ë¥¼ ìƒíšŒí–ˆìŠµë‹ˆë‹¤. ë§¤ì¶œì´ì´ìµë¥ ì€ ë°ì´í„°ì„¼í„° ì œí’ˆ ë¯¹ìŠ¤, ê°œì„ ëœ ì‚¬ì´í´ íƒ€ì„ ë° ë¹„ìš© êµ¬ì¡°ë¡œ ì¸í•´ ì „ë¶„ê¸° ëŒ€ë¹„ ì¦ê°€í–ˆìŠµë‹ˆë‹¤. <br><br>GAAP ê¸°ì¤€ ì˜ì—…ë¹„ìš©ì€ ì „ë¶„ê¸° ëŒ€ë¹„ 8% ì¦ê°€í–ˆê³ , non-GAAP ê¸°ì¤€ìœ¼ë¡œëŠ” 11% ì¦ê°€í–ˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ì¦ê°€ëŠ” ì¸í”„ë¼ ì»´í“¨íŒ… íˆ¬ìì™€ ë”ë¶ˆì–´ ì¸ê±´ë¹„ ë° ë³µë¦¬í›„ìƒë¹„ ì¦ê°€, ê·¸ë¦¬ê³  ì—”ì§€ë‹ˆì–´ë§ ê°œë°œ ë¹„ìš© ì¦ê°€ì— ì˜í•´ ì£¼ë„ë˜ì—ˆìŠµë‹ˆë‹¤.</td></tr>
<tr><td>Non-GAAP effective tax rate for the third quarter was just over 17% higher than our guidance of 16.5% due to the strong U.S. revenue. On our balance sheet, inventory grew 32% quarter-over-quarter, while supply commitments increased 63% sequentially. The we are preparing for significant growth ahead and feel good about our ability to execute against our opportunity set. Okay. Let me turn to the outlook for the fourth quarter. Total revenue is expected to be $65 billion, plus or minus 2%. At the midpoint, our outlook implies 14% sequential growth driven by continued momentum in the Blackwell architecture.</td><td>3ë¶„ê¸° ë¹„-GAAP ì‹¤íš¨ì„¸ìœ¨ì€ 17%ë¥¼ ì•½ê°„ ìƒíšŒí–ˆìœ¼ë©°, ì´ëŠ” ë¯¸êµ­ ë§¤ì¶œ í˜¸ì¡°ë¡œ ì¸í•´ ê°€ì´ë˜ìŠ¤ì¸ 16.5%ë³´ë‹¤ ë†’ì€ ìˆ˜ì¹˜ì…ë‹ˆë‹¤. ëŒ€ì°¨ëŒ€ì¡°í‘œë¥¼ ë³´ë©´, ì¬ê³ ìì‚°ì€ ì „ë¶„ê¸° ëŒ€ë¹„ 32% ì¦ê°€í–ˆìœ¼ë©°, ê³µê¸‰ ì•½ì •ì€ ì „ë¶„ê¸° ëŒ€ë¹„ 63% ì¦ê°€í–ˆìŠµë‹ˆë‹¤. ìš°ë¦¬ëŠ” í–¥í›„ ìƒë‹¹í•œ ì„±ì¥ì— ëŒ€ë¹„í•˜ê³  ìˆìœ¼ë©°, ìš°ë¦¬ì˜ ê¸°íšŒë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì— ëŒ€í•´ ê¸ì •ì ìœ¼ë¡œ ìƒê°í•˜ê³  ìˆìŠµë‹ˆë‹¤. <br><br>ì´ì œ 4ë¶„ê¸° ì „ë§ìœ¼ë¡œ ë„˜ì–´ê°€ê² ìŠµë‹ˆë‹¤. ì´ ë§¤ì¶œì€ 650ì–µ ë‹¬ëŸ¬, í”ŒëŸ¬ìŠ¤ ë§ˆì´ë„ˆìŠ¤ 2%ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤. ì¤‘ê°„ê°’ ê¸°ì¤€ìœ¼ë¡œ, ìš°ë¦¬ì˜ ì „ë§ì€ Blackwell ì•„í‚¤í…ì²˜ì˜ ì§€ì†ì ì¸ ëª¨ë©˜í…€ì— í˜ì…ì–´ ì „ë¶„ê¸° ëŒ€ë¹„ 14% ì„±ì¥ì„ ì‹œì‚¬í•©ë‹ˆë‹¤.</td></tr>
<tr><td>Consistent with last quarter, we are not assuming any data center compute revenue from China. GAAP and non-GAAP gross margins are expected to be 74.8% and 75%, respectively, plus or minus 50 basis points. Looking ahead to fiscal year 2027, and input costs are on the rise, but we are working to hold gross margins in the mid-70s. GAAP and non-GAAP operating expenses are expected to be approximately $6.7 billion and $5 billion, respectively. GAAP and non-GAAP other income and expenses are expected to be an income of approximately $500 million, excluding gains and losses from nonmarketable and publicly held equity securities.</td><td>ì§€ë‚œ ë¶„ê¸°ì™€ ë§ˆì°¬ê°€ì§€ë¡œ, ì¤‘êµ­ìœ¼ë¡œë¶€í„°ì˜ ë°ì´í„°ì„¼í„° ì»´í“¨íŒ… ë§¤ì¶œì€ ê°€ì •í•˜ì§€ ì•Šê³  ìˆìŠµë‹ˆë‹¤. GAAP ë° non-GAAP ê¸°ì¤€ ë§¤ì¶œì´ì´ìµë¥ ì€ ê°ê° 74.8%ì™€ 75%ë¡œ ì˜ˆìƒë˜ë©°, ì˜¤ì°¨ë²”ìœ„ëŠ” í”ŒëŸ¬ìŠ¤ë§ˆì´ë„ˆìŠ¤ 50bpì…ë‹ˆë‹¤. 2027 íšŒê³„ì—°ë„ë¥¼ ì „ë§í•˜ë©´, íˆ¬ì… ë¹„ìš©ì´ ìƒìŠ¹í•˜ê³  ìˆì§€ë§Œ, ë§¤ì¶œì´ì´ìµë¥ ì„ 70% ì¤‘ë°˜ëŒ€ë¡œ ìœ ì§€í•˜ê¸° ìœ„í•´ ë…¸ë ¥í•˜ê³  ìˆìŠµë‹ˆë‹¤. GAAP ë° non-GAAP ê¸°ì¤€ ì˜ì—…ë¹„ìš©ì€ ê°ê° ì•½ 67ì–µ ë‹¬ëŸ¬ì™€ 50ì–µ ë‹¬ëŸ¬ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤. GAAP ë° non-GAAP ê¸°ì¤€ ê¸°íƒ€ì†ìµì€ ë¹„ìƒì¥ ë° ìƒì¥ ì§€ë¶„ì¦ê¶Œì˜ í‰ê°€ì†ìµì„ ì œì™¸í•˜ê³  ì•½ 5ì–µ ë‹¬ëŸ¬ì˜ ìˆ˜ìµìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤.</td></tr>
<tr><td>GAAP and non-GAAP tax rates are expected to be 17%, plus or minus 1%, excluding any discrete items. At this time, let me turn the call over to Jensen for him to say a few words. Jen-Hsun Huang<br>Co-Founder, CEO, President & Director<br><br>Thanks, Colette. There's been a lot of talk about an AI bubble. From our vantage point, we see something very different. As a reminder, NVIDIA is unlike any other accelerator. We excel at every phase of AI from pre-training and post training to inference. And with our 2-decade investment in CUDA-X acceleration libraries, we are also exceptional at science and engineering simulations, computer graphics, structured data processing to classical machine learning.</td><td>GAAP ë° non-GAAP ì„¸ìœ¨ì€ ê°œë³„ í•­ëª©ì„ ì œì™¸í•˜ê³  17% ì „í›„ 1% ë²”ìœ„ê°€ ë  ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤. ì´ì œ Jensenì—ê²Œ ë§ˆì´í¬ë¥¼ ë„˜ê²¨ ëª‡ ë§ì”€ ë“œë¦¬ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.<br><br>ì  ìŠ¨ í™©(Jen-Hsun Huang)<br>ê³µë™ ì°½ë¦½ì, CEO, ì‚¬ì¥ ê²¸ ì´ì‚¬<br><br>ê°ì‚¬í•©ë‹ˆë‹¤, Colette. ìµœê·¼ AI ë²„ë¸”ì— ëŒ€í•œ ë§ì€ ì´ì•¼ê¸°ê°€ ìˆì—ˆìŠµë‹ˆë‹¤. ìš°ë¦¬ì˜ ê´€ì ì—ì„œ ë³´ë©´, ìš°ë¦¬ëŠ” ë§¤ìš° ë‹¤ë¥¸ ê²ƒì„ ë³´ê³  ìˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ í•œë²ˆ ë§ì”€ë“œë¦¬ìë©´, NVIDIAëŠ” ë‹¤ë¥¸ ì–´ë–¤ ê°€ì†ê¸°ì™€ë„ ë‹¤ë¦…ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì‚¬ì „ í•™ìŠµ(pre-training)ê³¼ ì‚¬í›„ í•™ìŠµ(post training)ë¶€í„° ì¶”ë¡ (inference)ì— ì´ë¥´ê¸°ê¹Œì§€ AIì˜ ëª¨ë“  ë‹¨ê³„ì—ì„œ íƒì›”í•©ë‹ˆë‹¤. ê·¸ë¦¬ê³  CUDA-X ê°€ì† ë¼ì´ë¸ŒëŸ¬ë¦¬ì— ëŒ€í•œ 20ë…„ê°„ì˜ íˆ¬ìë¥¼ í†µí•´, ìš°ë¦¬ëŠ” ê³¼í•™ ë° ì—”ì§€ë‹ˆì–´ë§ ì‹œë®¬ë ˆì´ì…˜, ì»´í“¨í„° ê·¸ë˜í”½ìŠ¤, êµ¬ì¡°í™”ëœ ë°ì´í„° ì²˜ë¦¬ë¶€í„° ê³ ì „ì  ë¨¸ì‹ ëŸ¬ë‹ì— ì´ë¥´ê¸°ê¹Œì§€ ëª¨ë“  ë¶„ì•¼ì—ì„œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤.</td></tr>
<tr><td>The world is going -- is undergoing 3 massive platform shifts at once. The first time since the dawn of Moore's Law, NVIDIA is uniquely addressing each of the 3 transformations. The first transition is from CPU general purpose computing to GPU accelerated computing and Moore's Law slows. The world has a massive investment in non-AI software. From data processing to science and engineering simulations, representing hundreds of billions of dollars in compute -- cloud computing spend each year. Many of these applications which ran once exclusively on CPUs are now rapidly shifting to CUDA GPUs. Accelerated computing has reached a tipping point.</td><td>ì„¸ê³„ëŠ” í˜„ì¬ 3ê°€ì§€ ëŒ€ê·œëª¨ í”Œë«í¼ ì „í™˜ì„ ë™ì‹œì— ê²ªê³  ìˆìŠµë‹ˆë‹¤. ë¬´ì–´ì˜ ë²•ì¹™ì´ ì‹œì‘ëœ ì´ë˜ ì²˜ìŒìœ¼ë¡œ, NVIDIAëŠ” ì´ 3ê°€ì§€ ë³€í™” ê°ê°ì„ ë…ë³´ì ìœ¼ë¡œ ë‹¤ë£¨ê³  ìˆìŠµë‹ˆë‹¤. ì²« ë²ˆì§¸ ì „í™˜ì€ ë¬´ì–´ì˜ ë²•ì¹™ì´ ë‘”í™”ë˜ë©´ì„œ CPU ë²”ìš© ì»´í“¨íŒ…ì—ì„œ GPU ê°€ì† ì»´í“¨íŒ…ìœ¼ë¡œì˜ ì´ë™ì…ë‹ˆë‹¤. ì „ ì„¸ê³„ëŠ” ë¹„AI ì†Œí”„íŠ¸ì›¨ì–´ì— ë§‰ëŒ€í•œ íˆ¬ìë¥¼ í•˜ê³  ìˆìŠµë‹ˆë‹¤. ë°ì´í„° ì²˜ë¦¬ë¶€í„° ê³¼í•™ ë° ì—”ì§€ë‹ˆì–´ë§ ì‹œë®¬ë ˆì´ì…˜ì— ì´ë¥´ê¸°ê¹Œì§€, ë§¤ë…„ ìˆ˜ì²œì–µ ë‹¬ëŸ¬ ê·œëª¨ì˜ í´ë¼ìš°ë“œ ì»´í“¨íŒ… ì§€ì¶œì„ ë‚˜íƒ€ë‚´ê³  ìˆìŠµë‹ˆë‹¤. í•œë•Œ CPUì—ì„œë§Œ ë…ì ì ìœ¼ë¡œ ì‹¤í–‰ë˜ë˜ ì´ëŸ¬í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ë“¤ ì¤‘ ìƒë‹¹ìˆ˜ê°€ ì´ì œ CUDA GPUë¡œ ë¹ ë¥´ê²Œ ì „í™˜ë˜ê³  ìˆìŠµë‹ˆë‹¤. ê°€ì† ì»´í“¨íŒ…ì€ í‹°í•‘ í¬ì¸íŠ¸ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤.</td></tr>
<tr><td>Secondly, AI has also reached a tipping point and is transforming existing applications while enabling entirely new ones. For existing applications, generative AI is replacing classical machine learning in search ranking, recommender systems, ad targeting, click-through prediction to content moderation. The very foundations of hyperscale infrastructure. Meta's GEM, a foundation model for ad recommendations trained on large-scale GPU clusters exemplifies this shift. In Q2, Meta reported over a 5% increase in ad conversions on Instagram and 3% gain on Facebook feed driven by generative AI-based GEM. Transitioning to generative AI represents substantial revenue gains for hyperscalers.</td><td>ë‘˜ì§¸, AIë„ ì „í™˜ì ì— ë„ë‹¬í•˜ì—¬ ê¸°ì¡´ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ í˜ì‹ í•˜ëŠ” ë™ì‹œì— ì™„ì „íˆ ìƒˆë¡œìš´ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ê³  ìˆìŠµë‹ˆë‹¤. ê¸°ì¡´ ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ê²½ìš°, ìƒì„±í˜• AIê°€ ê²€ìƒ‰ ë­í‚¹, ì¶”ì²œ ì‹œìŠ¤í…œ, ê´‘ê³  íƒ€ê²ŸíŒ…, í´ë¦­ë¥  ì˜ˆì¸¡ì—ì„œ ì½˜í…ì¸  ì¡°ì •ì— ì´ë¥´ê¸°ê¹Œì§€ ê¸°ì¡´ì˜ ë¨¸ì‹ ëŸ¬ë‹ì„ ëŒ€ì²´í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ë°”ë¡œ í•˜ì´í¼ìŠ¤ì¼€ì¼ ì¸í”„ë¼ì˜ ê·¼ê°„ì…ë‹ˆë‹¤. ëŒ€ê·œëª¨ GPU í´ëŸ¬ìŠ¤í„°ì—ì„œ í•™ìŠµëœ ê´‘ê³  ì¶”ì²œìš© íŒŒìš´ë°ì´ì…˜ ëª¨ë¸ì¸ ë©”íƒ€ì˜ GEMì´ ì´ëŸ¬í•œ ë³€í™”ë¥¼ ì˜ ë³´ì—¬ì¤ë‹ˆë‹¤. 2ë¶„ê¸°ì— ë©”íƒ€ëŠ” ìƒì„±í˜• AI ê¸°ë°˜ GEMì„ í†µí•´ ì¸ìŠ¤íƒ€ê·¸ë¨ì—ì„œ ê´‘ê³  ì „í™˜ìœ¨ì´ 5% ì´ìƒ ì¦ê°€í–ˆê³ , í˜ì´ìŠ¤ë¶ í”¼ë“œì—ì„œëŠ” 3% ì¦ê°€í–ˆë‹¤ê³  ë³´ê³ í–ˆìŠµë‹ˆë‹¤. ìƒì„±í˜• AIë¡œì˜ ì „í™˜ì€ í•˜ì´í¼ìŠ¤ì¼€ì¼ëŸ¬ë“¤ì—ê²Œ ìƒë‹¹í•œ ë§¤ì¶œ ì¦ëŒ€ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.</td></tr>
<tr><td>Now a new wave is rising, agenetic AI systems capable of reasoning, planning and using tools from coding assistance like Cursor and Claude Code to radiology tools like Aidoc, legal assistants like Harvey and AI chauffeurs like Tesla FSD and Waymo. These systems mark the next frontier of computing, the fastest-growing companies in the world today, OpenAI, Anthropic, xAI, Google, Cursor, Lovable, Replit, Cognition AI, OpenEvidence, Abridge, Tesla are pioneering agentic AI. So there are 3 massive platform shifts. The transition to accelerated computing is foundational and necessary essential in a post-Moore's Law era.</td><td>ì´ì œ ìƒˆë¡œìš´ ë¬¼ê²°ì´ ì¼ê³  ìˆìŠµë‹ˆë‹¤. ì¶”ë¡ í•˜ê³ , ê³„íší•˜ê³ , ë„êµ¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì—ì´ì „í‹±(agentic) AI ì‹œìŠ¤í…œì…ë‹ˆë‹¤. Cursorì™€ Claude Code ê°™ì€ ì½”ë”© ì§€ì› ë„êµ¬ë¶€í„° Aidoc ê°™ì€ ë°©ì‚¬ì„  ë„êµ¬, Harvey ê°™ì€ ë²•ë¥  ë³´ì¡°, Tesla FSDì™€ Waymo ê°™ì€ AI ìš´ì „ì‚¬ì— ì´ë¥´ê¸°ê¹Œì§€ ë‹¤ì–‘í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ì‹œìŠ¤í…œë“¤ì€ ì»´í“¨íŒ…ì˜ ì°¨ì„¸ëŒ€ ì˜ì—­ì„ ê°œì²™í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì˜¤ëŠ˜ë‚  ì„¸ê³„ì—ì„œ ê°€ì¥ ë¹ ë¥´ê²Œ ì„±ì¥í•˜ëŠ” ê¸°ì—…ë“¤ì¸ OpenAI, Anthropic, xAI, Google, Cursor, Lovable, Replit, Cognition AI, OpenEvidence, Abridge, Teslaê°€ ì—ì´ì „í‹± AIë¥¼ ì„ ë„í•˜ê³  ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ 3ê°€ì§€ ëŒ€ê·œëª¨ í”Œë«í¼ ì „í™˜ì´ ìˆìŠµë‹ˆë‹¤. ê°€ì† ì»´í“¨íŒ…ìœ¼ë¡œì˜ ì „í™˜ì€ ë¬´ì–´ì˜ ë²•ì¹™ ì´í›„ ì‹œëŒ€ì—ì„œ ê·¼ë³¸ì ì´ê³  í•„ìˆ˜ì ì´ë©° í•µì‹¬ì ì…ë‹ˆë‹¤.</td></tr>
<tr><td>The transition to generative AI is transformational and necessary, supercharging existing applications and business models. And the transition to agentic and physical AI will be revolutionary, giving rise to new applications, companies, products and services. As you consider infrastructure investments, consider these 3 fundamental dynamics, each will contribute to infrastructure growth in the coming years. NVIDIA is chosen because our singular architecture enables all 3 transitions.</td><td>ìƒì„±í˜• AIë¡œì˜ ì „í™˜ì€ í˜ì‹ ì ì´ê³  í•„ìˆ˜ì ì´ë©°, ê¸°ì¡´ ì• í”Œë¦¬ì¼€ì´ì…˜ê³¼ ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸ì„ ê·¹ëŒ€í™”í•˜ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ë¦¬ê³  ì—ì´ì „í‹± AIì™€ ë¬¼ë¦¬ì  AIë¡œì˜ ì „í™˜ì€ í˜ëª…ì ì¼ ê²ƒì´ë©°, ìƒˆë¡œìš´ ì• í”Œë¦¬ì¼€ì´ì…˜, ê¸°ì—…, ì œí’ˆ ë° ì„œë¹„ìŠ¤ë¥¼ íƒ„ìƒì‹œí‚¬ ê²ƒì…ë‹ˆë‹¤. ì¸í”„ë¼ íˆ¬ìë¥¼ ê³ ë ¤í•˜ì‹¤ ë•Œ, ì´ 3ê°€ì§€ ê·¼ë³¸ì ì¸ ë™í–¥ì„ ê³ ë ¤í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤. ê°ê°ì€ í–¥í›„ ëª‡ ë…„ê°„ ì¸í”„ë¼ ì„±ì¥ì— ê¸°ì—¬í•  ê²ƒì…ë‹ˆë‹¤. NVIDIAê°€ ì„ íƒë°›ëŠ” ì´ìœ ëŠ” ìš°ë¦¬ì˜ ë‹¨ì¼ ì•„í‚¤í…ì²˜ê°€ ì´ 3ê°€ì§€ ì „í™˜ ëª¨ë‘ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.</td></tr>
<tr><td>And thus so, for any form and modality of AI across all industries, across every phase of AI, across all of the diverse computing needs in the cloud, and also from cloud to enterprise to robots, one architecture. Toshiya, back to you. Toshiya Hari<br>Vice President of Investor Relations & Strategic Finance<br><br>We will now open the call for questions. Operator, would you please poll for questions?</td><td>ì´ì œ ëª¨ë“  ì‚°ì—… ì „ë°˜ì— ê±¸ì³, AIì˜ ëª¨ë“  ë‹¨ê³„ì— ê±¸ì³, í´ë¼ìš°ë“œì˜ ëª¨ë“  ë‹¤ì–‘í•œ ì»´í“¨íŒ… ìš”êµ¬ì‚¬í•­ì— ëŒ€í•´, ê·¸ë¦¬ê³  í´ë¼ìš°ë“œì—ì„œ ì—”í„°í”„ë¼ì´ì¦ˆ, ë¡œë´‡ì— ì´ë¥´ê¸°ê¹Œì§€ ëª¨ë“  í˜•íƒœì™€ ë°©ì‹ì˜ AIë¥¼ ìœ„í•œ í•˜ë‚˜ì˜ ì•„í‚¤í…ì²˜ë¥¼ ì œê³µí•˜ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. í† ì‹œì•¼, ë‹¤ì‹œ ë„˜ê²¨ë“œë¦¬ê² ìŠµë‹ˆë‹¤.<br><br>í† ì‹œì•¼ í•˜ë¦¬<br>íˆ¬ìì ê´€ê³„ ë° ì „ëµ ì¬ë¬´ ë‹´ë‹¹ ë¶€ì‚¬ì¥<br><br>ì´ì œ ì§ˆì˜ì‘ë‹µ ì‹œê°„ì„ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤. êµí™˜ì›ë‹˜, ì§ˆë¬¸ì„ ë°›ì•„ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.</td></tr>
    </table>
    <h3>ğŸ“Œ ìš”ì•½</h3>
    <p style="background:#f0f0f0; padding:15px; border-left: 5px solid #333;"># NVIDIA Q3 2026 ì‹¤ì  ë°œí‘œ ìš”ì•½<br><br>â€¢ **ê°•ë ¥í•œ ì‹¤ì  ë° ì„±ì¥ ëª¨ë©˜í…€**: 3ë¶„ê¸° ë§¤ì¶œ 570ì–µ ë‹¬ëŸ¬(ì „ë…„ ëŒ€ë¹„ 62% ì¦ê°€, ì „ë¶„ê¸° ëŒ€ë¹„ 22% ì¦ê°€)ë¡œ ê¸°ë¡ ê²½ì‹ . ë°ì´í„°ì„¼í„° ë¶€ë¬¸ì€ 512ì–µ ë‹¬ëŸ¬ë¡œ 66% ì„±ì¥í–ˆìœ¼ë©°, Blackwell ì•„í‚¤í…ì²˜(íŠ¹íˆ GB300)ê°€ ë§¤ì¶œì˜ ì•½ 2/3 ê¸°ì—¬. 4ë¶„ê¸° ê°€ì´ë˜ìŠ¤ëŠ” 650ì–µ ë‹¬ëŸ¬(Â±2%)ë¡œ 14% ìˆœì°¨ ì„±ì¥ ì „ë§.<br><br>â€¢ **ìˆ˜ìš” ê°€ì‹œì„± ë° ì¥ê¸° ì „ë§**: 2026ë…„ ë§ê¹Œì§€ Blackwell ë° Rubin ì œí’ˆêµ°ì—ì„œ 5ì²œì–µ ë‹¬ëŸ¬ ê·œëª¨ì˜ ë§¤ì¶œ ê°€ì‹œì„± í™•ë³´. ì£¼ìš” í´ë¼ìš°ë“œ ì—…ì²´ë“¤ì˜ 2026ë…„ ì´ CapExëŠ” ì•½ 6ì²œì–µ ë‹¬ëŸ¬ë¡œ ì—°ì´ˆ ëŒ€ë¹„ 2ì²œì–µ ë‹¬ëŸ¬ ì´ìƒ ì¦ê°€. ê²½ì˜ì§„ì€ 2020ë…„ëŒ€ ë§ê¹Œì§€ ì—°ê°„ 3~4ì¡° ë‹¬ëŸ¬ ê·œëª¨ì˜ AI ì¸í”„ë¼ ì‹œì¥ í˜•ì„± ì˜ˆìƒí•˜ë©° ìì‹ ê° í‘œëª….<br><br>â€¢ **ì „ëµì  íŒŒíŠ¸ë„ˆì‹­ ê°•í™”**: OpenAI(ìµœì†Œ 10ê¸°ê°€ì™€íŠ¸ ë°ì´í„°ì„¼í„° êµ¬ì¶• ì§€ì› ë° íˆ¬ì ê¸°íšŒ), Anthropic(ìµœì´ˆ NVIDIA ì±„íƒ, ìµœëŒ€ 1ê¸°ê°€ì™€íŠ¸ ì»´í“¨íŒ… ì•½ì •), xAI, Meta, AWS ë“±ê³¼ ëŒ€ê·œëª¨ í˜‘ë ¥ ë°œí‘œ. ë„¤íŠ¸ì›Œí‚¹ ì‚¬ì—…ì€ 82ì–µ ë‹¬ëŸ¬ë¡œ 162% ì„±ì¥í•˜ë©° AI ì¸í”„ë¼ ìƒíƒœê³„ ë‚´ ì…ì§€ ê°•í™”.<br><br>â€¢ **</p>
    <hr style="margin:50px 0;">
    

    <h2>â“ Q&A</h2>
    <table style="width:100%; border-collapse:collapse; margin-bottom: 40px;">
        <tr>
            <th style="width:50%; border-bottom: 2px solid #333;">Original</th>
            <th style="width:50%; border-bottom: 2px solid #333;">Translation</th>
        </tr>
        <tr><td>Operator: [Operator Instructions] Your first question comes from Joseph Moore with Morgan Stanley.</td><td>**Operator:** [êµí™˜ì› ì•ˆë‚´] ì²« ë²ˆì§¸ ì§ˆë¬¸ì€ ëª¨ê±´ìŠ¤íƒ ë¦¬ì˜ ì¡°ì…‰ ë¬´ì–´ ì• ë„ë¦¬ìŠ¤íŠ¸ë¡œë¶€í„° ë°›ê² ìŠµë‹ˆë‹¤.</td></tr>
<tr><td>Joseph Moore: Morgan Stanley, Research Division I wonder if you could update us, you talked about the $500 billion of revenue for Blackwell plus Rubin in '25 and '26 at GTC. At that time, you talked about $150 billion of that already having been shipped. So as the quarter is wrapped up, are those still kind of the general parameters that there's $350 billion in the next kind of 14 months or so. And I would assume over that time, you haven't seen all the demand that there is, there's any possibility of upside to those numbers as we move forward.</td><td>**Joseph Moore:** GTCì—ì„œ ë§ì”€ë“œë ¸ë˜ 2025ë…„ê³¼ 2026ë…„ Blackwellê³¼ Rubinì˜ ë§¤ì¶œ 5,000ì–µ ë‹¬ëŸ¬, ê·¸ë¦¬ê³  ë‹¹ì‹œ ì´ë¯¸ ì¶œí•˜ëœ 1,500ì–µ ë‹¬ëŸ¬ì— ëŒ€í•´ ì—…ë°ì´íŠ¸ ë¶€íƒë“œë¦½ë‹ˆë‹¤. ë¶„ê¸°ê°€ ë§ˆë¬´ë¦¬ëœ ì§€ê¸ˆ, í–¥í›„ 14ê°œì›” ì •ë„ ë™ì•ˆ 3,500ì–µ ë‹¬ëŸ¬ë¼ëŠ” ì „ë°˜ì ì¸ íŒŒë¼ë¯¸í„°ê°€ ì—¬ì „íˆ ìœ íš¨í•œì§€ ê¶ê¸ˆí•©ë‹ˆë‹¤. ê·¸ë¦¬ê³  ê·¸ ê¸°ê°„ ë™ì•ˆ ëª¨ë“  ìˆ˜ìš”ë¥¼ ë‹¤ í™•ì¸í•˜ì‹  ê±´ ì•„ë‹ ê²ƒìœ¼ë¡œ ìƒê°ë˜ëŠ”ë°, ì•ìœ¼ë¡œ ì´ ìˆ˜ì¹˜ë“¤ì´ ìƒí–¥ë  ê°€ëŠ¥ì„±ì´ ìˆì„ê¹Œìš”?</td></tr>
<tr><td>Colette Kress: Executive VP & CFO Yes. Thanks, Joe. I'll start first with a response here on that. Yes, that's correct. We are working into our $500 billion forecast. And we are on track for that as we have finished some of the quarters, and now we have several quarters now in front of us to take us through the end of calendar year '26. The number will grow. And we will achieve, I'm sure, additional needs for compute that will be shippable by fiscal year '26. So we shipped $50 billion this quarter but we would be not finished if we didn't say that we'll probably be taking more orders. For example, just even today, our announcements with KSA. And that agreement in itself is 400,000 to 600,000 more GPUs over 3 years. Anthropic is also net new. So there's definitely an opportunity for us to have more on top of the $500 billion that we announced.</td><td>**Colette Kress:** ë„¤, ê°ì‚¬í•©ë‹ˆë‹¤. ë¨¼ì € ì œê°€ ë‹µë³€ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ë§ìŠµë‹ˆë‹¤. ìš°ë¦¬ëŠ” 5,000ì–µ ë‹¬ëŸ¬ ì „ë§ì¹˜ë¥¼ í–¥í•´ ì‘ì—…í•˜ê³  ìˆìŠµë‹ˆë‹¤. ëª‡ ë¶„ê¸°ë¥¼ ë§ˆë¬´ë¦¬í•œ ì§€ê¸ˆ, ìš°ë¦¬ëŠ” ê·¸ ëª©í‘œë¥¼ í–¥í•´ ìˆœì¡°ë¡­ê²Œ ì§„í–‰ ì¤‘ì´ë©°, 26ë…„ ë§ê¹Œì§€ ì•ìœ¼ë¡œ ì—¬ëŸ¬ ë¶„ê¸°ê°€ ë‚¨ì•„ìˆìŠµë‹ˆë‹¤. ì´ ìˆ˜ì¹˜ëŠ” ê³„ì† ì¦ê°€í•  ê²ƒì…ë‹ˆë‹¤. ê·¸ë¦¬ê³  26íšŒê³„ì—°ë„ê¹Œì§€ ì¶œí•˜ ê°€ëŠ¥í•œ ì»´í“¨íŒ…ì— ëŒ€í•œ ì¶”ê°€ ìˆ˜ìš”ë¥¼ í™•ë³´í•  ê²ƒì´ë¼ê³  í™•ì‹ í•©ë‹ˆë‹¤. ì´ë²ˆ ë¶„ê¸°ì— 500ì–µ ë‹¬ëŸ¬ë¥¼ ì¶œí•˜í–ˆì§€ë§Œ, ì¶”ê°€ ì£¼ë¬¸ì„ ë” ë°›ê²Œ ë  ê²ƒì´ë¼ëŠ” ì ì„ ë§ì”€ë“œë¦¬ì§€ ì•Šìœ¼ë©´ ì™„ì „í•œ ë‹µë³€ì´ ì•„ë‹ ê²ƒì…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì˜¤ëŠ˜ ë°œí‘œí•œ ì‚¬ìš°ë””ì•„ë¼ë¹„ì•„ì™€ì˜ ê³„ì•½ë§Œ í•´ë„ í–¥í›„ 3ë…„ê°„ 40ë§Œ~60ë§Œ ê°œì˜ GPUê°€ ì¶”ê°€ë©ë‹ˆë‹¤. Anthropicë„ ìˆœì¦ ë¬¼ëŸ‰ì…ë‹ˆë‹¤. ì €í¬ê°€ ë°œí‘œí•œ 5,000ì–µ ë‹¬ëŸ¬ ì™¸ì— ì¶”ê°€ë¡œ í™•ë³´í•  ìˆ˜ ìˆëŠ” ê¸°íšŒê°€ ë¶„ëª…íˆ ìˆìŠµë‹ˆë‹¤.</td></tr>
<tr><td>Operator: The next question comes from CJ Muse with Cantor Fitzgerald.</td><td>**Operator:** ë‹¤ìŒ ì§ˆë¬¸ì€ Cantor Fitzgeraldì˜ CJ Museë‹˜ê»˜ì„œ ì£¼ì‹œê² ìŠµë‹ˆë‹¤.</td></tr>
<tr><td>Christopher Muse: Cantor Fitzgerald & Co., Research Division There's clearly a great deal of consternation around the magnitude of AI infrastructure build-outs and the ability to fund such plans and the ROI yet, at the same time, you're talking about being sold out, every stood up GP is taken. The AI world hasn't seen the enormous benefit yet from B300, never mind Rubin, and Gemini 3 just announced Grok 5 coming soon. And so the question is this, when you look at that as the backdrop do you see a realistic path for supply to catch up with demand over the next 12 to 18 months? Or do you think it can extend beyond that time frame?</td><td>**Christopher Muse:** AI ì¸í”„ë¼ êµ¬ì¶• ê·œëª¨ì™€ ì´ë¥¼ ìœ„í•œ ìê¸ˆ ì¡°ë‹¬ ëŠ¥ë ¥, ê·¸ë¦¬ê³  íˆ¬ììˆ˜ìµë¥ ì— ëŒ€í•œ ìš°ë ¤ê°€ ë¶„ëª…íˆ í° ìƒí™©ì…ë‹ˆë‹¤. í•˜ì§€ë§Œ ë™ì‹œì— ê·€ì‚¬ëŠ” ì™„íŒë˜ì—ˆê³ , ê°€ë™ëœ ëª¨ë“  GPUê°€ ì‚¬ìš© ì¤‘ì´ë¼ê³  ë§ì”€í•˜ì…¨ìŠµë‹ˆë‹¤. AI ì—…ê³„ëŠ” ì•„ì§ B300ì˜ ì—„ì²­ë‚œ ì´ì ì„ ë³´ì§€ ëª»í–ˆê³ , Rubinì€ ë§í•  ê²ƒë„ ì—†ìœ¼ë©°, Gemini 3ê°€ ë§‰ ë°œí‘œë˜ì—ˆê³  Grok 5ë„ ê³§ ì¶œì‹œë  ì˜ˆì •ì…ë‹ˆë‹¤. ì´ëŸ¬í•œ ìƒí™©ì„ ë°°ê²½ìœ¼ë¡œ ë³¼ ë•Œ, í–¥í›„ 12ê°œì›”ì—ì„œ 18ê°œì›” ë‚´ì— ê³µê¸‰ì´ ìˆ˜ìš”ë¥¼ ë”°ë¼ì¡ì„ ìˆ˜ ìˆëŠ” í˜„ì‹¤ì ì¸ ê²½ë¡œê°€ ë³´ì´ì‹­ë‹ˆê¹Œ? ì•„ë‹ˆë©´ ê·¸ ê¸°ê°„ì„ ë„˜ì–´ì„œê¹Œì§€ ì—°ì¥ë  ê²ƒìœ¼ë¡œ ë³´ì‹­ë‹ˆê¹Œ?</td></tr>
<tr><td>Jen-Hsun Huang: Co-Founder, CEO, President & Director Well, as you know, we've done a really good job planning our supply chain. NVIDIA supply chain basically includes every technology company in the world. And TSMC and their packaging and our memory vendors -- memory partners and all of our system ODMs have done a really good job planning with us. And we were planning for a big year. We've seen for some time, the 3 transitions that I spoke about just a second ago, accelerated computing from general-purpose computing. And it's really important to recognize that AI is not just agentic AI but generative AI is transforming the way that hyperscalers did the work that they used to do on CPUs. Generative AI made it possible for them to move search and recommender systems and ad recommendations and targeting, all of that has been moved to generative AI and still transitioning. And so whether you install NVIDIA GPUs for data processing or you did it for generative AI for your recommender system or you're building it for agentic chatbots and the type of AIs that most people see when they think about AI, all of those applications are accelerated by NVIDIA. And so when you -- when you look at the totality of the spend, it's really important to think about each 1 of those layers. They're all growing. They're related, but not the same, but the wonderful thing is that they all run on NVIDIA GPUs. Simultaneously, because the quality of the AI models are improving so incredibly. The adoption of it in the different use cases, whether it's in code assistance, which NVIDIA uses fairly exhaustively, and we're not the only one. I mean, the fastest-growing application in history, a combination of Cursor and Claude Code and code -- OpenAI's Codex and GitHub CoPilot. These applications are the fastest-growing in history. And it's not just used for software engineers. It's used by because of wide coding is used by engineers and marketeers all over companies, supply chain planners, all over companies. And so I think that that's just 1 example, and the list goes on, whether it's OpenEvidence and the work that they do in health care or the work that's being done in digital video editing, Runway in -- I mean a number of really, really exciting start-ups that are taking advantage of generative AI and agentic AI is growing quite rapidly. And not to mention we're all using it a lot more. And so all of these exponentials , not to mention just today, I was reading a text from Denis. And he was saying that pre-training and post training are fully intact. And Gemini 3 takes advantage of the scaling laws and got to receive a huge jump in quality performance -- model performance. And so we're seeing all of these exponentials kind of running at the same time. And just always go back to first principles and think about what's happening from each one of the dynamics that I mentioned before, general purpose computing to accelerated computing, generative AI replacing classical machine learning and, of course, agentic AI, which is a brand-new category.</td><td>**Jen-Hsun Huang:** ì•„ì‹œë‹¤ì‹œí”¼ ìš°ë¦¬ëŠ” ê³µê¸‰ë§ ê³„íšì„ ì •ë§ ì˜ ì„¸ì›Œì™”ìŠµë‹ˆë‹¤. ì—”ë¹„ë””ì•„ ê³µê¸‰ë§ì€ ê¸°ë³¸ì ìœ¼ë¡œ ì „ ì„¸ê³„ ëª¨ë“  ê¸°ìˆ  ê¸°ì—…ë“¤ì„ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤. TSMCì™€ ê·¸ë“¤ì˜ íŒ¨í‚¤ì§•, ê·¸ë¦¬ê³  ìš°ë¦¬ ë©”ëª¨ë¦¬ ë²¤ë”ë“¤ - ë©”ëª¨ë¦¬ íŒŒíŠ¸ë„ˆë“¤ê³¼ ëª¨ë“  ì‹œìŠ¤í…œ ODMë“¤ì´ ìš°ë¦¬ì™€ í•¨ê»˜ ì •ë§ í›Œë¥­í•˜ê²Œ ê³„íšì„ ìˆ˜ë¦½í•´ì™”ìŠµë‹ˆë‹¤. ìš°ë¦¬ëŠ” í° í•œ í•´ë¥¼ ì¤€ë¹„í•´ì™”ìŠµë‹ˆë‹¤. ì¡°ê¸ˆ ì „ì— ë§ì”€ë“œë¦° ì„¸ ê°€ì§€ ì „í™˜, ì¦‰ ë²”ìš© ì»´í“¨íŒ…ì—ì„œ ê°€ì† ì»´í“¨íŒ…(accelerated computing)ìœ¼ë¡œì˜ ì „í™˜ì„ ìš°ë¦¬ëŠ” í•œë™ì•ˆ ì§€ì¼œë´ ì™”ìŠµë‹ˆë‹¤. ê·¸ë¦¬ê³  AIê°€ ë‹¨ìˆœíˆ ì—ì´ì „í‹± AIë§Œì´ ì•„ë‹ˆë¼ ìƒì„±í˜• AIê°€ í•˜ì´í¼ìŠ¤ì¼€ì¼ëŸ¬ë“¤ì´ ì˜ˆì „ì— CPUë¡œ ì²˜ë¦¬í•˜ë˜ ì‘ì—… ë°©ì‹ì„ ë³€í™”ì‹œí‚¤ê³  ìˆë‹¤ëŠ” ì ì„ ì¸ì‹í•˜ëŠ” ê²ƒì´ ì •ë§ ì¤‘ìš”í•©ë‹ˆë‹¤. ìƒì„±í˜• AI ë•ë¶„ì— ê²€ìƒ‰, ì¶”ì²œ ì‹œìŠ¤í…œ, ê´‘ê³  ì¶”ì²œ ë° íƒ€ê²ŸíŒ… ë“± ëª¨ë“  ê²ƒì´ ìƒì„±í˜• AIë¡œ ì „í™˜ë˜ì—ˆê³  ì•„ì§ë„ ì „í™˜ ì¤‘ì…ë‹ˆë‹¤. ê·¸ë˜ì„œ ë°ì´í„° ì²˜ë¦¬ë¥¼ ìœ„í•´ NVIDIA GPUë¥¼ ì„¤ì¹˜í•˜ë“ , ì¶”ì²œ ì‹œìŠ¤í…œì„ ìœ„í•œ ìƒì„±í˜• AIë¥¼ ìœ„í•´ ì„¤ì¹˜í•˜ë“ , ì•„ë‹ˆë©´ ëŒ€ë¶€ë¶„ì˜ ì‚¬ëŒë“¤ì´ AIë¥¼ ë– ì˜¬ë¦´ ë•Œ ìƒê°í•˜ëŠ” ì—ì´ì „í‹± ì±—ë´‡ì´ë‚˜ ê·¸ëŸ° ìœ í˜•ì˜ AIë¥¼ êµ¬ì¶•í•˜ë“ , ì´ ëª¨ë“  ì• í”Œë¦¬ì¼€ì´ì…˜ì´ NVIDIAë¡œ ê°€ì†í™”ë©ë‹ˆë‹¤. ë”°ë¼ì„œ ì „ì²´ ì§€ì¶œ ê·œëª¨ë¥¼ ë³´ì‹¤ ë•Œ, ê°ê°ì˜ ë ˆì´ì–´ë¥¼ ìƒê°í•´ë³´ì‹œëŠ” ê²ƒì´ ì •ë§ ì¤‘ìš”í•©ë‹ˆë‹¤. ëª¨ë‘ ì„±ì¥í•˜ê³  ìˆê³ , ì„œë¡œ ì—°ê´€ë˜ì–´ ìˆì§€ë§Œ ë™ì¼í•˜ì§€ëŠ” ì•ŠìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ë†€ë¼ìš´ ì ì€ ì´ ëª¨ë“  ê²ƒì´ NVIDIA GPUì—ì„œ ì‹¤í–‰ëœë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤. ë™ì‹œì— AI ëª¨ë¸ì˜ í’ˆì§ˆì´ ì—„ì²­ë‚˜ê²Œ í–¥ìƒë˜ê³  ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ë‹¤ì–‘í•œ ì‚¬ìš© ì‚¬ë¡€ì—ì„œì˜ ë„ì… í˜„í™©ì„ ë³´ë©´, ì½”ë“œ ì§€ì›(code assistance) ë¶„ì•¼ê°€ ìˆëŠ”ë°, NVIDIAë„ ìƒë‹¹íˆ ê´‘ë²”ìœ„í•˜ê²Œ í™œìš©í•˜ê³  ìˆê³ , ì €í¬ë§Œ ê·¸ëŸ° ê²ƒë„ ì•„ë‹™ë‹ˆë‹¤. ì—­ì‚¬ìƒ ê°€ì¥ ë¹ ë¥´ê²Œ ì„±ì¥í•˜ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì´ë¼ê³  í•˜ë©´, Cursorì™€ Claude Code, ê·¸ë¦¬ê³  OpenAIì˜ Codex, GitHub CoPilot ê°™ì€ ê²ƒë“¤ì˜ ì¡°í•©ì„ ë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŸ° ì• í”Œë¦¬ì¼€ì´ì…˜ë“¤ì´ ì—­ì‚¬ìƒ ê°€ì¥ ë¹ ë¥¸ ì„±ì¥ì„¸ë¥¼ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ë¦¬ê³  ì´ê±´ ì†Œí”„íŠ¸ì›¨ì–´ ì—”ì§€ë‹ˆì–´ë“¤ë§Œ ì‚¬ìš©í•˜ëŠ” ê²Œ ì•„ë‹™ë‹ˆë‹¤. ì½”ë”©ì´ ê´‘ë²”ìœ„í•˜ê²Œ í™œìš©ë˜ë©´ì„œ ì—”ì§€ë‹ˆì–´ë“¤ê³¼ ë§ˆì¼€í„°ë“¤, ê³µê¸‰ë§ ê¸°íšìë“¤ ë“± íšŒì‚¬ ì „ë°˜ì— ê±¸ì³ ì‚¬ìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ê²ƒì€ í•œ ê°€ì§€ ì˜ˆì‹œì¼ ë¿ì´ê³ , í—¬ìŠ¤ì¼€ì–´ ë¶„ì•¼ì—ì„œ í™œë™í•˜ëŠ” OpenEvidenceë‚˜ ë””ì§€í„¸ ì˜ìƒ í¸ì§‘ ë¶„ì•¼ì˜ Runway ë“± ìƒì„±í˜• AI(generative AI)ì™€ ì—ì´ì „í‹± AI(agentic AI)ë¥¼ í™œìš©í•˜ëŠ” ì •ë§ í¥ë¯¸ë¡­ê³  ìœ ë§í•œ ìŠ¤íƒ€íŠ¸ì—…ë“¤ì´ ë¹ ë¥´ê²Œ ì„±ì¥í•˜ê³  ìˆìŠµë‹ˆë‹¤. ê²Œë‹¤ê°€ ìš°ë¦¬ ëª¨ë‘ê°€ ì´ëŸ° ê¸°ìˆ ë“¤ì„ í›¨ì”¬ ë” ë§ì´ ì‚¬ìš©í•˜ê³  ìˆì£ . ì´ëŸ° ëª¨ë“  ê¸°í•˜ê¸‰ìˆ˜ì ì¸ ì„±ì¥ì´ ë™ì‹œì— ì¼ì–´ë‚˜ê³  ìˆëŠ”ë°, ì˜¤ëŠ˜ë§Œ í•´ë„ Denisê°€ ë³´ë‚¸ ë©”ì‹œì§€ë¥¼ ì½ì—ˆëŠ”ë°, ì‚¬ì „ í•™ìŠµ(pre-training)ê³¼ ì‚¬í›„ í•™ìŠµ(post training)ì´ ì™„ë²½í•˜ê²Œ ìœ ì§€ë˜ê³  ìˆë‹¤ê³  í•˜ë”êµ°ìš”. Gemini 3ê°€ ìŠ¤ì¼€ì¼ë§ ë²•ì¹™(scaling laws)ì„ í™œìš©í•´ì„œ ëª¨ë¸ ì„±ëŠ¥ì—ì„œ ì—„ì²­ë‚œ ë„ì•½ì„ ì´ë¤˜ë‹¤ê³  í•©ë‹ˆë‹¤. ê·¸ë˜ì„œ ì´ëŸ° ëª¨ë“  ê¸°í•˜ê¸‰ìˆ˜ì ì¸ ë°œì „ë“¤ì´ ë™ì‹œì— ì§„í–‰ë˜ê³  ìˆëŠ” ìƒí™©ì…ë‹ˆë‹¤. <response><br><br>í•­ìƒ ê¸°ë³¸ ì›ì¹™ìœ¼ë¡œ ëŒì•„ê°€ì„œ ì œê°€ ì•ì„œ ì–¸ê¸‰í•œ ê°ê°ì˜ ì—­í•™ ê´€ê³„ì—ì„œ ë¬´ìŠ¨ ì¼ì´ ì¼ì–´ë‚˜ê³  ìˆëŠ”ì§€ ìƒê°í•´ë³´ì‹œë©´ ë©ë‹ˆë‹¤. ë²”ìš© ì»´í“¨íŒ…ì—ì„œ ê°€ì† ì»´í“¨íŒ…ìœ¼ë¡œì˜ ì „í™˜, ìƒì„±í˜• AIê°€ ê¸°ì¡´ ë¨¸ì‹ ëŸ¬ë‹ì„ ëŒ€ì²´í•˜ëŠ” ê²ƒ, ê·¸ë¦¬ê³  ë¬¼ë¡  ì™„ì „íˆ ìƒˆë¡œìš´ ì¹´í…Œê³ ë¦¬ì¸ ì—ì´ì „í‹± AIê¹Œì§€ ë§ì´ì£ .<br><br></response></td></tr>
<tr><td>Operator: The next question comes from Vivek Arya with Bank of America Securities.</td><td>**Operator:** ë‹¤ìŒ ì§ˆë¬¸ì€ ë±…í¬ì˜¤ë¸Œì•„ë©”ë¦¬ì¹´ ì¦ê¶Œì˜ Vivek Aryaë‹˜ê»˜ì„œ ì£¼ì‹œê² ìŠµë‹ˆë‹¤.</td></tr>
<tr><td>Vivek Arya: BofA Securities, Research Division I'm curious, what assumptions are you making on NVIDIA content per gigawatt in that $500 billion number? Because we have heard numbers as low as $25 billion per gigawatt of content to as high as $30 billion or $40 billion per gigawatt. So I'm curious what power and what dollar per gig assumptions you are making as part of that $500 billion number. And then longer term, Jensen, the $3 trillion to $4 trillion in data center by 2030 was mentioned. How much of that do you think will require vendor financing? And how much of that can be supported by cash flows of your large customers or governments or enterprises?</td><td>**Vivek Arya:** 5ì²œì–µ ë‹¬ëŸ¬ ê·œëª¨ì—ì„œ ê¸°ê°€ì™€íŠ¸ë‹¹ ì—”ë¹„ë””ì•„ ì½˜í…ì¸ ì— ëŒ€í•´ ì–´ë–¤ ê°€ì •ì„ í•˜ê³  ê³„ì‹ ì§€ ê¶ê¸ˆí•©ë‹ˆë‹¤. ê¸°ê°€ì™€íŠ¸ë‹¹ 250ì–µ ë‹¬ëŸ¬ì—ì„œ ë§ê²ŒëŠ” 300ì–µ~400ì–µ ë‹¬ëŸ¬ê¹Œì§€ ë‹¤ì–‘í•œ ìˆ˜ì¹˜ë“¤ì„ ë“¤ì–´ì™”ëŠ”ë°ìš”. ê·¸ë˜ì„œ 5ì²œì–µ ë‹¬ëŸ¬ ê·œëª¨ ì‚°ì •ì— ì „ë ¥ê³¼ ê¸°ê°€ì™€íŠ¸ë‹¹ ê¸ˆì•¡ì„ ì–´ë–»ê²Œ ê°€ì •í•˜ì…¨ëŠ”ì§€ ê¶ê¸ˆí•©ë‹ˆë‹¤. ê·¸ë¦¬ê³  ì¥ê¸°ì ìœ¼ë¡œ ì  ìŠ¨, 2030ë…„ê¹Œì§€ ë°ì´í„°ì„¼í„° ì‹œì¥ì´ 3ì¡°~4ì¡° ë‹¬ëŸ¬ ê·œëª¨ê°€ ë  ê²ƒì´ë¼ëŠ” ì–¸ê¸‰ì´ ìˆì—ˆëŠ”ë°ìš”. ì´ ì¤‘ ì–¼ë§ˆë‚˜ ë§ì€ ë¶€ë¶„ì´ ë²¤ë” íŒŒì´ë‚¸ì‹±ì´ í•„ìš”í•  ê²ƒìœ¼ë¡œ ë³´ì‹œë‚˜ìš”? ê·¸ë¦¬ê³  ëŒ€í˜• ê³ ê°ì‚¬ë“¤ì´ë‚˜ ì •ë¶€, ê¸°ì—…ë“¤ì˜ í˜„ê¸ˆíë¦„ìœ¼ë¡œ ì–¼ë§ˆë‚˜ ì§€ì› ê°€ëŠ¥í• ê¹Œìš”?</td></tr>
<tr><td>Jen-Hsun Huang: Co-Founder, CEO, President & Director In each generation, from Ampere to Hopper, from Hopper to Blackwell, Blackwell to Rubin, our part of the data center increases. And Hopper generation was probably something along the lines of 20-some-odd, 20 to 25. Blackwell generation, Grace Blackwell particularly is probably 30 to 30 to say, 30 plus or minus and then Rubin is probably higher than that. And in each one of these generations, the speed up is X factors. And therefore, their TCO, the customer TCO, improves by X factors, and the most important thing is, in the end, you still only have 1 gigawatt of power. One gigawatt data centers, 1 gigawatt power. And therefore, performance per watt, the efficiency of your architecture is incredibly important. And the efficiency of your architecture can't be brute force. There is no brute forcing about it. That 1 gigawatt translates directly. Your performance per watt translates directly absolutely directly to your revenues, which is the reason why choosing the right architecture matters so much now. The world doesn't have an excess of anything to squander. And so we have to be really, really -- we use this concept called codesign across our entire stack, across the frameworks and models, across the entire data center, even power and cooling, optimized across the entire supply chain or ecosystem. And so each generation, our economic contribution will be greater. Our value delivered will be greater but the most important thing is our energy efficiency per watt is going to be extraordinary, every single generation. With respect to growing into -- continuing to grow, our customers' financing is up to them. We are -- we see the opportunity to grow for quite some time. And remember, today, most of the focus has been on the hyperscalers. And one of the areas that is really misunderstood about the hyperscalers is that the investment on NVIDIA GPUs not only improves their scale, speed and cost for -- from general purpose computing. That's number 1, because Moore's Law saw scaling has really slowed. Moore's Law is about driving cost down. It's about deflationary cost, the incredible deflationary cost of computing over time. But that has slowed. Therefore, a new approach is necessary for them to keep driving the cost down. Going to NVIDIA GPU computing is really the best way to do so. The second is revenue boosting in their current business models, recommender systems drive the world's hyperscalers. Every single -- whether it's watching short-form videos or recommending books or recommending the next item in your basket to recommending ads to recommending news to -- it's all about recommenders. The world has -- the Internet has trillions of pieces of content, how could they possibly figure out what to put in front of you and your little tiny screen, unless they have really sophisticated recommender systems to do so. Well, that has gone generative AI, so the first 2 things that I've just said, hundreds of billions of dollars of CapEx that's going to have to be invested is fully cash flow funded. What is above it, therefore, is agentic AI. This is revenue -- this is net new, net new consumption, but it's also net new applications and some of the applications I mentioned before, but these are -- these new applications are also the fastest-growing applications in history, okay? So I think that you're going to see that once people start to appreciate what is actually happening under the water, if you will, from the simplistic view of what's happening to CapEx investment, recognizing there's these 3 dynamics. And then lastly, remember, we were just talking about the American CSPs. Each country will fund their own infrastructure. And you have multiple countries, you have multiple industries. Most of the world's industries haven't really engaged agentic AI yet, and they're about to. All the names of companies that you know we're working with, whether it's autonomous vehicle companies or digital twins for physical AI for factories and the number of factories and warehouses being built around the world, just a number of digital biology start-ups that are being funded so that we could accelerate drug discovery. All of those different industries are now getting engaged, and they're going to do their own fundraising. And so don't just look at the hyperscalers as a way to build out for the future. You got to look at the world, you got to look at all the different industries and enterprise computing is going to fund their own industry.</td><td>**Jen-Hsun Huang:** ê° ì„¸ëŒ€ë§ˆë‹¤, Ampereì—ì„œ Hopperë¡œ, Hopperì—ì„œ Blackwellë¡œ, Blackwellì—ì„œ Rubinìœ¼ë¡œ ë„˜ì–´ê°€ë©´ì„œ ë°ì´í„°ì„¼í„°ì—ì„œ ìš°ë¦¬ê°€ ì°¨ì§€í•˜ëŠ” ë¹„ì¤‘ì´ ì¦ê°€í•˜ê³  ìˆìŠµë‹ˆë‹¤. Hopper ì„¸ëŒ€ëŠ” ì•„ë§ˆ 20% ì¤‘ë°˜ëŒ€, 20~25% ì •ë„ì˜€ì„ ê²ë‹ˆë‹¤. Blackwell ì„¸ëŒ€, íŠ¹íˆ Grace Blackwellì€ ì•„ë§ˆ 30% ì •ë„, 30% ì „í›„ê°€ ë  ê²ƒì´ê³ , Rubinì€ ê·¸ë³´ë‹¤ ë” ë†’ì„ ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤. ê·¸ë¦¬ê³  ì´ëŸ¬í•œ ê° ì„¸ëŒ€ë§ˆë‹¤ ì†ë„ í–¥ìƒì€ Xë°° ìˆ˜ì¤€ì…ë‹ˆë‹¤. ë”°ë¼ì„œ ê³ ê°ì˜ TCO(ì´ì†Œìœ ë¹„ìš©)ë„ Xë°°ë§Œí¼ ê°œì„ ë˜ëŠ” ê²ƒì´ì£ . ê°€ì¥ ì¤‘ìš”í•œ ì ì€, ê²°êµ­ ì—¬ì „íˆ 1ê¸°ê°€ì™€íŠ¸ì˜ ì „ë ¥ë§Œ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤ëŠ” ê²ë‹ˆë‹¤. 1ê¸°ê°€ì™€íŠ¸ ë°ì´í„°ì„¼í„°, 1ê¸°ê°€ì™€íŠ¸ ì „ë ¥ì´ì£ . ê·¸ë ‡ê¸° ë•Œë¬¸ì— ì™€íŠ¸ë‹¹ ì„±ëŠ¥, ì¦‰ ì•„í‚¤í…ì²˜ì˜ íš¨ìœ¨ì„±ì´ ì—„ì²­ë‚˜ê²Œ ì¤‘ìš”í•©ë‹ˆë‹¤. ê·¸ë¦¬ê³  ì•„í‚¤í…ì²˜ì˜ íš¨ìœ¨ì„±ì€ ë¬´ì°¨ë³„ ëŒ€ì…(brute force)ìœ¼ë¡œ í•´ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¬´ì°¨ë³„ ëŒ€ì…ê³¼ëŠ” ì „í˜€ ê´€ê³„ê°€ ì—†ì–´ìš”. 1ê¸°ê°€ì™€íŠ¸ëŠ” ì§ì ‘ì ìœ¼ë¡œ ì „í™˜ë©ë‹ˆë‹¤. ì™€íŠ¸ë‹¹ ì„±ëŠ¥ì´ ë§¤ì¶œë¡œ ì§ì ‘ ì—°ê²°ë˜ëŠ” ê±°ì£ . ì™„ì „íˆ ì§ì ‘ì ìœ¼ë¡œìš”. ê·¸ë˜ì„œ ì§€ê¸ˆ ì˜¬ë°”ë¥¸ ì•„í‚¤í…ì²˜ë¥¼ ì„ íƒí•˜ëŠ” ê²ƒì´ ë§¤ìš° ì¤‘ìš”í•œ ê²ë‹ˆë‹¤. ì„¸ìƒì—ëŠ” ë‚­ë¹„í•  ë§Œí¼ ì—¬ìœ ë¡œìš´ ê²Œ ì—†ìŠµë‹ˆë‹¤. ê·¸ë˜ì„œ ìš°ë¦¬ëŠ” ì •ë§, ì •ë§ ì‹ ì¤‘í•´ì•¼ í•˜ì£ . ìš°ë¦¬ëŠ” ì½”ë””ìì¸(codesign)ì´ë¼ëŠ” ê°œë…ì„ ì „ì²´ ìŠ¤íƒì— ê±¸ì³ ì‚¬ìš©í•©ë‹ˆë‹¤. í”„ë ˆì„ì›Œí¬ì™€ ëª¨ë¸ ì „ë°˜ì— ê±¸ì³ì„œ, ì „ì²´ ë°ì´í„°ì„¼í„°ì— ê±¸ì³ì„œ, ì‹¬ì§€ì–´ ì „ë ¥ê³¼ ëƒ‰ê°ê¹Œì§€, ì „ì²´ ê³µê¸‰ë§ì´ë‚˜ ìƒíƒœê³„ ì „ë°˜ì— ê±¸ì³ ìµœì í™”í•˜ëŠ” ê±°ì£ . ê·¸ë˜ì„œ ë§¤ ì„¸ëŒ€ë§ˆë‹¤ ìš°ë¦¬ì˜ ê²½ì œì  ê¸°ì—¬ë„ê°€ ë” ì»¤ì§ˆ ê²ë‹ˆë‹¤. ìš°ë¦¬ê°€ ì œê³µí•˜ëŠ” ê°€ì¹˜ëŠ” ë” ì»¤ì§ˆ ê²ƒì´ê³ , ê°€ì¥ ì¤‘ìš”í•œ ê²ƒì€ ì™€íŠ¸ë‹¹ ì—ë„ˆì§€ íš¨ìœ¨ì´ ë§¤ ì„¸ëŒ€ë§ˆë‹¤ ë†€ë¼ìš¸ ì •ë„ë¡œ í–¥ìƒë  ê²ƒì´ë¼ëŠ” ì ì…ë‹ˆë‹¤. ì§€ì†ì ì¸ ì„±ì¥ê³¼ ê´€ë ¨í•´ì„œ, ê³ ê°ë“¤ì˜ ìê¸ˆ ì¡°ë‹¬ì€ ê·¸ë“¤ì˜ ëª«ì…ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ìƒë‹¹ ê¸°ê°„ ë™ì•ˆ ì„±ì¥í•  ìˆ˜ ìˆëŠ” ê¸°íšŒë¥¼ ë³´ê³  ìˆìŠµë‹ˆë‹¤. ê¸°ì–µí•˜ì‹¤ ì ì€, í˜„ì¬ ëŒ€ë¶€ë¶„ì˜ ê´€ì‹¬ì´ í•˜ì´í¼ìŠ¤ì¼€ì¼ëŸ¬ë“¤ì—ê²Œ ì§‘ì¤‘ë˜ì–´ ìˆë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤. í•˜ì´í¼ìŠ¤ì¼€ì¼ëŸ¬ë“¤ì— ëŒ€í•´ ì •ë§ ì˜¤í•´ë°›ê³  ìˆëŠ” ë¶€ë¶„ ì¤‘ í•˜ë‚˜ëŠ”, NVIDIA GPUì— ëŒ€í•œ íˆ¬ìê°€ ë²”ìš© ì»´í“¨íŒ…ì˜ ê·œëª¨ì™€ ì†ë„, ë¹„ìš©ì„ ê°œì„ í•  ë¿ë§Œ ì•„ë‹ˆë¼ - ì´ê²Œ ì²« ë²ˆì§¸ì¸ë°, ë¬´ì–´ì˜ ë²•ì¹™ í™•ì¥ì´ ì‹¤ì œë¡œ ë§ì´ ë‘”í™”ëê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ë¬´ì–´ì˜ ë²•ì¹™ì€ ë¹„ìš©ì„ ë‚®ì¶”ëŠ” ê²ƒì— ê´€í•œ ê²ƒì…ë‹ˆë‹¤. ì‹œê°„ì´ ì§€ë‚¨ì— ë”°ë¼ ì»´í“¨íŒ… ë¹„ìš©ì´ ë†€ëë„ë¡ í•˜ë½í•˜ëŠ”, ë””í”Œë ˆì´ì…˜ íš¨ê³¼ì— ê´€í•œ ê²ƒì´ì£ . í•˜ì§€ë§Œ ê·¸ ì†ë„ê°€ ëŠë ¤ì¡ŒìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ë¹„ìš©ì„ ì§€ì†ì ìœ¼ë¡œ ë‚®ì¶”ê¸° ìœ„í•´ì„œëŠ” ìƒˆë¡œìš´ ì ‘ê·¼ ë°©ì‹ì´ í•„ìš”í•©ë‹ˆë‹¤. NVIDIA GPU ì»´í“¨íŒ…ìœ¼ë¡œ ì „í™˜í•˜ëŠ” ê²ƒì´ ì‹¤ì œë¡œ ê°€ì¥ ì¢‹ì€ ë°©ë²•ì…ë‹ˆë‹¤. ë‘ ë²ˆì§¸ëŠ” í˜„ì¬ ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸ì—ì„œ ë§¤ì¶œì„ ì¦ëŒ€ì‹œí‚¤ëŠ” ê²ƒì¸ë°, ì¶”ì²œ ì‹œìŠ¤í…œì´ ì „ ì„¸ê³„ í•˜ì´í¼ìŠ¤ì¼€ì¼ëŸ¬ë“¤ì„ ì›€ì§ì´ê³  ìˆìŠµë‹ˆë‹¤. ìˆí¼ ë¹„ë””ì˜¤ë¥¼ ì‹œì²­í•˜ë“ , ì±…ì„ ì¶”ì²œí•˜ë“ , ì¥ë°”êµ¬ë‹ˆì— ë‹´ì„ ë‹¤ìŒ ìƒí’ˆì„ ì¶”ì²œí•˜ë“ , ê´‘ê³ ë¥¼ ì¶”ì²œí•˜ë“ , ë‰´ìŠ¤ë¥¼ ì¶”ì²œí•˜ë“  - ëª¨ë“  ê²ƒì´ ì¶”ì²œ ì‹œìŠ¤í…œì— ê´€í•œ ê²ƒì…ë‹ˆë‹¤. ì¸í„°ë„·ì—ëŠ” ìˆ˜ì¡° ê°œì˜ ì½˜í…ì¸ ê°€ ìˆëŠ”ë°, ì •ë§ ì •êµí•œ ì¶”ì²œ ì‹œìŠ¤í…œ ì—†ì´ ì–´ë–»ê²Œ ì—¬ëŸ¬ë¶„ì˜ ì‘ì€ í™”ë©´ì— ë¬´ì—‡ì„ ë³´ì—¬ì¤„ì§€ ì•Œì•„ë‚¼ ìˆ˜ ìˆê² ìŠµë‹ˆê¹Œ. ìƒì„±í˜• AIë¡œ ë„˜ì–´ê°€ë©´ì„œ, ì œê°€ ë°©ê¸ˆ ë§ì”€ë“œë¦° ì²˜ìŒ ë‘ ê°€ì§€, ì¦‰ ìˆ˜ì²œì–µ ë‹¬ëŸ¬ì˜ ìë³¸ ì§€ì¶œ(CapEx)ì´ íˆ¬ìë˜ì–´ì•¼ í•˜ëŠ”ë° ì´ëŠ” ì „ì•¡ í˜„ê¸ˆ íë¦„ìœ¼ë¡œ ì¶©ë‹¹ë©ë‹ˆë‹¤. ê·¸ ìœ„ì— ìˆëŠ” ê²ƒì´ ë°”ë¡œ ì—ì´ì „í‹± AIì…ë‹ˆë‹¤. ì´ê²ƒì€ ë§¤ì¶œì´ì£  - ì™„ì „íˆ ìƒˆë¡œìš´, ìˆœì¦í•˜ëŠ” ì†Œë¹„ì´ë©´ì„œ ë™ì‹œì— ì™„ì „íˆ ìƒˆë¡œìš´ ì• í”Œë¦¬ì¼€ì´ì…˜ë“¤ì…ë‹ˆë‹¤. ì œê°€ ì „ì— ì–¸ê¸‰í–ˆë˜ ì¼ë¶€ ì• í”Œë¦¬ì¼€ì´ì…˜ë“¤ì´ ìˆëŠ”ë°, ì´ ìƒˆë¡œìš´ ì• í”Œë¦¬ì¼€ì´ì…˜ë“¤ì€ ì—­ì‚¬ìƒ ê°€ì¥ ë¹ ë¥´ê²Œ ì„±ì¥í•˜ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ë“¤ì´ê¸°ë„ í•©ë‹ˆë‹¤. ê·¸ë˜ì„œ ì‚¬ëŒë“¤ì´ ì‹¤ì œë¡œ ìˆ˜ë©´ ì•„ë˜ì—ì„œ ë¬´ìŠ¨ ì¼ì´ ì¼ì–´ë‚˜ê³  ìˆëŠ”ì§€ ì´í•´í•˜ê¸° ì‹œì‘í•˜ë©´, ìë³¸ ì§€ì¶œ íˆ¬ìì— ëŒ€í•œ ë‹¨ìˆœí•œ ì‹œê°ì—ì„œ ë²—ì–´ë‚˜ ì´ ì„¸ ê°€ì§€ ì—­í•™ ê´€ê³„ë¥¼ ì¸ì‹í•˜ê²Œ ë  ê²ƒì…ë‹ˆë‹¤. ê·¸ë¦¬ê³  ë§ˆì§€ë§‰ìœ¼ë¡œ ê¸°ì–µí•˜ì„¸ìš”, ìš°ë¦¬ëŠ” ë°©ê¸ˆ ë¯¸êµ­ í†µì‹ ì‚¬ì—…ìë“¤ì— ëŒ€í•´ì„œë§Œ ì´ì•¼ê¸°í–ˆìŠµë‹ˆë‹¤. ê°êµ­ì´ ìì²´ ì¸í”„ë¼ì— íˆ¬ìí•  ê²ƒì…ë‹ˆë‹¤. ì—¬ëŸ¬ êµ­ê°€ê°€ ìˆê³ , ì—¬ëŸ¬ ì‚°ì—…ì´ ìˆìŠµë‹ˆë‹¤. ì „ ì„¸ê³„ ëŒ€ë¶€ë¶„ì˜ ì‚°ì—…ì€ ì•„ì§ ì—ì´ì „í‹± AI(agentic AI)ì— ë³¸ê²©ì ìœ¼ë¡œ ì°¸ì—¬í•˜ì§€ ì•Šì•˜ì§€ë§Œ, ê³§ ê·¸ë ‡ê²Œ ë  ê²ƒì…ë‹ˆë‹¤. ìš°ë¦¬ê°€ í˜‘ë ¥í•˜ê³  ìˆëŠ” ê²ƒìœ¼ë¡œ ì•Œë ¤ì§„ ëª¨ë“  ê¸°ì—…ë“¤, ììœ¨ì£¼í–‰ì°¨ ê¸°ì—…ì´ë“ , ê³µì¥ì„ ìœ„í•œ ë¬¼ë¦¬ì  AI(physical AI)ìš© ë””ì§€í„¸ íŠ¸ìœˆì´ë“ , ì „ ì„¸ê³„ì ìœ¼ë¡œ ê±´ì„¤ë˜ê³  ìˆëŠ” ìˆ˜ë§ì€ ê³µì¥ê³¼ ë¬¼ë¥˜ì°½ê³ ë“ , ì‹ ì•½ ê°œë°œì„ ê°€ì†í™”í•˜ê¸° ìœ„í•´ íˆ¬ìë°›ê³  ìˆëŠ” ìˆ˜ë§ì€ ë””ì§€í„¸ ìƒë¬¼í•™ ìŠ¤íƒ€íŠ¸ì—…ì´ë“  ë§ì…ë‹ˆë‹¤. ì´ ëª¨ë“  ë‹¤ì–‘í•œ ì‚°ì—…ë“¤ì´ ì§€ê¸ˆ ì°¸ì—¬í•˜ê³  ìˆìœ¼ë©°, ê°ì ìì²´ì ìœ¼ë¡œ ìê¸ˆì„ ì¡°ë‹¬í•  ê²ƒì…ë‹ˆë‹¤. ë”°ë¼ì„œ ë¯¸ë˜ë¥¼ ìœ„í•œ êµ¬ì¶• ë°©ë²•ìœ¼ë¡œ í•˜ì´í¼ìŠ¤ì¼€ì¼ëŸ¬ë§Œ ë³´ì§€ ë§ˆì‹œê¸° ë°”ëë‹ˆë‹¤. ì„¸ê³„ ì‹œì¥ì„ ë´ì•¼ í•˜ê³ , ë‹¤ì–‘í•œ ì‚°ì—…ë“¤ì„ ì‚´í´ë´ì•¼ í•©ë‹ˆë‹¤. ê·¸ë¦¬ê³  ì—”í„°í”„ë¼ì´ì¦ˆ ì»´í“¨íŒ…ì€ ìì²´ ì‚°ì—…ì„ ìê¸ˆ ì¡°ë‹¬í•  ê²ƒì…ë‹ˆë‹¤.</td></tr>
<tr><td>Operator: The next question comes from Ben Reitzes with Melius.</td><td>**Operator:** ë‹¤ìŒ ì§ˆë¬¸ì€ Meliusì˜ Ben Reitzesë‹˜ê»˜ì„œ ì£¼ì‹œê² ìŠµë‹ˆë‹¤.</td></tr>
<tr><td>Melius Research LLC: Jensen, I wanted to ask you about cash. Speaking of $0.5 trillion, you may generate about $0.5 trillion in free cash flow over the next couple of years. What are your plans for that cash? How much goes to buyback versus investing in the ecosystem? And how do you look at investing in the ecosystem? I think there's just a lot of confusion out there about how these deals work and your criteria for doing those like the Anthropic, the OpenAI's, et cetera.</td><td>**Melius Research LLC:** ì  ìŠ¨, í˜„ê¸ˆì— ëŒ€í•´ ì—¬ì­¤ë³´ê³  ì‹¶ìŠµë‹ˆë‹¤. 5ì²œì–µ ë‹¬ëŸ¬ ì–˜ê¸°ê°€ ë‚˜ì™”ëŠ”ë°, í–¥í›„ ëª‡ ë…„ê°„ ì•½ 5ì²œì–µ ë‹¬ëŸ¬ì˜ ì‰ì—¬í˜„ê¸ˆíë¦„(free cash flow)ì„ ì°½ì¶œí•˜ì‹¤ ê²ƒ ê°™ìŠµë‹ˆë‹¤. ì´ í˜„ê¸ˆì„ ì–´ë–»ê²Œ í™œìš©í•˜ì‹¤ ê³„íšì´ì‹ ê°€ìš”? ìì‚¬ì£¼ ë§¤ì…ê³¼ ìƒíƒœê³„ íˆ¬ìì— ê°ê° ì–¼ë§ˆë‚˜ ë°°ë¶„í•˜ì‹¤ ê±´ê°€ìš”? ê·¸ë¦¬ê³  ìƒíƒœê³„ íˆ¬ìëŠ” ì–´ë–¤ ê´€ì ìœ¼ë¡œ ë³´ê³  ê³„ì‹ ì§€ìš”? Anthropicì´ë‚˜ OpenAI ê°™ì€ íˆ¬ì ê±´ë“¤ì´ ì‹¤ì œë¡œ ì–´ë–»ê²Œ ì§„í–‰ë˜ëŠ”ì§€, ê·¸ë¦¬ê³  ì´ëŸ° íˆ¬ìë¥¼ ê²°ì •í•˜ëŠ” ê¸°ì¤€ì´ ë¬´ì—‡ì¸ì§€ì— ëŒ€í•´ ì‹œì¥ì— ë§ì€ í˜¼ë€ì´ ìˆëŠ” ê²ƒ ê°™ìŠµë‹ˆë‹¤.</td></tr>
<tr><td>Jen-Hsun Huang: Co-Founder, CEO, President & Director Yes, I appreciate the question. Of course, using cash to fund our growth, no company has grown at the scale that we're talking about and have the connection and the depth and the breadth of supply chain that NVIDIA has. The reason why our entire customer base can rely on us is because we've secured a really resilient supply chain, and we have the balance sheet to support them. When we make purchases, our suppliers can take it to the bank. When we make forecast and we plan with them, they take us seriously because of our balance sheet. We're not making up the offtake. We know what our offtake is, and because they've been planning with us for so many years, our reputation and our credibility is incredible. And so it takes really strong balance sheet to do that, to support the level of growth and the rate of growth and the magnitude associated with that. So that's number one. The second thing, of course, we're going to continue to do stock buybacks. We're going to continue to do that. But with respect to the investments, this is really, really important work that we do. All of the investments that we've done so far, all the period, is associated with expanding the reach of CUDA expanding the ecosystem. If you look at the work that -- the investments that we did with OpenAI, it's -- of course, that relationship we've had since 2016, I delivered the first AI supercomputer ever made to OpenAI. And so we've had a close and wonderful relationship with OpenAI since then. And everything that OpenAI does runs on NVIDIA today. So all the clouds that they deploy in, whether it's training and inference runs NVIDIA and we love working with them. The partnership that we have with them is one, so that we could work even deeper from a technical perspective so that we could support their accelerated growth. This is a company that's growing incredibly fast. And don't just look at what is said in the press, look at all the ecosystem partners and all the developers that are connected to OpenAI, and they're all driving consumption of it. and the quality of the AI that's being produced, huge step-up since a year ago. And so the quality of response is extraordinary. So we invest in OpenAI for a deep partnership in co-development to expand our ecosystem and support their growth. And of course, rather than giving up a share of our company, we get a share of their company. And we invested in them, in one of the most consequential once-in-a-generation companies that we have a share of. And so I fully expect that investment to translate to extraordinary returns. Now in the case of Anthropic, this is the first time that Anthropic will be on NVIDIA's architecture. The first time Anthropic will be on NVIDIA's architecture is the second most successful AI in the world in terms of total number of users. But in enterprise, they're doing incredibly well. Claude Code is doing incredibly well. Claude Code is doing incredibly well all of the world's enterprise. And now we have the opportunity to have a deep partnership with them and bringing Claude onto the NVIDIA platform. And so what do we have now? NVIDIA's architecture, taking a step back, NVIDIA's architecture, NVIDIA's platform is the singular platform in the world that runs every AI model. We run OpenAI, we run Anthropic, we run xAI because of our deep partnership with Elon and xAI, we were able to bring that opportunity to Saudi Arabia to the KSA so that HUMAIN could also be hosting opportunity for xAI. We run xAI, we run Gemini, we run Thinking Machines, let's see, what else do we run? We've run them all. And so not to mention, we run the science models, the biology models, DNA models, gene models, chemical models and all the different fields around the world. It's not just cognitive AI that the world uses, AI is impacting every single industry. And so we have the ability to the ecosystem investments that we make to partner with -- deeply partner on a technical basis with some of the best companies, most brilliant companies in the world, we are expanding the reach of our ecosystem, and we're getting a share and investment in what will be a very successful company, oftentimes once in a generation company. And so that basic -- that's our investment thesis.</td><td>**Jen-Hsun Huang:** ë„¤, ì§ˆë¬¸ ê°ì‚¬í•©ë‹ˆë‹¤. ë¬¼ë¡  ì„±ì¥ ìê¸ˆì„ í˜„ê¸ˆìœ¼ë¡œ ì¡°ë‹¬í•˜ëŠ” ê²ƒì— ëŒ€í•´ ë§ì”€ë“œë¦¬ìë©´, ìš°ë¦¬ê°€ ì´ì•¼ê¸°í•˜ëŠ” ê·œëª¨ë¡œ ì„±ì¥í•˜ë©´ì„œ ë™ì‹œì— NVIDIAê°€ ë³´ìœ í•œ ê²ƒê³¼ ê°™ì€ ì—°ê²°ì„±ê³¼ ê¹Šì´, ê·¸ë¦¬ê³  ê³µê¸‰ë§ì˜ í­ì„ ê°–ì¶˜ íšŒì‚¬ëŠ” ì—†ìŠµë‹ˆë‹¤. ìš°ë¦¬ ì „ì²´ ê³ ê° ê¸°ë°˜ì´ ìš°ë¦¬ë¥¼ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì´ìœ ëŠ” ìš°ë¦¬ê°€ ì •ë§ íƒ„íƒ„í•œ ê³µê¸‰ë§ì„ í™•ë³´í–ˆê³ , ê·¸ë“¤ì„ ë’·ë°›ì¹¨í•  ìˆ˜ ìˆëŠ” ì¬ë¬´ì œí‘œë¥¼ ê°–ì¶”ê³  ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ìš°ë¦¬ê°€ êµ¬ë§¤ë¥¼ í•˜ë©´ ê³µê¸‰ì—…ì²´ë“¤ì€ ê·¸ê²ƒì„ ì€í–‰ì— ê°€ì ¸ê°ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìš°ë¦¬ê°€ ì˜ˆì¸¡ì„ í•˜ê³  ê·¸ë“¤ê³¼ ê³„íšì„ ì„¸ìš°ë©´, ê·¸ë“¤ì€ ìš°ë¦¬ì˜ ì¬ë¬´ì œí‘œ ë•Œë¬¸ì— ìš°ë¦¬ë¥¼ ì§„ì§€í•˜ê²Œ ë°›ì•„ë“¤ì…ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì¸ìˆ˜ëŸ‰(offtake)ì„ ì§€ì–´ë‚´ëŠ” ê²Œ ì•„ë‹™ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ìš°ë¦¬ì˜ ì¸ìˆ˜ëŸ‰ì´ ì–¼ë§ˆì¸ì§€ ì •í™•íˆ ì•Œê³  ìˆê³ , ê·¸ë“¤ì´ ìˆ˜ë…„ê°„ ìš°ë¦¬ì™€ í•¨ê»˜ ê³„íšì„ ì„¸ì›Œì™”ê¸° ë•Œë¬¸ì— ìš°ë¦¬ì˜ ëª…ì„±ê³¼ ì‹ ë¢°ë„ëŠ” ëŒ€ë‹¨í•©ë‹ˆë‹¤. ê·¸ë˜ì„œ ê·¸ëŸ° ìˆ˜ì¤€ì˜ ì„±ì¥ê³¼ ì„±ì¥ë¥ , ê·¸ë¦¬ê³  ê·¸ ê·œëª¨ë¥¼ ë’·ë°›ì¹¨í•˜ë ¤ë©´ ì •ë§ íƒ„íƒ„í•œ ì¬ë¬´êµ¬ì¡°ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì´ê²Œ ì²« ë²ˆì§¸ì…ë‹ˆë‹¤. ë‘ ë²ˆì§¸ë¡œ, ë¬¼ë¡  ìì‚¬ì£¼ ë§¤ì…ë„ ê³„ì†í•  ê²ë‹ˆë‹¤. ê³„ì† ì§„í–‰í•  ì˜ˆì •ì…ë‹ˆë‹¤. í•˜ì§€ë§Œ íˆ¬ìì™€ ê´€ë ¨í•´ì„œëŠ”, ì´ê±´ ì •ë§ ì¤‘ìš”í•œ ì‘ì—…ì…ë‹ˆë‹¤. ì§€ê¸ˆê¹Œì§€ ìš°ë¦¬ê°€ í•´ì˜¨ ëª¨ë“  íˆ¬ìëŠ” CUDAì˜ ì˜í–¥ë ¥ì„ í™•ëŒ€í•˜ê³  ìƒíƒœê³„ë¥¼ ë„“íˆëŠ” ê²ƒê³¼ ê´€ë ¨ì´ ìˆìŠµë‹ˆë‹¤. OpenAIì— ëŒ€í•œ íˆ¬ìë¥¼ ë³´ì‹œë©´, ìš°ë¦¬ëŠ” 2016ë…„ë¶€í„° ê·¸ë“¤ê³¼ ê´€ê³„ë¥¼ ë§ºì–´ì™”ìŠµë‹ˆë‹¤. ì œê°€ ì§ì ‘ ì—­ì‚¬ìƒ ìµœì´ˆì˜ AI ìŠˆí¼ì»´í“¨í„°ë¥¼ OpenAIì— ì „ë‹¬í–ˆì—ˆì£ . ê·¸ë˜ì„œ ê·¸ ì´í›„ë¡œ OpenAIì™€ ê¸´ë°€í•˜ê³  í›Œë¥­í•œ ê´€ê³„ë¥¼ ìœ ì§€í•´ì˜¤ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ë¦¬ê³  OpenAIê°€ í•˜ëŠ” ëª¨ë“  ì‘ì—…ì€ í˜„ì¬ NVIDIAì—ì„œ ì‹¤í–‰ë©ë‹ˆë‹¤. ê·¸ë“¤ì´ ë°°í¬í•˜ëŠ” ëª¨ë“  í´ë¼ìš°ë“œì—ì„œ, í•™ìŠµì´ë“  ì¶”ë¡ ì´ë“  NVIDIAë¥¼ ì‚¬ìš©í•˜ê³  ìˆê³  ìš°ë¦¬ëŠ” ê·¸ë“¤ê³¼ í•¨ê»˜ ì¼í•˜ëŠ” ê²ƒì„ ì •ë§ ì¢‹ì•„í•©ë‹ˆë‹¤. ìš°ë¦¬ê°€ ê·¸ë“¤ê³¼ ë§ºê³  ìˆëŠ” íŒŒíŠ¸ë„ˆì‹­ì€ ê¸°ìˆ ì  ê´€ì ì—ì„œ ë”ìš± ê¹Šì´ í˜‘ë ¥í•  ìˆ˜ ìˆë„ë¡, ê·¸ë¦¬ê³  ê·¸ë“¤ì˜ ê°€ì†í™”ëœ ì„±ì¥ì„ ì§€ì›í•  ìˆ˜ ìˆë„ë¡ í•˜ê¸° ìœ„í•œ ê²ƒì…ë‹ˆë‹¤. ì´ íšŒì‚¬ëŠ” ë¯¿ì„ ìˆ˜ ì—†ì„ ì •ë„ë¡œ ë¹ ë¥´ê²Œ ì„±ì¥í•˜ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ë¦¬ê³  ì–¸ë¡ ì— ë‚˜ì˜¨ ê²ƒë§Œ ë³´ì§€ ë§ˆì‹œê³ , ëª¨ë“  ìƒíƒœê³„ íŒŒíŠ¸ë„ˆë“¤ê³¼ OpenAIì— ì—°ê²°ëœ ëª¨ë“  ê°œë°œìë“¤ì„ ë³´ì„¸ìš”. ê·¸ë“¤ ëª¨ë‘ê°€ ì†Œë¹„ë¥¼ ì´‰ì§„í•˜ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ë¦¬ê³  ìƒì‚°ë˜ëŠ” AIì˜ í’ˆì§ˆì€ 1ë…„ ì „ê³¼ ë¹„êµí•´ ì—„ì²­ë‚˜ê²Œ í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤. ì‘ë‹µì˜ í’ˆì§ˆì´ ì •ë§ ë›°ì–´ë‚©ë‹ˆë‹¤. ì €í¬ëŠ” OpenAIì— íˆ¬ìí•˜ì—¬ ê³µë™ ê°œë°œì„ í†µí•œ ê¸´ë°€í•œ íŒŒíŠ¸ë„ˆì‹­ì„ êµ¬ì¶•í•˜ê³ , ìƒíƒœê³„ë¥¼ í™•ì¥í•˜ë©° ê·¸ë“¤ì˜ ì„±ì¥ì„ ì§€ì›í•˜ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ë¦¬ê³  ë‹¹ì—°íˆ ìš°ë¦¬ íšŒì‚¬ì˜ ì§€ë¶„ì„ í¬ê¸°í•˜ëŠ” ëŒ€ì‹ , ê·¸ë“¤ íšŒì‚¬ì˜ ì§€ë¶„ì„ í™•ë³´í–ˆìŠµë‹ˆë‹¤. ìš°ë¦¬ëŠ” í•œ ì„¸ëŒ€ì— í•œ ë²ˆ ë‚˜ì˜¬ê¹Œ ë§ê¹Œ í•œ ê°€ì¥ ì¤‘ìš”í•œ ê¸°ì—… ì¤‘ í•˜ë‚˜ì— íˆ¬ìí–ˆê³ , ê·¸ ì§€ë¶„ì„ ë³´ìœ í•˜ê³  ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ì´ íˆ¬ìê°€ ì—„ì²­ë‚œ ìˆ˜ìµìœ¼ë¡œ ì´ì–´ì§ˆ ê²ƒìœ¼ë¡œ ì¶©ë¶„íˆ ê¸°ëŒ€í•˜ê³  ìˆìŠµë‹ˆë‹¤. <br><br>Anthropicì˜ ê²½ìš°, ì´ë²ˆì´ Anthropicì´ ì—”ë¹„ë””ì•„ ì•„í‚¤í…ì²˜ë¥¼ ì‚¬ìš©í•˜ëŠ” ì²« ë²ˆì§¸ ì‚¬ë¡€ì…ë‹ˆë‹¤. ì „ì²´ ì‚¬ìš©ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì„¸ê³„ì—ì„œ ë‘ ë²ˆì§¸ë¡œ ì„±ê³µì ì¸ AIì¸ Anthropicì´ ì—”ë¹„ë””ì•„ ì•„í‚¤í…ì²˜ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì€ ì´ë²ˆì´ ì²˜ìŒì…ë‹ˆë‹¤. ê·¸ëŸ°ë° ê¸°ì—… ì‹œì¥ì—ì„œëŠ” ì •ë§ ë†€ë¼ìš´ ì„±ê³¼ë¥¼ ë‚´ê³  ìˆìŠµë‹ˆë‹¤. Claude Codeê°€ ì—„ì²­ë‚œ ì„±ê³¼ë¥¼ ê±°ë‘ê³  ìˆìŠµë‹ˆë‹¤. Claude CodeëŠ” ì „ ì„¸ê³„ ê¸°ì—…ë“¤ì—ì„œ ì •ë§ ë›°ì–´ë‚œ ì„±ê³¼ë¥¼ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤. ì´ì œ ìš°ë¦¬ëŠ” ê·¸ë“¤ê³¼ ê¸´ë°€í•œ íŒŒíŠ¸ë„ˆì‹­ì„ ë§ºê³  Claudeë¥¼ NVIDIA í”Œë«í¼ì— ë„ì…í•  ê¸°íšŒë¥¼ ê°–ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. ê·¸ë ‡ë‹¤ë©´ ì§€ê¸ˆ ìš°ë¦¬ê°€ ê°€ì§„ ê²ƒì€ ë¬´ì—‡ì¼ê¹Œìš”? í•œ ë°œ ë¬¼ëŸ¬ì„œì„œ ë³´ë©´, NVIDIAì˜ ì•„í‚¤í…ì²˜, NVIDIAì˜ í”Œë«í¼ì€ ì „ ì„¸ê³„ì—ì„œ ëª¨ë“  AI ëª¨ë¸ì„ ì‹¤í–‰í•˜ëŠ” ìœ ì¼í•œ í”Œë«í¼ì…ë‹ˆë‹¤. ìš°ë¦¬ëŠ” OpenAIë¥¼ ì‹¤í–‰í•˜ê³ , Anthropicì„ ì‹¤í–‰í•˜ë©°, Elonê³¼ xAIì™€ì˜ ê¸´ë°€í•œ íŒŒíŠ¸ë„ˆì‹­ ë•ë¶„ì— xAIë„ ì‹¤í–‰í•©ë‹ˆë‹¤. ê·¸ ê¸°íšŒë¥¼ ì‚¬ìš°ë””ì•„ë¼ë¹„ì•„ì— ê°€ì ¸ê°€ì„œ HUMAINì´ xAIë¥¼ ìœ„í•œ í˜¸ìŠ¤íŒ… ê¸°íšŒë„ ê°€ì§ˆ ìˆ˜ ìˆê²Œ í–ˆìŠµë‹ˆë‹¤. xAIë¥¼ ì‹¤í–‰í•˜ê³ , Geminië¥¼ ì‹¤í–‰í•˜ë©°, Thinking Machinesë„ ì‹¤í–‰í•©ë‹ˆë‹¤. ë˜ ë­ê°€ ìˆì£ ? ì „ë¶€ ë‹¤ ì‹¤í–‰í•©ë‹ˆë‹¤. ê²Œë‹¤ê°€ ê³¼í•™ ëª¨ë¸, ìƒë¬¼í•™ ëª¨ë¸, DNA ëª¨ë¸, ìœ ì „ì ëª¨ë¸, í™”í•™ ëª¨ë¸ ë“± ì „ ì„¸ê³„ ë‹¤ì–‘í•œ ë¶„ì•¼ì˜ ëª¨ë¸ë“¤ì„ ëª¨ë‘ ì‹¤í–‰í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì„¸ìƒì´ ì‚¬ìš©í•˜ëŠ” ê²ƒì€ ì¸ì§€ AIë§Œì´ ì•„ë‹ˆë¼, AIëŠ” ëª¨ë“  ì‚°ì—…ì— ì˜í–¥ì„ ë¯¸ì¹˜ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ë˜ì„œ ìš°ë¦¬ê°€ í•˜ëŠ” ìƒíƒœê³„ íˆ¬ìë¥¼ í†µí•´ ì„¸ê³„ ìµœê³ ì˜ ê¸°ì—…ë“¤, ê°€ì¥ ë›°ì–´ë‚œ ê¸°ì—…ë“¤ê³¼ ê¸°ìˆ ì ìœ¼ë¡œ ê¸´ë°€í•˜ê²Œ í˜‘ë ¥í•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì„ ê°–ì¶”ê³  ìˆìœ¼ë©°, ìš°ë¦¬ ìƒíƒœê³„ì˜ ë²”ìœ„ë¥¼ í™•ì¥í•˜ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ë¦¬ê³  ìš°ë¦¬ëŠ” ë§¤ìš° ì„±ê³µì ì¸ ê¸°ì—…, ë•Œë¡œëŠ” í•œ ì„¸ëŒ€ì— í•œ ë²ˆ ë‚˜ì˜¬ê¹Œ ë§ê¹Œ í•œ ê¸°ì—…ì— ëŒ€í•œ ì§€ë¶„ê³¼ íˆ¬ìë¥¼ í™•ë³´í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ê²ƒì´ ë°”ë¡œ ìš°ë¦¬ì˜ íˆ¬ì ë…¼ë¦¬ì…ë‹ˆë‹¤.</td></tr>
<tr><td>Operator: The next question comes from Jim Schneider with Goldman Sachs.</td><td>**Operator:** ë‹¤ìŒ ì§ˆë¬¸ì€ ê³¨ë“œë§Œì‚­ìŠ¤ì˜ Jim Schneiderë¡œë¶€í„° ë°›ê² ìŠµë‹ˆë‹¤.</td></tr>
<tr><td>James Schneider: Goldman Sachs Group, Inc., Research Division In the past, you've talked about roughly 40% of your shipments tied to AI inference. I'm wondering, as you look forward into next year, where do you expect that percentage could go in, say, a year's time? And can you maybe address the Rubin CPX product you expect to introduce next year or contextualize that, how big of the overall TAM you expect that can take? And maybe talk about some of the target customer applications for that specific product.</td><td>**James Schneider:** ê³¼ê±°ì— ì¶œí•˜ëŸ‰ì˜ ì•½ 40%ê°€ AI ì¶”ë¡ ì— ì—°ê²°ë˜ì–´ ìˆë‹¤ê³  ë§ì”€í•˜ì…¨ëŠ”ë°ìš”, ë‚´ë…„ì„ ì „ë§í•˜ì‹¤ ë•Œ 1ë…„ í›„ì—ëŠ” ê·¸ ë¹„ìœ¨ì´ ì–´ëŠ ì •ë„ê¹Œì§€ ì˜¬ë¼ê°ˆ ê²ƒìœ¼ë¡œ ì˜ˆìƒí•˜ì‹œëŠ”ì§€ ê¶ê¸ˆí•©ë‹ˆë‹¤. ê·¸ë¦¬ê³  ë‚´ë…„ì— ì¶œì‹œ ì˜ˆì •ì¸ Rubin CPX ì œí’ˆì— ëŒ€í•´ì„œë„ ë§ì”€í•´ ì£¼ì‹¤ ìˆ˜ ìˆì„ê¹Œìš”? ì „ì²´ TAM(Total Addressable Market, ì „ì²´ ì ì¬ ì‹œì¥) ì¤‘ì—ì„œ ì´ ì œí’ˆì´ ì°¨ì§€í•  ìˆ˜ ìˆëŠ” ê·œëª¨ê°€ ì–´ëŠ ì •ë„ì¼ì§€, ê·¸ë¦¬ê³  ì´ íŠ¹ì • ì œí’ˆì˜ ì£¼ìš” íƒ€ê²Ÿ ê³ ê° ì• í”Œë¦¬ì¼€ì´ì…˜ì€ ë¬´ì—‡ì¸ì§€ ì„¤ëª…í•´ ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤.</td></tr>
<tr><td>Jen-Hsun Huang: Co-Founder, CEO, President & Director CPX is designed for long context type of workload generation. And so long context, basically, before you start generating answers, you have to read a lot, basically long context. And it could be a bunch of PDFs. It could be watching a bunch of videos, studying 3D images, so on and so forth. You have to absorb the context. And so CPX is designed for a long context type of workloads. And it's perf-per-dollar excellent, it's perf-per-watt is excellent. And which -- maybe forget the first part of the question...</td><td>**Jen-Hsun Huang:** CPXëŠ” ì¥ë¬¸ë§¥(long context) ìœ í˜•ì˜ ì›Œí¬ë¡œë“œ ìƒì„±ì„ ìœ„í•´ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. ì¥ë¬¸ë§¥ì´ë¼ëŠ” ê²ƒì€ ê¸°ë³¸ì ìœ¼ë¡œ ë‹µë³€ ìƒì„±ì„ ì‹œì‘í•˜ê¸° ì „ì— ë§ì€ ë‚´ìš©ì„ ì½ì–´ì•¼ í•œë‹¤ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤. ì—¬ëŸ¬ PDF íŒŒì¼ì¼ ìˆ˜ë„ ìˆê³ , ì—¬ëŸ¬ ë™ì˜ìƒì„ ì‹œì²­í•˜ê±°ë‚˜ 3D ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ëŠ” ê²ƒì¼ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ë¬¸ë§¥ì„ í¡ìˆ˜í•´ì•¼ í•˜ëŠ” ê±°ì£ . ê·¸ë˜ì„œ CPXëŠ” ì¥ë¬¸ë§¥ ìœ í˜•ì˜ ì›Œí¬ë¡œë“œë¥¼ ìœ„í•´ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¬ëŸ¬ë‹¹ ì„±ëŠ¥(perf-per-dollar)ì´ ë›°ì–´ë‚˜ê³ , ì™€íŠ¸ë‹¹ ì„±ëŠ¥(perf-per-watt)ë„ ìš°ìˆ˜í•©ë‹ˆë‹¤. ê·¸ëŸ°ë°... ì§ˆë¬¸ì˜ ì²« ë²ˆì§¸ ë¶€ë¶„ì´ ë­ì˜€ì£ ...</td></tr>
<tr><td>Colette Kress: Executive VP & CFO</td><td>**Colette Kress:** <thinking><br>The user has only provided a title "Executive VP & CFO" without any actual content to translate. According to the instructions, I should only translate spoken content from earnings call Q&A sessions, not titles or speaker names.<br><br>Since there's no actual content to translate, I should ask for the actual content that needs to be translated.<br></thinking><br><br>ë²ˆì—­í•  ì‹¤ì œ ë‚´ìš©ì´ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. <br><br>ì¬ë¬´ ë‹´ë‹¹ ë¶€ì‚¬ì¥ ê²¸ CFOì˜ ë‹µë³€ ë‚´ìš©ì„ ì œê³µí•´ ì£¼ì‹œë©´ ë²ˆì—­í•´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤.</td></tr>
<tr><td>Jen-Hsun Huang: Co-Founder, CEO, President & Director Oh inferencing, yes, there are 3 scaling laws that are scaling at the same time. The first scaling law called pretraining continues to be very effective. And the second is post-training. Post-training basically has found incredible algorithms for improving an AI's ability to break a problem down and solve a problem step by step. And post-training is scaling exponentially, basically, the more compute you apply to a model, the smarter it is, the more intelligent it is. And then the third is inference. Inference because of chain of thought, because of reasoning capabilities, AIs are essentially reading, thinking before it answers. And the amount of computation necessary as a result of those 3 things has gone completely exponential. I think that it's hard to know exactly what the percentage of it will be at any given point in time and who. But of course, our hope is that inference is a very large part of the market because if inference is large, then what it suggests is that people are using it in more applications and they're using it more frequently. And that's -- we should all hope for inference to be very large. And this is where Grace Blackwell is just an order of magnitude better more advanced than anything in the world. The second best platform is H200, and it's very clear now that GB300, GB200and GB300 because of NVLink 72, the scale-up network that we have achieved. And you saw and Colette talked about in the semi analysis benchmark. It's the largest single inference benchmark ever done and GB200, NVLink 72 is 10x, 10 to 15x higher performance. And so that's a big step up. It's going to take a long time before somebody is able to take that on. And our leadership there is surely multiyear. And so I think I'm hoping that inference becomes a very big deal. Our leadership in inference is extraordinary.</td><td>**Jen-Hsun Huang:** ì¶”ë¡ ì— ê´€í•´ì„œ ë§ì”€ë“œë¦¬ë©´, í˜„ì¬ 3ê°€ì§€ ìŠ¤ì¼€ì¼ë§ ë²•ì¹™ì´ ë™ì‹œì— ì‘ë™í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì²« ë²ˆì§¸ëŠ” ì‚¬ì „í•™ìŠµ(pretraining)ì´ë¼ê³  ë¶ˆë¦¬ëŠ” ê²ƒìœ¼ë¡œ, ì—¬ì „íˆ ë§¤ìš° íš¨ê³¼ì ì…ë‹ˆë‹¤. ë‘ ë²ˆì§¸ëŠ” ì‚¬í›„í•™ìŠµ(post-training)ì…ë‹ˆë‹¤. ì‚¬í›„í•™ìŠµì€ ê¸°ë³¸ì ìœ¼ë¡œ AIê°€ ë¬¸ì œë¥¼ ì„¸ë¶„í™”í•˜ê³  ë‹¨ê³„ë³„ë¡œ í•´ê²°í•˜ëŠ” ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ë†€ë¼ìš´ ì•Œê³ ë¦¬ì¦˜ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ì‚¬í›„í•™ìŠµì€ ê¸°í•˜ê¸‰ìˆ˜ì ìœ¼ë¡œ í™•ì¥ë˜ê³  ìˆëŠ”ë°, ëª¨ë¸ì— ë” ë§ì€ ì»´í“¨íŒ…ì„ ì ìš©í• ìˆ˜ë¡ ë” ë˜‘ë˜‘í•´ì§€ê³  ë” ì§€ëŠ¥ì ì´ ë©ë‹ˆë‹¤. ê·¸ë¦¬ê³  ì„¸ ë²ˆì§¸ëŠ” ì¶”ë¡ (inference)ì…ë‹ˆë‹¤. ì¶”ë¡ ì€ ì‚¬ê³ ì˜ ì—°ì‡„(chain of thought)ì™€ ì¶”ë¡  ëŠ¥ë ¥ ë•ë¶„ì— AIê°€ ë³¸ì§ˆì ìœ¼ë¡œ ë‹µë³€í•˜ê¸° ì „ì— ì½ê³  ìƒê°í•˜ëŠ” ê³¼ì •ì„ ê±°ì¹©ë‹ˆë‹¤. ì´ ì„¸ ê°€ì§€ ìš”ì†Œì˜ ê²°ê³¼ë¡œ í•„ìš”í•œ ì—°ì‚°ëŸ‰ì´ ì™„ì „íˆ ê¸°í•˜ê¸‰ìˆ˜ì ìœ¼ë¡œ ì¦ê°€í–ˆìŠµë‹ˆë‹¤. ì •í™•íˆ ì–´ëŠ ì‹œì ì— ì–´ë–¤ ë¹„ìœ¨ì´ ë ì§€ ì•Œê¸°ëŠ” ì–´ë µìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ë¬¼ë¡  ìš°ë¦¬ê°€ ë°”ë¼ëŠ” ê²ƒì€ ì¶”ë¡ (inference)ì´ ì‹œì¥ì—ì„œ ë§¤ìš° í° ë¶€ë¶„ì„ ì°¨ì§€í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì¶”ë¡ ì´ í¬ë‹¤ëŠ” ê²ƒì€ ì‚¬ëŒë“¤ì´ ë” ë§ì€ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ë” ìì£¼ ì‚¬ìš©í•˜ê³  ìˆë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ê·¸ë˜ì„œ ìš°ë¦¬ ëª¨ë‘ ì¶”ë¡ ì´ ë§¤ìš° ì»¤ì§€ê¸°ë¥¼ ë°”ë¼ì•¼ í•©ë‹ˆë‹¤. ê·¸ë¦¬ê³  ì´ ë¶€ë¶„ì—ì„œ Grace Blackwellì€ ì„¸ê³„ ì–´ë–¤ ê²ƒë³´ë‹¤ë„ í•œ ë‹¨ê³„ ë” ë›°ì–´ë‚˜ê³  ì§„ë³´ëœ ì œí’ˆì…ë‹ˆë‹¤. ë‘ ë²ˆì§¸ë¡œ ì¢‹ì€ í”Œë«í¼ì€ H200ì´ê³ , ì´ì œ GB300, GB200 ê·¸ë¦¬ê³  GB300ì´ NVLink 72 ë•ë¶„ì— ëª…í™•í•´ì¡ŒìŠµë‹ˆë‹¤. ìš°ë¦¬ê°€ ë‹¬ì„±í•œ ìŠ¤ì¼€ì¼ì—… ë„¤íŠ¸ì›Œí¬ ë§ì´ì£ . Coletteê°€ ì„¸ë¯¸ ì• ë„ë¦¬ì‹œìŠ¤ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ë§ì”€ë“œë¦° ë‚´ìš©ì„ ë³´ì…¨ì„ ê²ë‹ˆë‹¤. ì§€ê¸ˆê¹Œì§€ ì§„í–‰ëœ ì¶”ë¡  ë²¤ì¹˜ë§ˆí¬ ì¤‘ ê°€ì¥ í° ê·œëª¨ì˜€ê³ , GB200 NVLink 72ëŠ” 10ë°°ì—ì„œ 15ë°° ë” ë†’ì€ ì„±ëŠ¥ì„ ë³´ì—¬ì¤¬ìŠµë‹ˆë‹¤. ì •ë§ í° ë„ì•½ì´ì£ . ë‹¤ë¥¸ ì—…ì²´ë“¤ì´ ì´ ìˆ˜ì¤€ì„ ë”°ë¼ì¡ìœ¼ë ¤ë©´ ìƒë‹¹íˆ ì˜¤ëœ ì‹œê°„ì´ ê±¸ë¦´ ê²ë‹ˆë‹¤. ì´ ë¶„ì•¼ì—ì„œ ìš°ë¦¬ì˜ ë¦¬ë”ì‹­ì€ í™•ì‹¤íˆ ìˆ˜ë…„ê°„ ì§€ì†ë  ê²ƒìœ¼ë¡œ ë´…ë‹ˆë‹¤. ê·¸ë˜ì„œ ì¶”ë¡ ì´ ì •ë§ í° ì‹œì¥ì´ ë˜ê¸°ë¥¼ ê¸°ëŒ€í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì¶”ë¡  ë¶„ì•¼ì—ì„œ ìš°ë¦¬ì˜ ë¦¬ë”ì‹­ì€ ì •ë§ íƒì›”í•©ë‹ˆë‹¤.</td></tr>
<tr><td>Operator: The next question comes from Timothy Arcuri with UBS.</td><td>**Operator:** ë‹¤ìŒ ì§ˆë¬¸ì€ UBSì˜ Timothy Arcurië‹˜ê»˜ì„œ ì£¼ì‹œê² ìŠµë‹ˆë‹¤.</td></tr>
<tr><td>Timothy Arcuri: UBS Investment Bank, Research Division Jensen, many of your customers are pursuing behind-the-meter power, but like what's the single biggest bottleneck that worries you that could constrain your growth? Is it power? Or maybe it's financing or maybe it's something else like memory or even foundry?</td><td>**Timothy Arcuri:** UBS ì¸ë² ìŠ¤íŠ¸ë¨¼íŠ¸ ë±…í¬ ë¦¬ì„œì¹˜ ë¶€ë¬¸ì—ì„œ ì§ˆë¬¸ ì£¼ì‹  ë‚´ìš©ì¸ë°ìš”, ë§ì€ ê³ ê°ì‚¬ë“¤ì´ ìê°€ë°œì „(behind-the-meter) ì „ë ¥ì„ ì¶”ì§„í•˜ê³  ìˆìŠµë‹ˆë‹¤ë§Œ, ê·€ì‚¬ì˜ ì„±ì¥ì„ ì œì•½í•  ìˆ˜ ìˆëŠ” ê°€ì¥ í° ë³‘ëª© í˜„ìƒì€ ë¬´ì—‡ì¸ê°€ìš”? ì „ë ¥ ê³µê¸‰ì¸ê°€ìš”? ì•„ë‹ˆë©´ ìê¸ˆ ì¡°ë‹¬ì¼ê¹Œìš”? ì•„ë‹ˆë©´ ë©”ëª¨ë¦¬ë‚˜ íŒŒìš´ë“œë¦¬ ê°™ì€ ë‹¤ë¥¸ ìš”ì¸ì¼ê¹Œìš”?</td></tr>
<tr><td>Jen-Hsun Huang: Co-Founder, CEO, President & Director Well, these are all issues and they're all constraints. And the reason for that, when you're growing at the rate that we are and the scale that we are, how could anything be easy? What NVIDIA is doing obviously has never been done before. And we've created a whole new industry. Now on the one hand, we are transitioning computing from general purpose and classical or traditional computing to accelerated computing and AI. That's on the one hand. On the other hand, we created a whole new industry called AI factories. The idea that in order for software to run, you need these factories to generate it, generate every single token instead of retrieving information that was pre-created. And so -- so I think this whole transition requires extraordinary scale. And all the way from the supply chain. Of course, the supply chain, we have much better visibility and control over because obviously, we're incredibly good at managing our supply chain. We have great partners that we've worked with for 33 years. And so the supply chain part of it, we're quite confident. Now looking down our supply chain, we've now established partnerships with so many players in land and power and shell. And of course, financing. These things -- none of these things are easy, but they're all attractable and they're all solvable things. And the most important thing that we have to do is do a good job planning we plan up the supply chain, down the supply chain. We have established a whole lot of partners. And so we have a lot of routes to market. And very importantly, our architecture has to deliver the best value to the customers that we have. And so at this point, I'm very confident that NVIDIA's architecture is the best performance per TCO, it is the best performance per watt. And therefore, for any amount of energy that is delivered, our architecture will drive the most revenues. And I think the increasing rate of our success, I think that we're more successful this year at this point than we were last year at this point. The number of customers coming to us and the number of platforms coming to us after they've explored others, is increasing, not decreasing. And so I think the -- I think all of that is just -- all the things that I've been telling you over the years are really coming -- are coming through or becoming evident.</td><td>**Jen-Hsun Huang:** ìš°ë¦¬ê°€ ì„±ì¥í•˜ëŠ” ì†ë„ì™€ ê·œëª¨ë¥¼ ê³ ë ¤í•˜ë©´, ì´ ëª¨ë“  ê²ƒë“¤ì´ ì´ìŠˆì´ì ì œì•½ì‚¬í•­ì…ë‹ˆë‹¤. ì–´ë–»ê²Œ ì‰¬ìš¸ ìˆ˜ê°€ ìˆê² ìŠµë‹ˆê¹Œ? ì—”ë¹„ë””ì•„ê°€ í•˜ê³  ìˆëŠ” ì¼ì€ ë¶„ëª… ì „ë¡€ê°€ ì—†ëŠ” ê²ƒì…ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì™„ì „íˆ ìƒˆë¡œìš´ ì‚°ì—…ì„ ë§Œë“¤ì–´ëƒˆìŠµë‹ˆë‹¤. í•œí¸ìœ¼ë¡œëŠ”, ìš°ë¦¬ê°€ ë²”ìš© ì»´í“¨íŒ…ê³¼ ê¸°ì¡´ì˜ ì „í†µì ì¸ ì»´í“¨íŒ…ì—ì„œ ê°€ì† ì»´í“¨íŒ…(accelerated computing)ê³¼ AIë¡œ ì „í™˜ì„ ì´ëŒê³  ìˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í•œí¸ìœ¼ë¡œëŠ”, AI íŒ©í† ë¦¬ë¼ëŠ” ì™„ì „íˆ ìƒˆë¡œìš´ ì‚°ì—…ì„ ì°½ì¶œí–ˆìŠµë‹ˆë‹¤. ì†Œí”„íŠ¸ì›¨ì–´ë¥¼ ì‹¤í–‰í•˜ê¸° ìœ„í•´ì„œëŠ” ë¯¸ë¦¬ ë§Œë“¤ì–´ì§„ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ëª¨ë“  í† í°ì„ ìƒì„±í•´ë‚´ëŠ” ì´ëŸ° íŒ©í† ë¦¬ë“¤ì´ í•„ìš”í•˜ë‹¤ëŠ” ê°œë…ì…ë‹ˆë‹¤. ê·¸ë˜ì„œ ì´ëŸ¬í•œ ì „í™˜ ì „ì²´ê°€ ì—„ì²­ë‚œ ê·œëª¨ë¥¼ í•„ìš”ë¡œ í•œë‹¤ê³  ìƒê°í•©ë‹ˆë‹¤. ê³µê¸‰ë§ ì „ë°˜ì— ê±¸ì³ì„œ ë§ì”€ë“œë¦¬ìë©´, ê³µê¸‰ë§ì˜ ê²½ìš° ìš°ë¦¬ê°€ í›¨ì”¬ ë” ì˜ íŒŒì•…í•˜ê³  í†µì œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¹ì—°íˆ ìš°ë¦¬ëŠ” ê³µê¸‰ë§ ê´€ë¦¬ì— ìˆì–´ì„œ íƒì›”í•œ ì—­ëŸ‰ì„ ë³´ìœ í•˜ê³  ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. 33ë…„ê°„ í•¨ê»˜ í•´ì˜¨ í›Œë¥­í•œ íŒŒíŠ¸ë„ˆë“¤ì´ ìˆê³ ìš”. ê·¸ë˜ì„œ ê³µê¸‰ë§ ë¶€ë¶„ì— ëŒ€í•´ì„œëŠ” ìƒë‹¹íˆ ìì‹  ìˆìŠµë‹ˆë‹¤. ì´ì œ ê³µê¸‰ë§ í•˜ë‹¨ì„ ë³´ë©´, í† ì§€, ì „ë ¥, ê±´ë¬¼ ë¶„ì•¼ì˜ ìˆ˜ë§ì€ ì—…ì²´ë“¤ê³¼ íŒŒíŠ¸ë„ˆì‹­ì„ êµ¬ì¶•í–ˆìŠµë‹ˆë‹¤. ë¬¼ë¡  ê¸ˆìœµ ë¶€ë¶„ë„ ë§ˆì°¬ê°€ì§€ê³ ìš”. ì´ëŸ° ê²ƒë“¤ì´ ì‰¬ìš´ ì¼ì€ ì•„ë‹ˆì§€ë§Œ, ëª¨ë‘ ë‹¤ë£° ìˆ˜ ìˆê³  í•´ê²° ê°€ëŠ¥í•œ ë¬¸ì œë“¤ì…ë‹ˆë‹¤. ìš°ë¦¬ê°€ í•´ì•¼ í•  ê°€ì¥ ì¤‘ìš”í•œ ì¼ì€ ê³„íšì„ ì˜ ì„¸ìš°ëŠ” ê²ƒì…ë‹ˆë‹¤. ê³µê¸‰ë§ ìƒí•˜ë‹¨ ì „ì²´ì— ê±¸ì³ ê³„íšì„ ìˆ˜ë¦½í•˜ê³  ìˆê³ , ìˆ˜ë§ì€ íŒŒíŠ¸ë„ˆë“¤ì„ í™•ë³´í–ˆìŠµë‹ˆë‹¤. ê·¸ë˜ì„œ ì‹œì¥ ì§„ì¶œ ê²½ë¡œê°€ ë‹¤ì–‘í•©ë‹ˆë‹¤. ê·¸ë¦¬ê³  ë§¤ìš° ì¤‘ìš”í•œ ì ì€, ìš°ë¦¬ì˜ ì•„í‚¤í…ì²˜ê°€ ê³ ê°ë“¤ì—ê²Œ ìµœê³ ì˜ ê°€ì¹˜ë¥¼ ì œê³µí•´ì•¼ í•œë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤. í˜„ì‹œì ì—ì„œ ì €ëŠ” NVIDIAì˜ ì•„í‚¤í…ì²˜ê°€ TCO(ì´ì†Œìœ ë¹„ìš©) ëŒ€ë¹„ ìµœê³ ì˜ ì„±ëŠ¥ì„ ì œê³µí•˜ê³ , ì™€íŠ¸ë‹¹ ìµœê³ ì˜ ì„±ëŠ¥ì„ ì œê³µí•œë‹¤ê³  í™•ì‹ í•©ë‹ˆë‹¤. ë”°ë¼ì„œ ì–´ë–¤ ì–‘ì˜ ì—ë„ˆì§€ê°€ ê³µê¸‰ë˜ë“ , ìš°ë¦¬ ì•„í‚¤í…ì²˜ê°€ ê°€ì¥ ë§ì€ ìˆ˜ìµì„ ì°½ì¶œí•  ê²ƒì…ë‹ˆë‹¤. ê·¸ë¦¬ê³  ìš°ë¦¬ì˜ ì„±ê³µë¥ ì´ ì¦ê°€í•˜ê³  ìˆë‹¤ê³  ìƒê°í•©ë‹ˆë‹¤. ì˜¬í•´ í˜„ì‹œì ì—ì„œ ì‘ë…„ ê°™ì€ ì‹œê¸°ë³´ë‹¤ ë” ì„±ê³µì ì´ë¼ê³  ë´…ë‹ˆë‹¤. ë‹¤ë¥¸ ëŒ€ì•ˆë“¤ì„ ê²€í† í•œ í›„ ìš°ë¦¬ì—ê²Œ ì˜¤ëŠ” ê³ ê° ìˆ˜ì™€ í”Œë«í¼ ìˆ˜ê°€ ê°ì†Œí•˜ëŠ” ê²Œ ì•„ë‹ˆë¼ ì¦ê°€í•˜ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ë˜ì„œ ì œê°€ ìˆ˜ë…„ê°„ ë§ì”€ë“œë ¸ë˜ ëª¨ë“  ê²ƒë“¤ì´ ì‹¤ì œë¡œ ì‹¤í˜„ë˜ê³  ìˆê³ , ëª…í™•í•´ì§€ê³  ìˆë‹¤ê³  ìƒê°í•©ë‹ˆë‹¤.</td></tr>
<tr><td>Operator: The next question comes from Stacy Rasgon with Bernstein Research.</td><td>**Operator:** ë‹¤ìŒ ì§ˆë¬¸ì€ ë²ˆìŠ¤íƒ€ì¸ ë¦¬ì„œì¹˜ì˜ ìŠ¤í…Œì´ì‹œ ë¼ìŠ¤ê³¤ë‹˜ê»˜ì„œ ì£¼ì‹œê² ìŠµë‹ˆë‹¤.</td></tr>
<tr><td>Stacy Rasgon: Sanford C. Bernstein & Co., LLC., Research Division Colette, I have some questions on margins. You said for next year, you're working to hold them in the mid-70s. So I guess, first of all, what are the biggest cost increases? Is it just memory or is it something else? What are you doing to work toward that? Is it -- how much is like cost optimizations versus prebuys versus pricing? And then also, how should we think about OpEx growth next year, given the revenues seem likely to grow materially from where we're running right now?</td><td>**Stacy Rasgon:** ì½œë ˆíŠ¸, ë§ˆì§„ì— ëŒ€í•´ ëª‡ ê°€ì§€ ì§ˆë¬¸ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ë‚´ë…„ì— ë§ˆì§„ì„ 70%ëŒ€ ì¤‘ë°˜ìœ¼ë¡œ ìœ ì§€í•˜ê¸° ìœ„í•´ ë…¸ë ¥í•˜ê³  ê³„ì‹ ë‹¤ê³  ë§ì”€í•˜ì…¨ëŠ”ë°ìš”. ìš°ì„ , ê°€ì¥ í° ë¹„ìš© ì¦ê°€ ìš”ì¸ì´ ë¬´ì—‡ì¸ê°€ìš”? ë©”ëª¨ë¦¬ì¸ê°€ìš”, ì•„ë‹ˆë©´ ë‹¤ë¥¸ ê²ƒì¸ê°€ìš”? ì´ë¥¼ ìœ„í•´ ì–´ë–¤ ë…¸ë ¥ì„ í•˜ê³  ê³„ì‹ ê°€ìš”? ì›ê°€ ìµœì í™”, ì‚¬ì „ êµ¬ë§¤, ê°€ê²© ì±…ì • ì¤‘ ì–´ëŠ ê²ƒì´ ì–¼ë§ˆë‚˜ ë¹„ì¤‘ì„ ì°¨ì§€í•˜ë‚˜ìš”? ê·¸ë¦¬ê³  í˜„ì¬ ìˆ˜ì¤€ ëŒ€ë¹„ ë§¤ì¶œì´ ìƒë‹¹íˆ ì¦ê°€í•  ê²ƒìœ¼ë¡œ ë³´ì´ëŠ”ë°, ë‚´ë…„ ì˜ì—…ë¹„ìš©(OpEx) ì¦ê°€ëŠ” ì–´ë–»ê²Œ ì˜ˆìƒí•´ì•¼ í• ê¹Œìš”?</td></tr>
<tr><td>Colette Kress: Executive VP & CFO Thanks, Stacy. Let me see if I can start with remembering where we were with the current fiscal year that we're in. Remember, earlier this year, we indicated that through cost improvements and mix that we would exit the year in our gross margins in the mid 70s. We've achieved that and getting ready to also execute that in Q4. So now it's time for us to communicate where are we working right now in terms of next year. Next year, there are input prices that are well known in the industries that we need to work through. And our systems are by no means very easy to work with. There are tremendous amount of components in many different parts of it as we think about that. So we're taking all of that into account, but we do believe as we look at working again on cost improvement, cycle time and mix that we will work to try and hold at our gross margins in the mid-70s. So that's our overall plan for gross margin. Your second question is around OpEx. And right now, our goal in terms of OpEx is to really make sure that we are innovating with our engineering teams with all of our business teams to create more and more systems for this market. As you know, right now, we have a new architecture coming out. And that means they are quite busy in order to meet that goal. And so we're going to continue to see our investments on innovating more and more both the software, both our systems and our hard work to do so. I'll leave it -- turn it to Jensen if he wants to add any couple of more comments.</td><td>**Colette Kress:** ê°ì‚¬í•©ë‹ˆë‹¤, Stacy. í˜„ì¬ íšŒê³„ì—°ë„ ìƒí™©ë¶€í„° ë§ì”€ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ì˜¬í•´ ì´ˆ ì €í¬ê°€ ë¹„ìš© ê°œì„ ê³¼ ì œí’ˆ ë¯¹ìŠ¤ë¥¼ í†µí•´ ì—°ë§ê¹Œì§€ ë§¤ì¶œì´ì´ìµë¥ (gross margin)ì„ 70% ì¤‘ë°˜ëŒ€ë¡œ ëŒì–´ì˜¬ë¦¬ê² ë‹¤ê³  ë§ì”€ë“œë ¸ë˜ ê²ƒ ê¸°ì–µí•˜ì‹¤ ê²ë‹ˆë‹¤. ì €í¬ëŠ” ì´ë¥¼ ë‹¬ì„±í–ˆê³ , 4ë¶„ê¸°ì—ë„ ì´ë¥¼ ì‹¤í–‰í•  ì¤€ë¹„ê°€ ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì´ì œëŠ” ë‚´ë…„ ê³„íšì— ëŒ€í•´ ë§ì”€ë“œë¦´ ì‹œì ì…ë‹ˆë‹¤. ë‚´ë…„ì—ëŠ” ì—…ê³„ì— ì˜ ì•Œë ¤ì§„ íˆ¬ì… ì›ê°€ ìƒìŠ¹ ìš”ì¸ë“¤ì´ ìˆê³ , ì €í¬ê°€ ì´ë¥¼ í•´ê²°í•´ ë‚˜ê°€ì•¼ í•©ë‹ˆë‹¤. ì €í¬ ì‹œìŠ¤í…œì€ ê²°ì½” ë‹¤ë£¨ê¸° ì‰¬ìš´ ê²ƒì´ ì•„ë‹™ë‹ˆë‹¤. ì—¬ëŸ¬ ë¶€ë¬¸ì— ê±¸ì³ ì—„ì²­ë‚˜ê²Œ ë§ì€ ë¶€í’ˆë“¤ì´ ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ì´ ëª¨ë“  ìš”ì†Œë“¤ì„ ê³ ë ¤í•˜ê³  ìˆìœ¼ë©°, ì›ê°€ ê°œì„ , ì‚¬ì´í´ íƒ€ì„, ì œí’ˆ ë¯¹ìŠ¤ ì‘ì—…ì„ í†µí•´ ë§¤ì¶œì´ì´ìµë¥ ì„ 70% ì¤‘ë°˜ëŒ€ì—ì„œ ìœ ì§€í•˜ê¸° ìœ„í•´ ë…¸ë ¥í•  ê²ƒì…ë‹ˆë‹¤. ì´ê²ƒì´ ë§¤ì¶œì´ì´ìµë¥ ì— ëŒ€í•œ ì „ë°˜ì ì¸ ê³„íšì…ë‹ˆë‹¤.<br><br>ë‘ ë²ˆì§¸ ì§ˆë¬¸ì€ ì˜ì—…ë¹„ìš©(OpEx)ì— ê´€í•œ ê²ƒì…ë‹ˆë‹¤. í˜„ì¬ ì˜ì—…ë¹„ìš© ì¸¡ë©´ì—ì„œ ìš°ë¦¬ì˜ ëª©í‘œëŠ” ì—”ì§€ë‹ˆì–´ë§ íŒ€ê³¼ ëª¨ë“  ì‚¬ì—…ë¶€ê°€ ì´ ì‹œì¥ì„ ìœ„í•œ ë” ë§ì€ ì‹œìŠ¤í…œì„ ê°œë°œí•  ìˆ˜ ìˆë„ë¡ í˜ì‹ ì„ ì§€ì†í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì•„ì‹œë‹¤ì‹œí”¼ í˜„ì¬ ìƒˆë¡œìš´ ì•„í‚¤í…ì²˜ê°€ ì¶œì‹œë˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ëŠ” í•´ë‹¹ ëª©í‘œë¥¼ ë‹¬ì„±í•˜ê¸° ìœ„í•´ íŒ€ë“¤ì´ ìƒë‹¹íˆ ë°”ì˜ê²Œ ì›€ì§ì´ê³  ìˆë‹¤ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤. ë”°ë¼ì„œ ì†Œí”„íŠ¸ì›¨ì–´, ì‹œìŠ¤í…œ, ê·¸ë¦¬ê³  ì´ë¥¼ ìœ„í•œ í•µì‹¬ ì‘ì—… ëª¨ë‘ì—ì„œ ì§€ì†ì ìœ¼ë¡œ í˜ì‹ ì— íˆ¬ìí•  ê²ƒì…ë‹ˆë‹¤. ì  ìŠ¨ì´ ëª‡ ê°€ì§€ ì½”ë©˜íŠ¸ë¥¼ ë” ì¶”ê°€í•˜ê³  ì‹¶ë‹¤ë©´ ë„˜ê¸°ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.</td></tr>
<tr><td>Jen-Hsun Huang: Co-Founder, CEO, President & Director Yes, that's spot on. I think the only thing that I would add is remember that we plan, we forecast, we plan and we negotiate with our supply chain well in advance. Our supply chain have known for quite a long time, our requirements. And they've known for quite a long time our demand, and we've been working with them and negotiating with them for quite a long time. And so I think the recent surge obviously quite significant. But remember, our supply chain has been working with us for a very long time. So in many cases, we've secured a lot of supply for ourselves because, obviously, they're working with the largest company in the world in doing so. And we've also been working closely with them on the financial aspects of it and securing forecasts and plans and so on and so forth. So I think all of that has worked out well for us.</td><td>**Jen-Hsun Huang:** ë„¤, ì •í™•í•©ë‹ˆë‹¤. í•œ ê°€ì§€ë§Œ ë§ë¶™ì´ìë©´, ì €í¬ëŠ” ê³µê¸‰ë§ê³¼ ìƒë‹¹íˆ ë¯¸ë¦¬ ê³„íší•˜ê³ , ì˜ˆì¸¡í•˜ê³ , í˜‘ìƒí•œë‹¤ëŠ” ì ì„ ê¸°ì–µí•˜ì…”ì•¼ í•©ë‹ˆë‹¤. ì €í¬ ê³µê¸‰ì—…ì²´ë“¤ì€ ì´ë¯¸ ì˜¤ë˜ì „ë¶€í„° ì €í¬ ìš”êµ¬ì‚¬í•­ì„ ì•Œê³  ìˆì—ˆìŠµë‹ˆë‹¤. ê·¸ë¦¬ê³  ì €í¬ ìˆ˜ìš”ë„ ì˜¤ë˜ì „ë¶€í„° ì•Œê³  ìˆì—ˆê³ , ì €í¬ëŠ” ê·¸ë“¤ê³¼ ì˜¤ë«ë™ì•ˆ í˜‘ë ¥í•˜ê³  í˜‘ìƒí•´ì™”ìŠµë‹ˆë‹¤. ê·¸ë˜ì„œ ìµœê·¼ì˜ ìˆ˜ìš” ê¸‰ì¦ì´ ë¶„ëª… ìƒë‹¹íˆ í° ê²ƒì€ ë§ì§€ë§Œ, ì €í¬ ê³µê¸‰ë§ì´ ì €í¬ì™€ ì•„ì£¼ ì˜¤ë«ë™ì•ˆ í•¨ê»˜ ì¼í•´ì™”ë‹¤ëŠ” ì ì„ ê¸°ì–µí•˜ì…”ì•¼ í•©ë‹ˆë‹¤. ë”°ë¼ì„œ ë§ì€ ê²½ìš°ì— ì €í¬ëŠ” ì´ë¯¸ ìƒë‹¹í•œ ë¬¼ëŸ‰ì„ í™•ë³´í•´ë†“ì•˜ìŠµë‹ˆë‹¤. ì™œëƒí•˜ë©´ ê³µê¸‰ì—…ì²´ë“¤ì´ ì„¸ê³„ ìµœëŒ€ ê¸°ì—…ê³¼ í˜‘ë ¥í•˜ê³  ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ë˜í•œ ì¬ë¬´ì ì¸ ì¸¡ë©´ì—ì„œë„ ê¸´ë°€í•˜ê²Œ í˜‘ë ¥í•˜ë©´ì„œ ì˜ˆì¸¡ì¹˜ì™€ ê³„íš ë“±ì„ í™•ë³´í•˜ëŠ” ì‘ì—…ì„ ì§„í–‰í•´ì™”ìŠµë‹ˆë‹¤. ê·¸ë˜ì„œ ì´ ëª¨ë“  ê²ƒë“¤ì´ ìš°ë¦¬ì—ê²Œ ì˜ í’€ë ¸ë‹¤ê³  ìƒê°í•©ë‹ˆë‹¤.</td></tr>
<tr><td>Operator: Your final question comes from the line of Aaron Rakers with Wells Fargo.</td><td>**Operator:** ë§ˆì§€ë§‰ ì§ˆë¬¸ì€ Wells Fargoì˜ Aaron Rakersë‹˜ê»˜ì„œ ì£¼ì‹œê² ìŠµë‹ˆë‹¤.</td></tr>
<tr><td>Aaron Rakers: Wells Fargo Securities, LLC, Research Division Jensen, the question for you. As you think about the Anthropic deal that was announced and just the overall breadth of your customers, I'm curious if your thoughts around the role that AI ASICs or dedicated XPUs play in these architecture build-outs has changed at all? Have you seen, I think you've been fairly adamant in the past that some of these programs never really see deployments. But I'm curious if we're at a point where maybe that's even changed more in favor of just GPU architecture.</td><td>**Aaron Rakers:** Anthropic ê±°ë˜ ë°œí‘œì™€ ì „ë°˜ì ì¸ ê³ ê°ì¸µì„ ê³ ë ¤í•  ë•Œ, AI ASICì´ë‚˜ ì „ìš© XPUê°€ ì´ëŸ¬í•œ ì•„í‚¤í…ì²˜ êµ¬ì¶•ì—ì„œ ë‹´ë‹¹í•˜ëŠ” ì—­í• ì— ëŒ€í•œ ìƒê°ì´ ë°”ë€Œì—ˆëŠ”ì§€ ê¶ê¸ˆí•©ë‹ˆë‹¤. ê³¼ê±°ì— ì´ëŸ¬í•œ í”„ë¡œê·¸ë¨ë“¤ ì¤‘ ì¼ë¶€ëŠ” ì‹¤ì œ ë°°í¬ê¹Œì§€ ì´ë¥´ì§€ ëª»í•œë‹¤ê³  ê½¤ í™•ê³ í•˜ê²Œ ë§ì”€í•˜ì…¨ë˜ ê²ƒìœ¼ë¡œ ì•„ëŠ”ë°, ì§€ê¸ˆì€ ì˜¤íˆë ¤ GPU ì•„í‚¤í…ì²˜ ìª½ìœ¼ë¡œ ë” ê¸°ìš¸ì–´ì§„ ì‹œì ì´ ì•„ë‹Œê°€ ì‹¶ìŠµë‹ˆë‹¤ë§Œ ì–´ë–»ê²Œ ë³´ì‹œëŠ”ì§€ìš”?</td></tr>
<tr><td>Jen-Hsun Huang: Co-Founder, CEO, President & Director Yes. Thank you very much, and I really appreciate the question. So first of all, you're not competing against teams -- excuse me, against a company, you're competing against teams. And the -- there just aren't that many teams in the world who are built -- who are extraordinary at building these incredibly complicated things. Back in the Hopper day and the Ampere days, we would build one GPU. That's the definition of an accelerated AI system. But today, we've got to build entire racks entire -- 3 different types of switches, scale up, scale out and scale across switch. And it takes a lot more than 1 chip to build a compute node anymore. Everything about that computing system because AI needs to have memory, AI didn't use to have memory at all. Now it has to remember things, the amount of memory and context it has is gigantic. The memory architecture implication is incredible. The diversity of models from mixture of experts to dense models, to diffusion models that are aggressive not to mention biological models that are based on the laws of physics, the list of different types of models have exploded in the last several years. And so the challenge is the complexity of the problem is much higher. The diversity of AI models is incredibly, incredibly large. And so this is where, if I will say, there are 5 things that makes us special, if you will. The first thing I would say that makes us special is that we accelerate every phase of that transition. That's the first space. CUDA allows us to have CUDA-X for transitioning from general purpose to accelerated computing. We are incredibly good at generative AI. We're incredibly good at agentic AI. So every single phase of that -- every single layer of the transition, we are excellent at. You can invest in 1 architecture, use it across the board. You can use 1 architecture and not worry about the changes in the workload across those 3 phases. That's number one. Number two, we're excellent at every phase of AI. Everybody's always known that we're incredibly good at pretraining. We're obviously very good at post-training, and we're incredibly good, as it turns out at inference because inference is really, really hard. How could thinking be easy? People think that inference is one shot and therefore, it's easy, anybody could approach the market that way. But it turns out to be the hardest of all because thinking as it turns out is quite hard. We're great at every phase of AI, the second thing. The third thing is we're now the only architecture in the world that runs every AI model, every frontier AI model, we run open source AI models incredibly well. We run science models, biology models, robotics models. We run every single model. We're the only architecture in the world that can claim that. It doesn't matter whether you're auto regressive or diffusion based. We run everything and we run it for every major platform, as I just mentioned. So we run every model. And then the fourth thing I would say is that we're in every cloud. The reason why developers love us is because we're literally everywhere. We're in every cloud, we're in every -- we can even make you a little tiny cloud called DGX Spark. And so we're in every computer, we're everywhere, from cloud to on-prem to robotic systems, edge devices, PCs, you name it. One architecture, things just work, it's incredible. And then the last thing, and this is probably the most important thing, the fifth thing is, if you are a cloud service provider, if you're a new company like HUMAIN, if you're a new company like CoreWeave or Nscale or Nebius or OCI for that matter, the reason why NVIDIA is the best platform for you is because our offtake is so diverse. We can help you with offtake. It's not about just putting a random ASIC into a data center. Where is the offtake coming from? Where is the diversity coming from? Where is the resilience coming from? The versatility of the architecture coming from, the diversity of capability coming from, NVIDIA has such incredibly good offtake because our ecosystem is so large. So these 5 things, every phase of acceleration and transition every phase of AI, every model, every cloud to on-prem. And of course, finally, it all leads to offtake.</td><td>**Jen-Hsun Huang:** ë„¤, ì •ë§ ê°ì‚¬í•©ë‹ˆë‹¤. ì¢‹ì€ ì§ˆë¬¸ ì£¼ì…”ì„œ ê°ì‚¬ë“œë¦½ë‹ˆë‹¤. ìš°ì„  ë§ì”€ë“œë¦¬ìë©´, ìš°ë¦¬ëŠ” ê¸°ì—…ê³¼ ê²½ìŸí•˜ëŠ” ê²Œ ì•„ë‹ˆë¼ íŒ€ë“¤ê³¼ ê²½ìŸí•˜ëŠ” ê²ë‹ˆë‹¤. ê·¸ë¦¬ê³  ì´ë ‡ê²Œ ì—„ì²­ë‚˜ê²Œ ë³µì¡í•œ ê²ƒë“¤ì„ ë§Œë“œëŠ” ë° íƒì›”í•œ íŒ€ì´ë¼ëŠ” ê²Œ ì„¸ìƒì— ê·¸ë ‡ê²Œ ë§ì§€ ì•ŠìŠµë‹ˆë‹¤. ê³¼ê±° í˜¸í¼(Hopper)ë‚˜ ì•”í˜ì–´(Ampere) ì‹œì ˆì—ëŠ” GPU í•˜ë‚˜ë§Œ ë§Œë“¤ë©´ ëìŠµë‹ˆë‹¤. ê·¸ê²Œ ë°”ë¡œ ê°€ì† AI ì‹œìŠ¤í…œì˜ ì •ì˜ì˜€ì£ . í•˜ì§€ë§Œ ì˜¤ëŠ˜ë‚ ì—ëŠ” ì „ì²´ ë™ì„ êµ¬ì¶•í•´ì•¼ í•˜ê³ , ìŠ¤ì¼€ì¼ ì—…(scale up), ìŠ¤ì¼€ì¼ ì•„ì›ƒ(scale out), ìŠ¤ì¼€ì¼ ì–´í¬ë¡œìŠ¤(scale across) ë“± 3ê°€ì§€ ìœ í˜•ì˜ ìŠ¤ìœ„ì¹˜ë¥¼ ëª¨ë‘ ë§Œë“¤ì–´ì•¼ í•©ë‹ˆë‹¤. ì´ì œëŠ” ì»´í“¨íŒ… ë…¸ë“œ í•˜ë‚˜ë¥¼ ë§Œë“œëŠ” ë°ë„ ì¹© í•˜ë‚˜ë¡œëŠ” í„±ì—†ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. ê·¸ ì»´í“¨íŒ… ì‹œìŠ¤í…œì˜ ëª¨ë“  ê²ƒì´ ë‹¬ë¼ì¡ŒìŠµë‹ˆë‹¤. AIì—ëŠ” ë©”ëª¨ë¦¬ê°€ í•„ìš”í•œë°, ì˜ˆì „ì—ëŠ” AIê°€ ë©”ëª¨ë¦¬ë¥¼ ì „í˜€ ì‚¬ìš©í•˜ì§€ ì•Šì•˜ê±°ë“ ìš”. ì´ì œ AIëŠ” ê¸°ì–µì„ í•´ì•¼ í•˜ê³ , ë©”ëª¨ë¦¬ ìš©ëŸ‰ê³¼ ì»¨í…ìŠ¤íŠ¸ê°€ ì—„ì²­ë‚˜ê²Œ ì»¤ì¡ŒìŠµë‹ˆë‹¤. ë©”ëª¨ë¦¬ ì•„í‚¤í…ì²˜ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì´ ëŒ€ë‹¨í•©ë‹ˆë‹¤. ì „ë¬¸ê°€ í˜¼í•© ëª¨ë¸(mixture of experts)ë¶€í„° ë°€ì§‘ ëª¨ë¸(dense models), ë””í“¨ì „ ëª¨ë¸(diffusion models), ë¬¼ë¦¬ ë²•ì¹™ ê¸°ë°˜ì˜ ìƒë¬¼í•™ì  ëª¨ë¸ê¹Œì§€, ë‹¤ì–‘í•œ ìœ í˜•ì˜ ëª¨ë¸ë“¤ì´ ì§€ë‚œ ëª‡ ë…„ê°„ í­ë°œì ìœ¼ë¡œ ì¦ê°€í–ˆìŠµë‹ˆë‹¤. ê·¸ë˜ì„œ ë¬¸ì œì˜ ë³µì¡ì„±ì´ í›¨ì”¬ ë†’ì•„ì¡ŒìŠµë‹ˆë‹¤. AI ëª¨ë¸ì˜ ë‹¤ì–‘ì„±ì´ ì •ë§ ì—„ì²­ë‚˜ê²Œ ì»¤ì¡Œì£ . ê·¸ë˜ì„œ ìš°ë¦¬ë¥¼ íŠ¹ë³„í•˜ê²Œ ë§Œë“œëŠ” 5ê°€ì§€ê°€ ìˆë‹¤ë©´, ì²« ë²ˆì§¸ëŠ” ìš°ë¦¬ê°€ ì „í™˜ì˜ ëª¨ë“  ë‹¨ê³„ë¥¼ ê°€ì†í™”í•œë‹¤ëŠ” ì ì…ë‹ˆë‹¤. ê·¸ê²Œ ì²« ë²ˆì§¸ì…ë‹ˆë‹¤. CUDAë¥¼ í†µí•´ ë²”ìš© ì»´í“¨íŒ…ì—ì„œ ê°€ì† ì»´í“¨íŒ…ìœ¼ë¡œ ì „í™˜í•˜ëŠ” CUDA-Xë¥¼ ë³´ìœ í•˜ê³  ìˆìŠµë‹ˆë‹¤. ìš°ë¦¬ëŠ” ìƒì„±í˜• AIì— ë§¤ìš° ë›°ì–´ë‚˜ê³ , ì—ì´ì „í‹± AIì—ë„ ë§¤ìš° ë›°ì–´ë‚©ë‹ˆë‹¤. ê·¸ëŸ¬ë‹ˆê¹Œ ê·¸ ëª¨ë“  ë‹¨ê³„ë§ˆë‹¤ -- ì „í™˜ì˜ ëª¨ë“  ê³„ì¸µì—ì„œ ìš°ë¦¬ëŠ” íƒì›”í•©ë‹ˆë‹¤. í•˜ë‚˜ì˜ ì•„í‚¤í…ì²˜ì— íˆ¬ìí•˜ë©´ ì „ë°˜ì ìœ¼ë¡œ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í•˜ë‚˜ì˜ ì•„í‚¤í…ì²˜ë¥¼ ì‚¬ìš©í•˜ë©´ì„œ ì´ 3ë‹¨ê³„ì— ê±¸ì¹œ ì›Œí¬ë¡œë“œ ë³€í™”ì— ëŒ€í•´ ê±±ì •í•  í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤. ì´ê²Œ ì²« ë²ˆì§¸ì…ë‹ˆë‹¤. ë‘ ë²ˆì§¸ë¡œ, ìš°ë¦¬ëŠ” AIì˜ ëª¨ë“  ë‹¨ê³„ì—ì„œ íƒì›”í•©ë‹ˆë‹¤. ìš°ë¦¬ê°€ ì‚¬ì „í•™ìŠµì— ì—„ì²­ë‚˜ê²Œ ë›°ì–´ë‚˜ë‹¤ëŠ” ê±´ ëª¨ë‘ê°€ í•­ìƒ ì•Œê³  ìˆì—ˆìŠµë‹ˆë‹¤. ì‚¬í›„í•™ìŠµì—ë„ ëª…ë°±íˆ ë§¤ìš° ë›°ì–´ë‚˜ê³ , ì•Œê³  ë³´ë‹ˆ ì¶”ë¡ ì—ë„ ì—„ì²­ë‚˜ê²Œ ë›°ì–´ë‚©ë‹ˆë‹¤. ì™œëƒí•˜ë©´ ì¶”ë¡ ì€ ì •ë§, ì •ë§ ì–´ë µê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ì‚¬ê³ í•˜ëŠ” ê²Œ ì‰¬ìš¸ ìˆ˜ê°€ ìˆë‚˜ìš”? ì‚¬ëŒë“¤ì€ ì¶”ë¡ (inference)ì´ ì¼íšŒì„±ì´ë¼ì„œ ì‰½ê³ , ëˆ„êµ¬ë‚˜ ê·¸ëŸ° ì‹ìœ¼ë¡œ ì‹œì¥ì— ì ‘ê·¼í•  ìˆ˜ ìˆë‹¤ê³  ìƒê°í•©ë‹ˆë‹¤. í•˜ì§€ë§Œ ì‹¤ì œë¡œëŠ” ê°€ì¥ ì–´ë ¤ìš´ ë¶€ë¶„ì…ë‹ˆë‹¤. ì™œëƒí•˜ë©´ ì‚¬ê³ (thinking)ë¼ëŠ” ê²ƒ ìì²´ê°€ ìƒë‹¹íˆ ì–´ë µê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ìš°ë¦¬ëŠ” AIì˜ ëª¨ë“  ë‹¨ê³„ì—ì„œ ë›°ì–´ë‚©ë‹ˆë‹¤. ì´ê²Œ ë‘ ë²ˆì§¸ì…ë‹ˆë‹¤. ì„¸ ë²ˆì§¸ëŠ” ìš°ë¦¬ê°€ ì´ì œ ì„¸ê³„ì—ì„œ ìœ ì¼í•˜ê²Œ ëª¨ë“  AI ëª¨ë¸, ëª¨ë“  ìµœì²¨ë‹¨ AI ëª¨ë¸ì„ ì‹¤í–‰í•˜ëŠ” ì•„í‚¤í…ì²˜ë¼ëŠ” ì ì…ë‹ˆë‹¤. ì˜¤í”ˆì†ŒìŠ¤ AI ëª¨ë¸ë„ ì—„ì²­ë‚˜ê²Œ ì˜ ì‹¤í–‰í•˜ê³ ìš”. ê³¼í•™ ëª¨ë¸, ìƒë¬¼í•™ ëª¨ë¸, ë¡œë³´í‹±ìŠ¤ ëª¨ë¸ë„ ì‹¤í–‰í•©ë‹ˆë‹¤. ëª¨ë“  ë‹¨ì¼ ëª¨ë¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤. ì´ë ‡ê²Œ ì£¼ì¥í•  ìˆ˜ ìˆëŠ” ê±´ ì„¸ê³„ì—ì„œ ìš°ë¦¬ ì•„í‚¤í…ì²˜ê°€ ìœ ì¼í•©ë‹ˆë‹¤. ìê¸°íšŒê·€(auto regressive) ë°©ì‹ì´ë“  í™•ì‚°(diffusion) ê¸°ë°˜ì´ë“  ìƒê´€ì—†ìŠµë‹ˆë‹¤. ìš°ë¦¬ëŠ” ëª¨ë“  ê²ƒì„ ì‹¤í–‰í•˜ê³ , ë°©ê¸ˆ ë§ì”€ë“œë¦° ê²ƒì²˜ëŸ¼ ëª¨ë“  ì£¼ìš” í”Œë«í¼ì—ì„œ ì‹¤í–‰í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‹ˆê¹Œ ëª¨ë“  ëª¨ë¸ì„ ì‹¤í–‰í•˜ëŠ” ê±°ì£ . ê·¸ë¦¬ê³  ë„¤ ë²ˆì§¸ë¡œ ë§ì”€ë“œë¦¬ê³  ì‹¶ì€ ê±´ ìš°ë¦¬ê°€ ëª¨ë“  í´ë¼ìš°ë“œì— ìˆë‹¤ëŠ” ì ì…ë‹ˆë‹¤. ê°œë°œìë“¤ì´ ì €í¬ë¥¼ ì¢‹ì•„í•˜ëŠ” ì´ìœ ëŠ” ë§ ê·¸ëŒ€ë¡œ ì €í¬ê°€ ì–´ë””ì—ë‚˜ ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ëª¨ë“  í´ë¼ìš°ë“œì— ìˆê³ , ì‹¬ì§€ì–´ DGX Sparkë¼ëŠ” ì‘ì€ í´ë¼ìš°ë“œë„ ë§Œë“¤ì–´ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ë˜ì„œ ëª¨ë“  ì»´í“¨í„°ì— ìˆê³ , í´ë¼ìš°ë“œë¶€í„° ì˜¨í”„ë ˆë¯¸ìŠ¤, ë¡œë´‡ ì‹œìŠ¤í…œ, ì—£ì§€ ë””ë°”ì´ìŠ¤, PCê¹Œì§€ ì •ë§ ì–´ë””ì—ë‚˜ ìˆìŠµë‹ˆë‹¤. í•˜ë‚˜ì˜ ì•„í‚¤í…ì²˜ë¡œ ëª¨ë“  ê²ƒì´ ì‘ë™í•˜ì£ , ì •ë§ ë†€ëìŠµë‹ˆë‹¤. ê·¸ë¦¬ê³  ë§ˆì§€ë§‰ìœ¼ë¡œ, ì•„ë§ˆ ê°€ì¥ ì¤‘ìš”í•œ ë‹¤ì„¯ ë²ˆì§¸ ì´ìœ ëŠ”, ë§Œì•½ ì—¬ëŸ¬ë¶„ì´ í´ë¼ìš°ë“œ ì„œë¹„ìŠ¤ ì œê³µì—…ì²´ì´ê±°ë‚˜, HUMAIN ê°™ì€ ì‹ ìƒ ê¸°ì—…ì´ê±°ë‚˜, CoreWeave, Nscale, Nebius, ë˜ëŠ” OCI ê°™ì€ ì‹ ìƒ ê¸°ì—…ì´ë¼ë©´, NVIDIAê°€ ìµœê³ ì˜ í”Œë«í¼ì¸ ì´ìœ ëŠ” ì €í¬ì˜ ì˜¤í”„í…Œì´í¬(offtake, êµ¬ë§¤ ì•½ì •)ê°€ ë§¤ìš° ë‹¤ì–‘í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ì €í¬ê°€ ì˜¤í”„í…Œì´í¬ë¥¼ ë„ì™€ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¨ìˆœíˆ ë¬´ì‘ìœ„ ASICì„ ë°ì´í„°ì„¼í„°ì— ë„£ëŠ” ê²ƒì´ ì•„ë‹™ë‹ˆë‹¤. ìˆ˜ìš”ëŠ” ì–´ë””ì„œ ë‚˜ì˜¤ëŠ”ê°€? ë‹¤ì–‘ì„±ì€ ì–´ë””ì„œ ë‚˜ì˜¤ëŠ”ê°€? íšŒë³µë ¥ì€ ì–´ë””ì„œ ë‚˜ì˜¤ëŠ”ê°€? ì•„í‚¤í…ì²˜ì˜ ë‹¤ì¬ë‹¤ëŠ¥í•¨ì€ ì–´ë””ì„œ ë‚˜ì˜¤ëŠ”ê°€? ì—­ëŸ‰ì˜ ë‹¤ì–‘ì„±ì€ ì–´ë””ì„œ ë‚˜ì˜¤ëŠ”ê°€? NVIDIAê°€ ì´ë ‡ê²Œ ì—„ì²­ë‚œ ìˆ˜ìš”ë¥¼ í™•ë³´í•˜ê³  ìˆëŠ” ì´ìœ ëŠ” ìš°ë¦¬ ìƒíƒœê³„ê°€ ë§¤ìš° ê´‘ë²”ìœ„í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ì´ 5ê°€ì§€ ìš”ì†Œë“¤ì´ ê°€ì†í™”ì™€ ì „í™˜ì˜ ëª¨ë“  ë‹¨ê³„, AIì˜ ëª¨ë“  ë‹¨ê³„, ëª¨ë“  ëª¨ë¸, í´ë¼ìš°ë“œì—ì„œ ì˜¨í”„ë ˆë¯¸ìŠ¤ê¹Œì§€ ëª¨ë“  ì˜ì—­ì—ì„œ ì‘ìš©í•©ë‹ˆë‹¤. ê·¸ë¦¬ê³  ê²°êµ­ ì´ ëª¨ë“  ê²ƒì´ ìˆ˜ìš”ë¡œ ì´ì–´ì§€ëŠ” ê²ƒì…ë‹ˆë‹¤.</td></tr>
<tr><td>Operator: Thank you. I will now turn the call to Toshiya Hari for closing remarks.</td><td>**Operator:** ê°ì‚¬í•©ë‹ˆë‹¤. ì´ì œ ë§ˆë¬´ë¦¬ ë°œì–¸ì„ ìœ„í•´ í† ì‹œì•¼ í•˜ë¦¬ì—ê²Œ ë§ˆì´í¬ë¥¼ ë„˜ê¸°ê² ìŠµë‹ˆë‹¤.</td></tr>
<tr><td>Toshiya Hari: Vice President of Investor Relations & Strategic Finance In closing, please note, we will be at the UBS Global Technology and AI Conference on December 2 and our earnings call to discuss the results of our fourth quarter of fiscal 2026 is scheduled for February 25. Thank you for joining us today. Operator, please go ahead and close the call.</td><td>**Toshiya Hari:** ë§ˆì§€ë§‰ìœ¼ë¡œ ì•ˆë‚´ ë§ì”€ ë“œë¦¬ê² ìŠµë‹ˆë‹¤. 12ì›” 2ì¼ UBS ê¸€ë¡œë²Œ í…Œí¬ë†€ë¡œì§€ ë° AI ì»¨í¼ëŸ°ìŠ¤ì— ì°¸ì„í•  ì˜ˆì •ì´ë©°, 2026 íšŒê³„ì—°ë„ 4ë¶„ê¸° ì‹¤ì  ë°œí‘œ ì»¨í¼ëŸ°ìŠ¤ ì½œì€ 2ì›” 25ì¼ë¡œ ì˜ˆì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì˜¤ëŠ˜ ì°¸ì„í•´ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤. êµí™˜ì›ë‹˜, í†µí™”ë¥¼ ì¢…ë£Œí•´ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.</td></tr>
<tr><td>Operator: Thank you. This concludes today's conference call. You may now disconnect.</td><td>**Operator:** ê°ì‚¬í•©ë‹ˆë‹¤. ì˜¤ëŠ˜ ì»¨í¼ëŸ°ìŠ¤ ì½œì„ ë§ˆì¹˜ê² ìŠµë‹ˆë‹¤. ì—°ê²°ì„ ì¢…ë£Œí•˜ì…”ë„ ë©ë‹ˆë‹¤.</td></tr>
    </table>
    <h3>ğŸ“Œ ìš”ì•½</h3>
    <p style="background:#f0f0f0; padding:15px; border-left: 5px solid #333;"># NVIDIA ì‹¤ì  ë°œí‘œ ì£¼ìš” ìš”ì•½<br><br>## í•µì‹¬ ì¬ë¬´ ì§€í‘œ ë° ê°€ì´ë˜ìŠ¤<br>- **$500B ë§¤ì¶œ ëª©í‘œ ìœ ì§€**: Blackwell + Rubin ì œí’ˆêµ°ìœ¼ë¡œ FY25-26ì— $500B ë§¤ì¶œ ëª©í‘œ ë‹¬ì„± ì˜ˆì •ì´ë©°, ì´ë¯¸ $150B ì¶œí•˜ ì™„ë£Œ. ë‹¹ ë¶„ê¸° $50B ì¶œí•˜<br>- **ì‹ ê·œ ìˆ˜ì£¼ ì¦ê°€**: ì‚¬ìš°ë””ì•„ë¼ë¹„ì•„(KSA) 40ë§Œ~60ë§Œ GPU 3ë…„ ê³„ì•½, Anthropic ì‹ ê·œ ê³„ì•½ ë“± ì¶”ê°€ ìˆ˜ì£¼ë¡œ $500B ìƒíšŒ ê°€ëŠ¥ì„±<br>- **ë§¤ì¶œì´ì´ìµë¥ **: FY26ì—ë„ mid-70% ìˆ˜ì¤€ ìœ ì§€ ëª©í‘œ. ì›ê°€ ê°œì„ , ì‚¬ì´í´ íƒ€ì„ ë‹¨ì¶•, ì œí’ˆ ë¯¹ìŠ¤ ìµœì í™”ë¡œ ëŒ€ì‘<br>- **ì¶”ë¡ (Inference) ë¹„ì¤‘**: í˜„ì¬ ì•½ 40%ì´ë©°, í–¥í›„ ëŒ€í­ ì¦ê°€ ì˜ˆìƒ. GB200 NVLink 72ëŠ” H200 ëŒ€ë¹„ 10~15ë°° ì„±ëŠ¥ í–¥ìƒ<br><br>## ê²½ì˜ì§„ í†¤ ë° ì „ëµ<br>- **ë§¤ìš° ë‚™ê´€ì **: Jensen Huang CEOëŠ” ê³µê¸‰ë§ í™•ë³´, ê¸°ìˆ  ë¦¬ë”ì‹­, ìƒíƒœê³„ í™•ì¥ì— ê°•í•œ ìì‹ ê° í‘œëª…<br>- **3ëŒ€ ì „í™˜ ê°•ì¡°**: â‘ ë²”ìš© ì»´í“¨íŒ…â†’ê°€ì† ì»´í“¨íŒ… â‘¡ì „í†µì  MLâ†’ìƒì„±í˜• AI â‘¢ì—ì´ì „í‹± AI ì‹ ê·œ ì¹´í…Œê³ ë¦¬<br>- **ìƒíƒœê³„ íˆ¬ì ì •ë‹¹í™”**: OpenAI, Anthropic ë“± íˆ¬ìëŠ” ê¸°ìˆ  í˜‘ë ¥ ì‹¬í™”, CUDA ìƒíƒœê³„ í™•ì¥, ì¥ê¸° ìˆ˜ìµ ì°½ì¶œ ëª©ì </p>
    <hr style="margin:50px 0;">
    
</body></html>